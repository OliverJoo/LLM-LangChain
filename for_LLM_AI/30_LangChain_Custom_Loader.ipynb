{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:28:56.680704Z",
     "start_time": "2025-02-28T08:28:56.284442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Loader Class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4b132287be19f64"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "\n",
    "# BaseLoader : LangChain_Core Class\n",
    "class WikidocsLoader(BaseLoader):\n",
    "    def __init__(self, book_id: int, base_url=\"https://wikidocs.net\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.book_id = book_id\n",
    "        self.base_url = base_url\n",
    "        self.headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        toc = self._get_toc(self.book_id)\n",
    "        pages = []\n",
    "        for item in toc:\n",
    "            page_id = item[\"id\"]\n",
    "            page_data = self._get_page(page_id)\n",
    "            document = Document(\n",
    "                title=page_data[\"subject\"],\n",
    "                page_content=page_data[\"content\"],\n",
    "                metadata={\n",
    "                    'id': page_id,\n",
    "                    'source': f\"{self.base_url}/{page_id}\",\n",
    "                    'title': page_data[\"subject\"]\n",
    "                }\n",
    "            )\n",
    "            pages.append(document)\n",
    "\n",
    "        return pages\n",
    "\n",
    "    # Get book index by book ID\n",
    "    def _get_toc(self, book_id):\n",
    "        url = f\"{self.base_url}/api/v1/toc/{book_id}\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            raise ValueError(\"Failed to get table of contents\")\n",
    "\n",
    "    # Get page contents by book ID\n",
    "    def _get_page(self, page_id):\n",
    "        url = f\"{self.base_url}/api/v1/page/{page_id}\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            raise ValueError(\"Failed to get page\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:11.291469Z",
     "start_time": "2025-02-28T08:31:11.071894Z"
    }
   },
   "id": "9f01d813b5590",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "book_id = 14316  # 생성AI 프로그래밍 트러블슈팅 가이드\n",
    "loader = WikidocsLoader(book_id)\n",
    "documents = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:21.573927Z",
     "start_time": "2025-02-28T08:31:13.891425Z"
    }
   },
   "id": "474aa05aa13e3c91",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'id': 231844, 'source': 'https://wikidocs.net/231844', 'title': '1. OpenAI 관련 문제해결'}, page_content='OpenAI-Python 깃허브: <https://github.com/openai/openai-python>\\n\\n[파이썬 openai 패키지 릴리스 이력](https://pypi.org/project/openai/#history)\\n\\n마이그레이션 가이드:\\n\\n- OpenAI [v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)\\n- Azure [OpenAI Python API 라이브러리 1.x로 마이그레이션](https://learn.microsoft.com/ko-kr/azure/ai-services/openai/how-to/migration?tabs=python-new%2Cdalle-fix)\\n'),\n Document(metadata={'id': 239781, 'source': 'https://wikidocs.net/239781', 'title': '1.1. OpenAI 관련 기본적인 문제 해결'}, page_content='.'),\n Document(metadata={'id': 231848, 'source': 'https://wikidocs.net/231848', 'title': \"ImportError: cannot import name 'OpenAI' from 'openai'\"}, page_content=\"## 문제\\n\\nopenai==0.28을 설치한 채로 다음을 실행하면,\\n\\n```python\\nfrom openai import OpenAI\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nImportError: cannot import name 'OpenAI' from 'openai'\\n```\\n\\n## 해결\\n\\n[최신 버전을 설치](229554#installing-latest-openai-package)해 해결한다.\\n\\n## 참고\\n\\n- <https://community.openai.com/t/cannot-import-name-openai-from-openai/486147>\"),\n Document(metadata={'id': 231849, 'source': 'https://wikidocs.net/231849', 'title': \"TypeError: 'Choice' object is not subscriptable\"}, page_content='## 문제\\n\\nopenai>=1.0.0을 설치한 채로 응답 객체를 구버전에서처럼 딕셔너리로 처리하려고 하면,\\n\\n```\\nprint(response.choices[0][\"message\"][\"content\"])\\n```\\n\\n다음과 같은 오류가 발생한다.\\n\\n```\\n>>> print(response.choices[0][\"message\"][\"content\"])\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: \\'Choice\\' object is not subscriptable\\n```\\n\\n## 설명\\n\\nopenai>=1.0.0에서 응답 객체는 딕셔너리 형태가 아닌 [Pydantic 모델](https://docs.pydantic.dev/latest/concepts/models/)로 반환된다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 코드를 수정\\n\\n코드를 다음과 같이 수정한다.\\n\\n```\\nprint(response.choices[0].[[MARK]]message.content[[/MARK]])\\n```'),\n Document(metadata={'id': 267225, 'source': 'https://wikidocs.net/267225', 'title': \"TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given\"}, page_content='## 증상\\n\\n다음 코드를 실행하면,\\n\\n```\\nimport openai\\n\\nopenai.api_key = \\'your-api-key\\'\\n\\nresponse = openai.chat.completions.create(\\n    engine=\"text-davinci-003\",\\n    prompt=\"Hello.\",\\n    max_tokens=100\\n)\\n\\nprint(response.choices[0].text)\\n```\\n\\n다음 오류가 발생\\n```\\nTypeError: Missing required arguments; Expected either (\\'model\\' and \\'prompt\\') or (\\'model\\', \\'prompt\\' and \\'stream\\') arguments to be given\\n```\\n\\n## 설명\\n\\nChat Endpoint는 deprecate되었으며 Python openai 패키지 사용법도 바뀌었음. 또한 text-davinci-003 모델도 deprecate됨.\\n\\n## 해결\\n\\n다음 코드를 사용.\\n\\n```\\nfrom openai import OpenAI\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n  model=\"gpt-4o-mini\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n    {\"role\": \"user\", \"content\": \"Hello!\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message)\\n```\\n\\n## 참고\\n\\n- <https://community.openai.com/t/typeerror-missing-required-arguments-expected-either-messages-and-model-or-messages-model-and-stream-arguments-to-be-given/601646>'),\n Document(metadata={'id': 231846, 'source': 'https://wikidocs.net/231846', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.ChatCompletion)'}, page_content='## 문제\\n\\n다음 코드는 openai==0.28에서 문제 없이 작동한다.\\n\\n```\\nimport os\\nimport openai\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nresponse = openai.ChatCompletion.create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n그런데 openai>=1.0.0으로 위의 코드를 실행하면 다음과 같은 오류가 난다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\lib\\\\_old_api.py\", line 39, in __call__\\n    raise APIRemovedInV1(symbol=self._symbol)\\nopenai.lib._old_api.APIRemovedInV1:\\n\\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface.\\n\\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\\n\\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\\n```\\n\\n## 설명\\n\\n`openai.ChatCompletion`은 openai>=1.0.0에서 지원되지 않는다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 한 가지를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 신버전의 패키지를 사용하고 코드 수정\\n\\nopenai>=1.0.0에서는 일단 다음과 같이 수정하면 오류나 경고가 뜨지 않고 잘 실행된다.\\n\\n```python\\nimport os\\nimport openai\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nresponse = openai.[[MARK]]chat.completions[[/MARK]].create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n[v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)에는 다음과 같이 하라고 안내되어 있다.\\n\\n```python\\nimport os\\n[[MARK]]from openai import OpenAI[[/MARK]]\\n\\n[[MARK]]client = OpenAI(\\n    api_key = os.environ[\"OPENAI_API_KEY\"]  # 생략 가능\\n)[[/MARK]]\\n\\nresponse = [[MARK]]client.chat.completions[[/MARK]].create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n## 참고\\n\\n- [v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)'),\n Document(metadata={'id': 229554, 'source': 'https://wikidocs.net/229554', 'title': '파이썬 OpenAI 패키지 버전 확인 및 재설치'}, page_content='## 설치된 버전 확인\\n\\nopenai 패키지를 이미 설치한 경우, 버전을 확인하려면 `pip list` 명령을 실행해 결과에서 openai의 버전을 확인한다.\\n\\n<a name=\"installing-openai-0.28\"></a>\\n\\n## 구버전(0.28)으로 고정\\n\\n2024년 1월 모델 종료와 관련해 구버전으로 고정하려면 아래 명령으로 (재)설치한다.\\n\\n```\\npip install -U openai==0.28\\n```\\n\\n<a name=\"installing-latest-openai-package\"></a>\\n\\n## 최신 버전 설치\\n\\n최신 버전으로 (재)설치하려면 아래 명령을 실행한다.\\n\\n```\\npip install -U openai\\n```\\n'),\n Document(metadata={'id': 232051, 'source': 'https://wikidocs.net/232051', 'title': '1.2. OpenAI 임베딩 관련'}, page_content='.'),\n Document(metadata={'id': 231863, 'source': 'https://wikidocs.net/231863', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (distances_from_embeddings)\"}, page_content='## 문제\\n\\nopenai>=1.0.0에서 다음 코드를 실행하면,\\n\\n```\\nfrom openai.embeddings_utils import distances_from_embeddings\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nModuleNotFoundError: No module named \\'openai.embeddings_utils\\'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 embeddings_utils가 삭제됨\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 코드를 수정\\n\\n문제를 일으키는 임포트문을 제거하고, `distances_from_embeddings` 함수를 다음과 같이 코드에 삽입한다.\\n\\n```\\ndef distances_from_embeddings(\\n    query_embedding: List[float],\\n    embeddings: List[List[float]],\\n    distance_metric=\"cosine\",\\n) -> List[List]:\\n    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\\n    distance_metrics = {\\n        \"cosine\": spatial.distance.cosine,\\n        \"L1\": spatial.distance.cityblock,\\n        \"L2\": spatial.distance.euclidean,\\n        \"Linf\": spatial.distance.chebyshev,\\n    }\\n    distances = [\\n        distance_metrics[distance_metric](query_embedding, embedding)\\n        for embedding in embeddings\\n    ]\\n    return distances\\n```\\n\\n## 참고\\n\\n- <https://stackoverflow.com/a/77645783>\\n- <https://community.openai.com/t/embeddings-utils-distance-formulas-where-did-it-move/479868/7>'),\n Document(metadata={'id': 231864, 'source': 'https://wikidocs.net/231864', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (get_embedding)\"}, page_content='## 문제\\n\\nopenai>=1.0.0에서 다음 코드를 실행하면,\\n\\n```\\nfrom openai.embeddings_utils import get_embedding\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nModuleNotFoundError: No module named \\'openai.embeddings_utils\\'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 embeddings_utils가 삭제됨\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 코드를 수정\\n\\n문제를 일으키는 임포트문을 제거하고, `get_embedding` 함수를 다음과 같이 코드에 삽입한다.\\n\\n```\\nfrom openai import OpenAI\\n\\nclient = OpenAI()\\n\\ndef get_embedding(text, model=\"text-embedding-ada-002\"):\\n   text = text.replace(\"\\\\n\", \" \")\\n   return client.embeddings.create(input = [text], model=model).data[0].embedding\\n```\\n\\n## 참고\\n\\n- <https://stackoverflow.com/a/77645783>\\n- <https://community.openai.com/t/embeddings-utils-distance-formulas-where-did-it-move/479868/7>'),\n Document(metadata={'id': 232698, 'source': 'https://wikidocs.net/232698', 'title': 'ValidationError: 1 validation error for OpenAIEmbeddings'}, page_content='## 문제\\n\\n```\\nValidationError: 1 validation error for OpenAIEmbeddings\\n__root__\\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)\\n```\\n\\n## 설명\\n\\nopenai_api_key를 찾지 못함.\\n\\n## 해결\\n\\n`OPENAI_API_KEY` 환경변수를 등록하거나, 명명된 매개변수로 `openai_api_key`를 전달해서 호출'),\n Document(metadata={'id': 231865, 'source': 'https://wikidocs.net/231865', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.Embedding)'}, page_content='## 문제\\n\\nopenai>=1.0.0을 설치하고 다음 코드를 실행하면,\\n\\n```\\nq_embeddings = openai.Embedding.create(input=question, engine=\\'text-embedding-ada-002\\')[\\'data\\'][0][\\'embedding\\']\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\app.py\", line 21, in <module>\\n    answer = answer_question(user_input, conversation_history)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\search.py\", line 49, in answer_question\\n    context = create_context(question, df, max_len=200)  #←질문과 학습 데이터를 비교해 컨텍스트 생성\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\search.py\", line 14, in create_context\\n    q_embeddings = openai.Embedding.create(input=question, engine=\\'text-embedding-ada-002\\')[\\'data\\'][0][\\'embedding\\']\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\lib\\\\_old_api.py\", line 39, in __call__\\n    raise APIRemovedInV1(symbol=self._symbol)\\nopenai.lib._old_api.APIRemovedInV1:\\n\\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\\n\\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface.\\n\\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\\n\\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\\n```\\n\\n## 설명\\n\\n`openai.Embedding`은 openai>=1.0.0에서 지원되지 않는다.\\n\\n## 해결\\n\\n다음 두 가지 방법 중 한 가지를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 신버전의 패키지를 사용하고 코드 수정\\n\\nopenai>=1.0.0을 그대로 사용하고 코드를 다음과 같이 수정한다.\\n\\n```python\\nq_embeddings = [[MARK]]client.embeddings[[/MARK]].create(input=[question], [[MARK]]model=\\'text-embedding-3-small\\'[[/MARK]]).[[MARK]]data[0].embedding[[/MARK]]\\n```\\n'),\n Document(metadata={'id': 232048, 'source': 'https://wikidocs.net/232048', 'title': '1.3. OpenAI Whisper 관련'}, page_content='- [파이썬 openai-whisper 패키지 릴리스 이력](https://pypi.org/project/openai-whisper/#history)'),\n Document(metadata={'id': 232049, 'source': 'https://wikidocs.net/232049', 'title': \"AttributeError: 'Audio' object has no attribute 'transcribe'\"}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```python\\nimport openai\\nimport os\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = client.audio.transcribe(\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\whisper\\\\srt_old.py\", line 8, in <module>\\n    transcript = openai.audio.transcribe(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\_utils\\\\_proxy.py\", line 23, in __getattr__\\n    return getattr(proxied, attr)\\n           ^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: \\'Audio\\' object has no attribute \\'transcribe\\'\\n```\\n\\n## 해결\\n\\n다음과 같이 코드를 수정하면 오류가 발생하지 않는다.\\n\\n```python\\nimport openai\\nimport os\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n[[MARK]]client = openai.OpenAI()[[/MARK]]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = [[MARK]]client.audio.transcriptions.create[[/MARK]](\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n또한 다음 코드가 더 신식이다.\\n\\n```python\\n[[MARK]]from openai import OpenAI\\nclient = OpenAI()[[/MARK]]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = client.audio.transcriptions.create(\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n`OPENAI_API_KEY`를 환경변수에 저장하는 것이 디폴트이므로 생략한다.'),\n Document(metadata={'id': 232568, 'source': 'https://wikidocs.net/232568', 'title': \"AttributeError: 'str' object has no attribute 'text'\"}, page_content='## 문제\\n\\n`audio.transcriptions.create()`의 `response_format` 인자를 `\"srt\"` 등으로 지정할 경우, 결괏값의 `.text`에 접근하려고 하면 `AttributeError: \\'str\\' object has no attribute \\'text\\'` 오류 발생\\n\\n## 설명\\n\\n이 오류의 주된 원인은 `create` 함수 호출 결과가 문자열(str)을 반환하는데, 코드가 이 반환값에 `.text` 속성을 접근하려고 시도하기 때문이다. 이 함수가 직접적으로 텍스트를 반환한다면, `.text` 속성 접근 대신 반환된 문자열을 직접 사용해야 한다.\\n\\n## 해결\\n\\n`response_format=\"srt\"`를 지정할 경우 `.text` 속성 접근 대신 반환된 문자열을 직접 사용한다.\\n\\n예를 들어, `return transcript.text`를 `return transcript`로 수정한다.'),\n Document(metadata={'id': 239780, 'source': 'https://wikidocs.net/239780', 'title': '1.4. GPT-4o 관련'}, page_content='.'),\n Document(metadata={'id': 239779, 'source': 'https://wikidocs.net/239779', 'title': \"KeyError: 'Could not automatically map gpt-4o to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'\"}, page_content=\"## 증상\\n\\n```\\nKeyError: 'Could not automatically map gpt-4o to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'\\n```\\n\\n## 해결\\n\\n```\\npip install -U tiktoken\\n```\"),\n Document(metadata={'id': 232052, 'source': 'https://wikidocs.net/232052', 'title': '1.5. 그 밖의 OpenAI 관련 문제'}, page_content='.'),\n Document(metadata={'id': 231380, 'source': 'https://wikidocs.net/231380', 'title': \"ImportError: cannot import name 'BaseTransport' from 'httpx'\"}, page_content=\"## 문제\\n\\nopenai>=1.0.0과 googletrans 패키지를 함께 사용하는 경우 이 오류가 발생할 수 있다.\\n\\n```\\nImportError: cannot import name 'BaseTransport' from 'httpx'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 사용하는 httpx 버전과 googletrans 에서 사용하는 httpx 버전이 맞지 않아서 발생하는 문제다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\ngoogletrans 패키지를 꼭 써야 하거나, 2023년까지의 자료를 바탕으로 실습할 때는 이 방법을 택하는 것이 좋을 것이다.\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n\\n### 옵션 2: googletrans 패키지를 삭제하고 httpx 재설치\\n\\n굳이 googletrans 패키지를 사용할 필요가 없다면 삭제한다.\\n\\n```\\npip uninstall googletrans\\n```\\n\\nhttpx 패키지를 높은 버전으로 재설치한다.\\n\\n```\\npip install -U httpx\\n```\\n\\n## 참고\\n\\n- <https://www.inflearn.com/questions/1139993/ch07-실습에-필요한-패키지-설치-시-오류가-납니다>\"),\n Document(metadata={'id': 231845, 'source': 'https://wikidocs.net/231845', 'title': '2. LangChain'}, page_content='\\nLangChain 문서: <https://python.langchain.com/docs/get_started/introduction>\\n\\nLangChain 레거시(v0.0.354) 레퍼런스 매뉴얼:  \\n[langchain 0.0.354](https://api.python.langchain.com/en/v0.0.354/langchain_api_reference.html)\\n\\n최신 레퍼런스 매뉴얼 및 소스 코드:\\n\\n| 패키지 | 레퍼런스 매뉴얼 | 소스 코드 |\\n| --- | --- | --- |\\n| langchain-core | [레퍼런스](https://api.python.langchain.com/en/latest/core_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/core/langchain_core) |\\n| langchain-community | [레퍼런스](https://api.python.langchain.com/en/latest/community_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community) |\\n| langchain | [레퍼런스](https://api.python.langchain.com/en/latest/langchain_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain)\\n\\nLangChain 프레임워크 개요:\\n\\n![](https://wikidocs.net/images/page/231845/LangChain-Framework-Overview.png)  \\n(이미지 출처: <https://python.langchain.com/docs/get_started/introduction>)\\n\\n패키지 릴리스 이력:\\n\\n- [파이썬 langchain 패키지 릴리스 이력](https://pypi.org/project/langchain/#history)\\n- [파이썬 langchain-community 패키지 릴리스 이력](https://pypi.org/project/langchain-community/#history)\\n- [파이썬 langchain-core 패키지 릴리스 이력](https://pypi.org/project/langchain-core/#history)\\n'),\n Document(metadata={'id': 267523, 'source': 'https://wikidocs.net/267523', 'title': '2.1 LangChain'}, page_content='.'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='## 증상\\n\\n다음 패키지를 사용해,\\n\\n```\\nlangchain                                0.2.13\\nlangchain-community                      0.2.5\\nlangchain-core                           0.2.30\\nlangchain-openai                         0.1.21\\nlangchainhub                             0.1.14\\n```\\n\\n다음 코드 실행 시,\\n\\n```\\nfrom langchain.agents import create_sql_agent\\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.chat_models import ChatOpenAI\\n\\nllm = ChatOpenAI()\\n\\ndb = SQLDatabase.from_uri(\\'sqlite:///chinook.db\\')\\n\\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)\\nagent_executor = create_sql_agent(\\n    llm=llm,\\n    toolkit=toolkit,\\n    verbose=True,\\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\n)\\n\\n[[MARK]]print(agent_executor.agent.llm_chain.prompt.template)[[/MARK]]\\n```\\n\\n다음 오류가 발생:\\n\\n```\\nAttributeError: \\'RunnableAgent\\' object has no attribute \\'llm_chain\\'\\n```\\n\\n## 해결\\n\\n```python\\nfrom langchain.agents import create_sql_agent\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\\n\\ndb = SQLDatabase.from_uri(\\'sqlite:///chinook.db\\')\\n\\nagent_executor = create_sql_agent(\\n    llm=llm,\\n    db=db,\\n    agent_type=\"tool-calling\",\\n    verbose=True,    \\n)\\n\\n[[MARK]]print(agent_executor.agent.runnable.steps[1].messages[0].content)[[/MARK]]\\n```\\n\\n결과:\\n\\n```.plaintext\\nYou are an agent designed to interact with a SQL database.\\nGiven an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.\\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\\nYou can order the results by a relevant column to return the most interesting examples in the database.\\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\\nYou have access to tools for interacting with the database.\\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\nIf the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n```'),\n Document(metadata={'id': 256096, 'source': 'https://wikidocs.net/256096', 'title': \"ImportError: cannot import name 'PythonREPL' from 'langchain.python'\"}, page_content=\"## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain.python import PythonREPL\\n```\\n\\n다음 오류가 발생:\\n\\n```\\n---------------------------------------------------------------------------\\nImportError                               Traceback (most recent call last)\\nCell In[2], line 4\\n      1 from langchain_experimental.agents.agent_toolkits import create_python_agent\\n      2 from langchain_experimental.tools.python.tool import PythonREPLTool\\n----> 4 from langchain.python import PythonREPL\\n      5 from langchain.llms.openai import OpenAI\\n      6 from langchain.agents.agent_types import AgentType\\n\\nImportError: cannot import name 'PythonREPL' from 'langchain.python' (c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\python.py)\\n```\\n\\n## 해결\\n\\n```\\n! pip install langchain_experimental\\n```\\n\\n```\\nfrom langchain_experimental.utilities import PythonREPL\\n```\"),\n Document(metadata={'id': 254474, 'source': 'https://wikidocs.net/254474', 'title': 'LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.'}, page_content='## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain import PromptTemplate, OpenAI, LLMChain\\n\\ntemplate = \"\"\"문장: {sentence}\\n{language}로 번역:\"\"\"\\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\\n\\nllm = OpenAI(temperature=0)\\n\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n\\nllm_chain.predict(sentence=\"탁자 위에 고양이가 있어요\", language=\"영어\")\\n```\\n\\n다음 경고가 발생함.\\n\\n```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\\n  warn_deprecated(\\n```\\n\\n## 해결\\n\\nLCEL을 사용.\\n\\n```\\nfrom langchain import PromptTemplate, OpenAI\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableSequence, RunnablePassthrough\\n\\ntemplate = \"\"\"문장: {sentence}\\n{language}로 번역:\"\"\"\\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\\n\\nllm = OpenAI(temperature=0)\\n\\noutput_parser = StrOutputParser()\\n\\nchain = RunnableSequence(\\n    {\\n        \"sentence\": RunnablePassthrough(),\\n        \"language\": RunnablePassthrough()\\n    }\\n    | prompt\\n    | llm\\n    | output_parser\\n)\\n\\nresult = chain.invoke({\\n    \"sentence\": \"탁자 위에 고양이가 있어요\",\\n    \"language\": \"영어\"\\n})\\nprint(result)\\n```'),\n Document(metadata={'id': 232743, 'source': 'https://wikidocs.net/232743', 'title': 'LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_community.chat_models import ChatOpenAI\\n\\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\nLangChainDeprecationWarning이 발생.\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\\n```\\n\\n## 해결\\n\\n`langchain-openai` 패키지를 설치하고,\\n\\n```\\npip install -U langchain-openai\\n```\\n\\n코드를 다음과 같이 수정.\\n\\n```\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\n'),\n Document(metadata={'id': 231843, 'source': 'https://wikidocs.net/231843', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_community.llms import OpenAI\\nopenai = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\\n```\\n\\n다음과 같은 오류가 난다.\\n\\n```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\\n  warn_deprecated(\\n```\\n\\n## 설명\\n\\n`langchain_community.llms.openai.OpenAI`는 langchain-community 0.0.10에서 deprecate되었으며 0.2.0에서 제거될 예정이다. 업데이트된 버전의 클래스가 langchain-openai 패키지에 있으며 이것을 사용해야 한다.\\n\\n## 해결 방법\\n\\n명령 프롬프트(또는 터미널)에서 다음 명령을 실행해 langchain-openai 패키지를 설치하고,\\n\\n```bash\\npip install -U langchain-openai\\n```\\n\\n임포트문을 다음과 같이 바꾼다.\\n\\n```python\\nfrom langchain_openai import OpenAI\\n```'),\n Document(metadata={'id': 233334, 'source': 'https://wikidocs.net/233334', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. 및 LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.'}, page_content='## 현상\\n\\n다음 패키지를 설치하고,\\n\\n```\\n!pip install langchain==0.1.14 openai==1.14.3\\n```\\n\\n다음 코드를 실행하면,\\n\\n```python\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI()\\nllm(\"hello\")\\n```\\n\\n`LangChainDeprecationWarning`이 두 개 뜬다.\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\\n  warn_deprecated(\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\\n  warn_deprecated(\\n\"\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\n```\\n\\n## 해결\\n\\n`langchain-openai`를 추가로 설치하고,\\n\\n```\\n!pip install langchain-openai==0.1.1\\n```\\n\\n코드를 이렇게 바꾼다.\\n\\n```python\\nfrom [[MARK]]langchain_openai[[/MARK]] import OpenAI\\n\\nllm = OpenAI()\\nllm[[MARK]].invoke[[/MARK]](\"hello\")\\n```\\n\\n이제 경고 메시지가 나오지 않는다.\\n\\n```\\n\\'world\\\\nThe quick brown fox jumps over the lazy dog.\\\\n\\\\nHello World!\\'\\n```'),\n Document(metadata={'id': 236206, 'source': 'https://wikidocs.net/236206', 'title': 'LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.'}, page_content='### 증상\\n\\n```\\n!pip install langchain==0.1.14 openai==1.16.2 langchain-openai==0.1.1\\n```\\n\\n```\\nfrom langchain.agents import AgentType, initialize_agent, load_tools\\nfrom langchain.chat_models import ChatOpenAI\\n\\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\ntools = load_tools([\"terminal\"])\\nagent_chain = initialize_agent(\\n    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\\n)\\n\\nresult = agent_chain.run(\"sample_data 디렉터리에 있는 파일 목록을 알려줘\")\\nprint(결과)\\n```\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\\n```\\n\\n### 해결\\n\\n```\\n!pip install langchain-experimental==0.0.56 langchainhub==0.1.15\\n```\\n\\n```\\nfrom langchain import hub\\nfrom langchain.agents import AgentExecutor, create_react_agent, load_tools\\nfrom langchain_openai import ChatOpenAI\\n\\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\ntools = load_tools([\"terminal\"], allow_dangerous_tools=True)\\n\\nprompt = hub.pull(\"hwchase17/react\")\\n\\nagent = create_react_agent(chat, tools, prompt)\\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\\n\\nresult = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\\nprint(result)\\n```\\n\\n### 참고\\n\\n- Agent Types: <https://python.langchain.com/docs/modules/agents/agent_types/>\\n- OpenAI functions: <https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent/>\\n- ReAct:\\n    - <https://python.langchain.com/docs/modules/agents/agent_types/react/>\\n    - create_react_agent: <https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html>\\n- JSON Chat Agent: <https://python.langchain.com/docs/modules/agents/agent_types/json_agent/>\\n- Structured chat: <https://python.langchain.com/docs/modules/agents/agent_types/structured_chat/>'),\n Document(metadata={'id': 235780, 'source': 'https://wikidocs.net/235780', 'title': 'LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.'}, page_content='## 현상\\n\\n다음을 설치하고,\\n\\n```\\n!pip install langchain==0.1.14 openai==1.14.3 langchain-openai==0.1.1\\n```\\n\\n다음을 실행하면,\\n\\n```\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain_openai import OpenAI\\n\\ntemplate = \"\"\"Question: {question}\\\\n\\\\nAnswer: Let\\'s think step by step.\"\"\"\\nprompt = PromptTemplate.from_template(template)\\nllm = OpenAI()\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\nquestion = \"What are the three key pieces of advice for learning how to code?\"\\nllm_chain.run(question)\\n```\\n\\n`LangChainDeprecationWarning`이 발생한다.\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\\n  warn_deprecated(\\n \\\\n\\\\n1. Start with the basics: Before diving into any specific programming language, it\\'s important to understand the fundamental concepts of coding. This includes understanding algorithms, data structures, and basic syntax. You can start with online resources like Codeacademy, Coursera, or YouTube tutorials to learn about these concepts.\\\\n\\\\n2. Choose a language and stick to it: There are many programming languages out there, but it\\'s important to choose one and stick to it for a while. This will help you build a strong foundation and understand the core principles of coding. Some popular languages for beginners include Python, Java, and JavaScript.\\\\n\\\\n3. Practice, practice, practice: The best way to learn coding is by practicing regularly. Start with simple projects and gradually move on to more complex ones. This will not only help you improve your coding skills but also give you a better understanding of how to solve problems using code. You can also join coding communities or atten\\n```\\n \\n## 해결\\n\\n`run` 대신 `invoke`를 사용한다.\\n\\n```\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain_openai import OpenAI\\n\\ntemplate = \"\"\"Question: {question}\\\\n\\\\nAnswer: Let\\'s think step by step.\"\"\"\\nprompt = PromptTemplate.from_template(template)\\nllm = OpenAI()\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\nquestion = \"What are the three key pieces of advice for learning how to code?\"\\nllm_chain[[MARK]].invoke[[/MARK]](question)\\n```\\n\\n그러면 경고가 뜨지 않는다.\\n\\n```\\n{\\'question\\': \\'What are the three key pieces of advice for learning how to code?\\',\\n \\'text\\': \" Here are three key pieces of advice for learning how to code:\\\\n\\\\n1. Start with the basics: Before diving into complex coding languages and projects, it is important to have a strong foundation in the basics of coding. This includes understanding concepts such as variables, loops, conditions, and data types. You can start with simple languages like HTML and CSS, which are used for building websites, or with programming languages like Python or Java.\\\\n\\\\n2. Practice, practice, practice: Coding is a skill that requires practice and repetition. The more you code, the better you will become at it. Set aside time each day to practice coding exercises or work on personal projects. This will help you improve your skills and build your confidence.\\\\n\\\\n3. Don\\'t be afraid to ask for help: Coding can be challenging, and it is common to run into roadblocks or encounter problems while learning. Don\\'t be afraid to ask for help from more experienced programmers, whether it\\'s through online forums, coding communities, or reaching out to a mentor. Learning from others and getting feedback on your code can greatly accelerate your learning process. \"}\\n```'),\n Document(metadata={'id': 256720, 'source': 'https://wikidocs.net/256720', 'title': \"ModuleNotFoundError: No module named 'youtube_search'\"}, page_content='## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain.tools import YouTubeSearchTool\\ntool = YouTubeSearchTool()\\nresult = tool.run(\"Avatar: The Way of Water,1\")\\n```\\n\\n다음 오류가 발생\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\ncore\\\\tools.py\", line 621, in run\\n    raise error_to_raise\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\tools.py\", line 590, in run\\n    response = context.run(self._run, *tool_args, **tool_kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_community\\\\tools\\\\youtube\\\\search.py\", line 54, in _run\\n    return self._search(person, num_results)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_community\\\\tools\\\\youtube\\\\search.py\", line 33, in _search\\n    from youtube_search import YoutubeSearch\\nModuleNotFoundError: No module named \\'youtube_search\\'\\n```\\n\\n## 해결\\n\\n다음 명령으로 youtube-search 패키지를 설치 후 재시도.\\n\\n```.console\\npip install youtube-search\\n```'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='## 증상\\n\\n```\\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\\nfrom langchain_experimental.tools.python.tool import PythonREPLTool\\n\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain.llms.openai import OpenAI\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.chat_models import ChatOpenAI\\n\\nmodel = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\\n\\nagent_executor = create_python_agent(\\n    llm=model,\\n    tool=PythonREPLTool(),\\n    verbose=True,\\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\n)\\n\\nagent_executor = create_python_agent(\\n    llm=model,\\n    tool=PythonREPLTool(),\\n    verbose=True,\\n    agent_type=AgentType.OPENAI_FUNCTIONS,\\n    agent_executor_kwargs={\"handle_parsing_errors\": True},\\n)\\n\\nquery = \"\"\"\\nIn a different basketball game, we have the following player stats:\\n- Player A: 38 points, 10 rebounds, 7 assists\\n- Player B: 28 points, 9 rebounds, 6 assists\\n- Player C: 19 points, 6 rebounds, 3 assists\\n- Player D: 12 points, 4 rebounds, 2 assists\\n- Player E: 7 points, 2 rebounds, 1 assist\\n\\nCould you create a scatter plot graph in Seaborn talk mode for each player, where the y-axis represents the number of points, the x-axis represents the number of rebounds, and use \\'o\\' as the marker? Additionally, please label each point with the player\\'s name and set the title as \"Team Players.\"\\n\"\"\"\\n\\nagent_executor.run(query)\\n```\\n\\n```\\nc:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\\n  warn_deprecated(\\n\\n\\n> Entering new AgentExecutor chain...\\n\\n---------------------------------------------------------------------------\\nNotFoundError                             Traceback (most recent call last)\\nCell In[6], line 12\\n      1 query = \"\"\"\\n      2 In a different basketball game, we have the following player stats:\\n      3 - Player A: 38 points, 10 rebounds, 7 assists\\n   (...)\\n      9 Could you create a scatter plot graph in Seaborn talk mode for each player, where the y-axis represents the number of points, the x-axis represents the number of rebounds, and use \\'o\\' as the marker? Additionally, please label each point with the player\\'s name and set the title as \"Team Players.\"\\n     10 \"\"\"\\n---> 12 agent_executor.run(query)\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:170, in deprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper(*args, **kwargs)\\n    168     warned = True\\n    169     emit_warning()\\n--> 170 return wrapped(*args, **kwargs)\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:598, in Chain.run(self, callbacks, tags, metadata, *args, **kwargs)\\n    596     if len(args) != 1:\\n    597         raise ValueError(\"`run` supports only one positional argument.\")\\n--> 598     return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\\n    599         _output_key\\n    600     ]\\n    602 if kwargs and not args:\\n    603     return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\\n    604         _output_key\\n...\\n   (...)\\n   1048     retries_taken=options.get_max_retries(self.max_retries) - retries,\\n   1049 )\\n\\nNotFoundError: Error code: 404 - {\\'error\\': {\\'message\\': \\'The model `gpt-3.5-turbo-0613` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': \\'model_not_found\\'}}\\n```\\n\\n## 원인\\n\\nOpenAI에서 종료한 모델을 사용하려고 해서 오류 발생\\n\\n## 해결\\n\\n모델을 교체. 예:\\n\\n```\\nmodel = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\\n```\\n'),\n Document(metadata={'id': 235773, 'source': 'https://wikidocs.net/235773', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', ...\"}, page_content='## 현상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_openai import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n\\nllm(\"hello\")\\n```\\n\\n다음 오류가 발생.\\n\\n```\\nNotFoundError: Error code: 404 - {\\'error\\': {\\'message\\': \\'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': \\'model\\', \\'code\\': None}}\\n```\\n\\n## 해결\\n\\n구형(legacy)인 Completions 엔드포인트를 사용하려면 다음과 같이 `gpt-3.5-turbo-instruct` 모델을 사용한다.\\n\\n```\\nfrom langchain_openai import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\\n\\nllm(\"hello\")\\n```\\n\\nChat Completions 엔드포인트를 지원하는 모델(예: `gpt-3.5-turbo`)을 사용하려면 `OpenAI` 대신 `ChatOpenAI`를 사용한다.'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='## 증상\\n\\nlangchain-openai==0.1.22에서 다음 코드를 실행하면,\\n\\n```\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.document_loaders import PyPDFLoader\\n\\nimport os\\n\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nos.environ[\"OPENAI_API_KEY\"]\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n            chunk_size=1500,\\n            chunk_overlap=200\\n        )\\n\\nraw_documents = PyPDFLoader(\\'italy_travel.pdf\\').load()\\ndocuments = text_splitter.split_documents(raw_documents)\\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\\n\\n\\nfrom langchain.tools.retriever import create_retriever_tool\\nfrom langchain.memory import ConversationBufferMemory\\nfrom langchain.agents.agent_toolkits import create_conversational_retrieval_agent\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\\n\\ntool = create_retriever_tool(\\n    db.as_retriever(), \\n    \"italy_travel\",\\n    \"이탈리아에 관한 문서를 검색해서 반환합니다.\"\\n)\\ntools = [tool]\\n\\nmemory = ConversationBufferMemory(\\n    memory_key=\\'chat_history\\',\\n    return_messages=True,\\n    llm=llm\\n)\\n\\nagent_executor = create_conversational_retrieval_agent(\\n    llm, \\n    tools, \\n    memory_key=\\'chat_history\\', \\n    verbose=True\\n)\\n\\nagent_executor.invoke({\"input\": \"판테온(Pantheon)에 관해 알려주세요\"})\\n```\\n\\n다음 오류가 발생.\\n\\n```\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\nCell In[6], line 1\\n----> 1 agent_executor.invoke({\"input\": \"판테온(Pantheon)에 관해 알려주세요\"})\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:164, in Chain.invoke(self, input, config, **kwargs)\\n    162 except BaseException as e:\\n    163     run_manager.on_chain_error(e)\\n--> 164     raise e\\n    165 run_manager.on_chain_end(outputs)\\n    167 if include_run_info:\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:159, in Chain.invoke(self, input, config, **kwargs)\\n    152     self._validate_inputs(inputs)\\n    153     outputs = (\\n    154         self._call(inputs, run_manager=run_manager)\\n    155         if new_arg_supported\\n    156         else self._call(inputs)\\n    157     )\\n--> 159     final_outputs: Dict[str, Any] = self.prep_outputs(\\n    160         inputs, outputs, return_only_outputs\\n    161     )\\n    162 except BaseException as e:\\n    163     run_manager.on_chain_error(e)\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:458, in Chain.prep_outputs(self, inputs, outputs, return_only_outputs)\\n    456 self._validate_outputs(outputs)\\n    457 if self.memory is not None:\\n--> 458     self.memory.save_context(inputs, outputs)\\n    459 if return_only_outputs:\\n    460     return outputs\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\agents\\\\openai_functions_agent\\\\agent_token_buffer_memory.py:97, in AgentTokenBufferMemory.save_context(self, inputs, outputs)\\n     95 # Prune buffer if it exceeds max token limit\\n     96 buffer = self.chat_memory.messages\\n---> 97 curr_buffer_length = self.llm.get_num_tokens_from_messages(buffer)\\n     98 if curr_buffer_length > self.max_token_limit:\\n     99     while curr_buffer_length > self.max_token_limit:\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_openai\\\\chat_models\\\\base.py:960, in BaseChatOpenAI.get_num_tokens_from_messages(self, messages)\\n    956     continue\\n    957 else:\\n    958     # Cast str(value) in case the message value is not a string\\n    959     # This occurs with function messages\\n--> 960     num_tokens += len(encoding.encode(value))\\n    961 if key == \"name\":\\n    962     num_tokens += tokens_per_name\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tiktoken\\\\core.py:116, in Encoding.encode(self, text, allowed_special, disallowed_special)\\n    114     if not isinstance(disallowed_special, frozenset):\\n    115         disallowed_special = frozenset(disallowed_special)\\n--> 116     if match := _special_token_regex(disallowed_special).search(text):\\n    117         raise_disallowed_special_token(match.group())\\n    119 # https://github.com/PyO3/pyo3/pull/3632\\n\\nTypeError: expected string or buffer\\n```\\n\\n## 해결\\n\\nlangchain-openai==0.1.23 이상을 설치.\\n\\n```\\npip install langchain-openai -U\\n```\\n\\n## 참고\\n\\n- openai[patch]: fix get_num_tokens for function calls ([#25785](https://github.com/langchain-ai/langchain/pull/25785))\\n- [langchain-openai==0.1.23 릴리스](https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D0.1.23)'),\n Document(metadata={'id': 235770, 'source': 'https://wikidocs.net/235770', 'title': 'UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`'}, page_content='## 현상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\n다음 경고가 발생.\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:249: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\\n  warnings.warn(\\n/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:1070: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\\n  warnings.warn(\\n```\\n\\n## 1차 조치\\n\\n다음 코드로 변경.\\n\\n```\\nfrom langchain_community.chat_models import ChatOpenAI\\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\n이제 LangChainDeprecationWarning이 발생.\\n\\n```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\\n```\\n\\n## 2차 조치\\n\\n<https://wikidocs.net/232743>를 참조.'),\n Document(metadata={'id': 256093, 'source': 'https://wikidocs.net/256093', 'title': \"ValueError: 'agent_toolkits' is not in the subpath of 'langchain_core' OR one path is relative and the other is absolute.\"}, page_content='## 증상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain.agents.agent_toolkits import create_python_agent\\n```\\n\\n다음 오류가 발생:\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\agents\\\\agent_toolkits\\\\__init__.py\", line 121, in __getattr__\\n    relative_path = as_import_path(Path(__file__).parent, suffix=name)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\\\path.py\", line 30, in as_import_path\\n    path = get_relative_path(file, relative_to=relative_to)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\path.py\", line 18, in get_relative_path\\n    return str(file.relative_to(relative_to))\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\pathlib.py\", line 730, in relative_to\\n    raise ValueError(\"{!r} is not in the subpath of {!r}\"\\nValueError: \\'C:\\\\\\\\Users\\\\\\\\yong\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Python\\\\\\\\Python311\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\langchain\\\\\\\\agents\\\\\\\\agent_toolkits\\' is not in the subpath of \\'C:\\\\\\\\Users\\\\\\\\yong\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Python\\\\\\\\Python311\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\langchain_core\\' OR one path is relative and the other is absolute.\\n```\\n\\n## 해결\\n\\n```\\n!pip install langchain_experimental\\n```\\n\\n```\\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\\n```\\n\\n## 참고\\n\\n- <https://stackoverflow.com/a/78021185>'),\n Document(metadata={'id': 232860, 'source': 'https://wikidocs.net/232860', 'title': 'VectorstoreIndexCreator 사용 시 LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n`VectorStoreIndexCreator` 사용 시 `langchain_community.embeddings.openai.OpenAIEmbeddings`의 사용 중단 경고가 발생한다.\\n\\n```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\\n  warn_deprecated(\\n```\\n\\n## 설명\\n\\n[vectorstore.py의 4번째 줄](https://github.com/langchain-ai/langchain/blob/5efb5c099f6ced0b752306c4cb1c45370c2a6920/libs/langchain/langchain/indexes/vectorstore.py#L4)에서 `langchain_community.embeddings.openai.OpenAIEmbeddings`가 사용되는 것이 원인으로 보인다. \\n\\n## 해결\\n\\n경고 메시지가 안 나오게 하려면 다음과 같이 할 수 있다.\\n\\n1. `langchain-openai` 패키지를 설치.\\n\\n        pip install -U langchain-openai\\n   \\n2. 코드에서, 사용 중단된 `langchain_community.embeddings.openai.OpenAIEmbeddings` 대신 `langchain_openai` 패키지에서 `OpenAIEmbeddings`를 임포트한다.\\n\\n\\n        from langchain_openai import OpenAIEmbeddings\\n\\n3. `VectorStoreIndexCreator` 인스턴스 생성 시 업데이트된 `OpenAIEmbeddings` 클래스를 사용한다.\\n\\n        from langchain_openai import OpenAIEmbeddings\\n        from langchain.indexes.vectorstore import VectorstoreIndexCreator\\n        \\n        vectorstore_index_creator = VectorStoreIndexCreator(embedding=OpenAIEmbeddings())\\n   \\n\\n이렇게 하면 최신 `OpenAIEmbeddings` 클래스를 사용하여 LangChain의 기능을 계속 활용할 수 있고, 라이브러리의 향후 업데이트에도 대비할 수 있다.\\n'),\n Document(metadata={'id': 239760, 'source': 'https://wikidocs.net/239760', 'title': '[terminal] is not a valid tool, try one of [terminal]'}, page_content='## 증상\\n\\nlangchain 0.1.19 미만에서 `tools = load_tools([\"terminal\"], allow_dangerous_tools=True)` 실행 시 terminal tool을 못 찾음.\\n\\n```\\n> Entering new AgentExecutor chain...\\nI should use the terminal to list the files in the sample_data directory.\\nAction: [terminal]\\nAction Input: ls sample_data[terminal] is not a valid tool, try one of [terminal].I should use the terminal to list the files in the sample_data directory.\\nAction: [terminal]\\n```\\n\\n## 해결\\n\\n```\\n!pip install langchain==0.1.19\\n```\\n\\n## 참고\\n\\n<https://github.com/langchain-ai/langchain/commit/44602bdc20ffa336326d64f593bf29f458088554>'),\n Document(metadata={'id': 239759, 'source': 'https://wikidocs.net/239759', 'title': 'ddg-search 사용 시 RatelimitException 발생'}, page_content='## 증상\\n\\nddg-search 사용 시 RatelimitException 발생\\n\\n```\\nduckduckgo_search.exceptions.RatelimitException: https://duckduckgo.com/ 202 Ratelimit\\n```\\n\\n## 해결\\n\\n```\\npip install -U duckduckgo_search\\n```\\n\\n## 참고\\n\\n<https://github.com/deedy5/duckduckgo_search/issues/213>'),\n Document(metadata={'id': 267506, 'source': 'https://wikidocs.net/267506', 'title': 'macOS에서 langchainhub 설치 시 npm error code EACCES 오류 발생'}, page_content='## 증상\\n\\n```\\n% npm i -g langchainhub\\nnpm error code EACCES\\nnpm error syscall open\\nnpm error path /Users/yong/.npm/_cacache/tmp/9cc563c5\\nnpm error errno EACCES\\nnpm error\\nnpm error Your cache folder contains root-owned files, due to a bug in\\nnpm error previous versions of npm which has since been addressed.\\nnpm error\\nnpm error To permanently fix this problem, please run:\\nnpm error   sudo chown -R 501:20 \"/Users/yong/.npm\"\\nnpm error A complete log of this run can be found in: /Users/yong/.npm/_logs/2024-11-27T09_04_47_244Z-debug-0.log\\n```\\n\\n## 해결\\n\\n루트 권한으로 설치.\\n\\n```\\nsudo npm i -g langchainhub\\n```'),\n Document(metadata={'id': 267524, 'source': 'https://wikidocs.net/267524', 'title': '2.2 LangSmith'}, page_content='.'),\n Document(metadata={'id': 267525, 'source': 'https://wikidocs.net/267525', 'title': 'LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API'}, page_content='## 증상\\n\\n구글 코랩  등에서 실습 시 LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API 경고 발생\\n\\n## 해결\\n\\n[LangSmith](https://www.langchain.com/langsmith) API 키를 받아서 환경 변수 설정.\\n\\n코드 예:\\n\\n```\\nimport getpass\\nimport os\\n\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\\nos.environ[\"LANGCHAIN_PROJECT\"] = \"My_project\"\\n```\\n\\n## 참고\\n\\n- <https://github.com/langchain-ai/langchain/discussions/26755>\\n- [Create an account and API key](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key)'),\n Document(metadata={'id': 267503, 'source': 'https://wikidocs.net/267503', 'title': '3. Flowise'}, page_content='.'),\n Document(metadata={'id': 267508, 'source': 'https://wikidocs.net/267508', 'title': \"Flowise 실행 시 Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/flowise/logs'\"}, page_content=\"## 증상\\n\\nmacOS에서 Flowise 실행 시 다음 오류 발생:\\n\\n```\\n% npx flowise start\\n    Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/flowise/logs'\\n    Code: EACCES\\n```\\n\\n## 해결\\n\\n1. 현재 사용자와 그룹 확인\\n\\n    사용자의 기본 그룹을 확인한다.\\n\\n        id -gn\\n\\n    출력된 그룹명을 확인한다. 예를 들어, 그룹명이 `staff`로 출력된다면 이를 사용하면 된다.\\n\\n2. chown 명령 수정\\n\\n    위에서 확인한 그룹 이름을 사용하여 아래 명령을 실행한다.\\n\\n        sudo chown -R root:staff /usr/local/lib/node_modules/\\n\\n3. 권한 변경\\n\\n    사용자가 해당 디렉터리 및 하위 디렉터리에 쓰기 권한을 가지도록 설정한다.\\n\\n        sudo chmod -R 775 /usr/local/lib/node_modules/\\n\\n4. Flowise 실행\\n\\n    다시 `npx flowise start`를 실행한다.\\n    \\n5. 만약 동일한 문제가 발생하면 아래와 같이 권한을 추가로 설정한 뒤,\\n\\n        sudo chmod -R 777 /usr/local/lib/node_modules/flowise/logs\\n\\n    다시 실행한다.\\n\\n        npx flowise start\\n\\n### 추가 팁\\n\\n권한 문제를 완전히 피하려면 npm의 전역 설치 경로를 사용자 전용 디렉터리로 변경하는 것도 좋다.\\n\\n## 참고\\n\\n- <https://stackoverflow.com/questions/49679808/error-eacces-permission-denied-mkdir-usr-local-lib-node-modules-node-sass-b>\"),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content='## 증상\\n\\n```\\n(base) yong@MacBookPro ~ % npx flowise start\\n2024-11-27 19:57:27 [INFO]: Starting Flowise...\\n(node:77686) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\\n(Use `node --trace-deprecation ...` to show where the warning was created)\\n2024-11-27 19:57:27 [INFO]: 📦 [server]: Data Source is initializing...\\nMigration \"AddFeedback1707213619308\" failed, error: SQLITE_READONLY: attempt to write a readonly database\\n2024-11-27 19:57:27 [ERROR]: ❌ [server]: Error during Data Source initialization: SQLITE_READONLY: attempt to write a readonly database\\nQueryFailedError: SQLITE_READONLY: attempt to write a readonly database\\n    at Statement.handler (/usr/local/lib/node_modules/flowise/node_modules/typeorm/driver/sqlite/SqliteQueryRunner.js:88:37)\\n    at Statement.replacement (/usr/local/lib/node_modules/flowise/node_modules/sqlite3/lib/trace.js:25:27)\\n    at Statement.replacement (/usr/local/lib/node_modules/flowise/node_modules/sqlite3/lib/trace.js:25:27)\\n2024-11-27 19:57:27 [INFO]: ⚡️ [server]: Flowise Server is listening at :3000\\n```\\n\\n## 해결\\n\\n`SQLITE_READONLY: attempt to write a readonly database` 오류는 SQLite 데이터베이스 파일이 읽기 전용 권한으로 설정되어 있어 Flowise가 데이터베이스에 쓰기를 시도할 때 발생한다. 이를 해결하려면 데이터베이스 파일의 권한을 수정하거나 올바른 설정을 확인해야 한다.\\n\\n1. Flowise 데이터베이스 파일 경로 확인\\n\\n    Flowise는 기본적으로 SQLite 데이터베이스를 사용한다. 데이터베이스 파일이 있는 디렉터리를 찾아야 한다. Flowise는 `DATABASE_PATH` 환경 변수에 지정된 경로에서 데이터베이스 파일을 찾으며, 해당 환경 변수가 설정돼 있지 않으면 홈 디렉터리 아래의 `.flowise` 아래에 위치한다.\\n\\n    데이터베이스 파일의 위치를 확인하려면 아래 명령을 사용한다.\\n\\n        ls -l ~/.flowise\\n\\n    SQLite 데이터베이스 파일 이름은 `database.sqlite` 또는 유사한 이름일 것이다.\\n\\n2. 데이터베이스 파일 권한 수정\\n\\n    파일이 읽기 전용으로 설정되어 있으면 권한을 수정한다.\\n\\n        sudo chmod 664 ~/.flowise/database.sqlite\\n\\n    Flowise가 실행될 때 사용할 디렉터리에도 쓰기 권한이 있어야 하므로 디렉터리 권한도 수정한다.\\n\\n        sudo chmod -R 775 ~/.flowise\\n\\n3. 데이터베이스 소유자 변경\\n\\n    현재 사용자가 데이터베이스 파일에 접근할 수 있도록 소유자를 변경한다.\\n\\n        sudo chown $(whoami):staff ~/.flowise/database.sqlite\\n\\n    여기서 staff는 기본 그룹 이름이며, macOS에서는 일반적으로 사용자 그룹으로 설정된다. 만약 다른 그룹을 사용 중이라면 해당 그룹 이름으로 변경하라.\\n\\n위 단계를 순서대로 진행한 후 다시 Flowise를 실행해 본다.\\n\\n[[TIP]]\\n**Flowise를 다른 디렉터리에 재설치**\\n\\n전역 설치 경로(/usr/local/lib)에서 권한 문제가 계속 발생한다면, Flowise를 사용자 디렉터리 내에 설치하는 방법도 있다.\\n\\n    npm config set prefix \\'~/.npm-global\\'\\n    npm install -g flowise\\n    npx flowise start\\n    \\n[[/TIP]]\\n'),\n Document(metadata={'id': 267507, 'source': 'https://wikidocs.net/267507', 'title': 'Flowise 채팅 시 화면이 하얗게 되는 문제 해결'}, page_content='## 증상\\n\\nmacOS에 설치한 Flowise 1.X 버전에서 Chatflow를 작성하고 채팅을 시작하면 화면이 하얗게 됨.\\n\\n## 해결\\n\\nFlowise 최신 버전(2.1.X)로 재설치\\n\\n## 참고\\n\\n- <https://github.com/FlowiseAI/Flowise/issues/3478>\\n- <https://github.com/FlowiseAI/Flowise/issues/3557>'),\n Document(metadata={'id': 267504, 'source': 'https://wikidocs.net/267504', 'title': 'macOS에 Flowise 설치 시 npm error code EEXIST 및 EACCES: permission denied 오류 발생'}, page_content=\"## 증상\\n\\nmacOS에서 Flowise 설치 시 다음 오류 발생:\\n\\n```\\n(base) yong@MacBookPro ~ % node -v\\nv22.11.0\\n(base) yong@MacBookPro ~ % npm install -g flowise\\n...\\nnpm error code EEXIST\\nnpm error syscall rename\\nnpm error path /Users/yong/.npm/_cacache/tmp/36e62795\\nnpm error dest /Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b\\nnpm error errno EEXIST\\nnpm error Invalid response body while trying to fetch https://registry.npmjs.org/@oclif%2fcore: EACCES: permission denied, rename '/Users/yong/.npm/_cacache/tmp/36e62795' -> '/Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b'\\nnpm error File exists: /Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b\\nnpm error Remove the existing file and try again, or run npm\\nnpm error with --force to overwrite files recklessly.\\n...\\n```\\n\\n## 해결\\n\\n캐시 삭제 후 다시 설치 시도.\\n\\n```\\nsudo npm cache clean --force\\nsudo npm install -g flowise\\n```\\n\"),\n Document(metadata={'id': 267505, 'source': 'https://wikidocs.net/267505', 'title': \"macOS에서 Flowise 실행 시 ModuleLoadError: [MODULE_NOT_FOUND] require failed to load ... Cannot find module 'langchainhub'오류\"}, page_content=\"## 증상\\n\\n```\\n% sudo npx flowise start\\nPassword:\\n ›   ModuleLoadError: [MODULE_NOT_FOUND] require failed to load /usr/local/lib/node_modules/flowise/dist/commands/start.js: Cannot \\n ›   find module 'langchainhub'\\n ›   Require stack:\\n ›   - /usr/local/lib/node_modules/flowise/dist/index.js\\n ›   - /usr/local/lib/node_modules/flowise/dist/commands/start.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/module-loader.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/plugin.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/config.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/index.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/command.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/index.js\\n ›   - /usr/local/lib/node_modules/flowise/bin/run\\n ›   Code: MODULE_NOT_FOUND\\n```\\n\\n## 해결\\n\\n다음 명령으로 랭체인허브 설치 후 Flowise 실행.\\n\\n```\\nnpm i -g langchainhub\\n```\\n\\n(만약 위 명령 실행 시 `npm error code EACCES` 오류 발생하면 다음을 참고: <https://wikidocs.net/267506>)\\n\\n## 참고\\n\\n- <https://github.com/FlowiseAI/Flowise/issues/2390#issuecomment-2385029705>\"),\n Document(metadata={'id': 256103, 'source': 'https://wikidocs.net/256103', 'title': '4. 기타'}, page_content='.'),\n Document(metadata={'id': 256709, 'source': 'https://wikidocs.net/256709', 'title': 'ERROR: No matching distribution found for azure-ai-vision'}, page_content='## 증상\\n\\n`pip install azure-ai-vision` 명령을 실행하면 다음 오류가 발생\\n\\n```\\nERROR: Ignored the following yanked versions: 0.8.0a1, 0.8.0b0.dev33537970, 0.8.1b1, 0.9.0b1, 0.10.0b1, 0.11.1b1, 0.13.0b1, 0.15.1b1\\nERROR: Could not find a version that satisfies the requirement azure-ai-vision (from versions: none)\\nERROR: No matching distribution found for azure-ai-vision\\n```\\n\\n## 해결\\n\\n<https://pypi.org/project/azure-ai-vision/#files>에서 whl 파일을 다운로드해서 설치\\n\\n```\\npip install azure_ai_vision-0.15.1b1-py3-none-win_amd64.whl\\n```\\n\\n## 참고\\n\\n- <https://learn.microsoft.com/en-us/answers/questions/1511970/error-occurred-while-trying-to-install-ai-vision-l>'),\n Document(metadata={'id': 256104, 'source': 'https://wikidocs.net/256104', 'title': \"ImportError: cannot import name 'ExtraValues' from 'pydantic.config'\"}, page_content='## 증상\\n\\n노트북에서 codeinterpreterapi를 설치한 후,\\n\\n```\\n!pip install -q codeinterpreterapi\\n```\\n\\n다음 명령을 실행하면,\\n\\n```\\nfrom codeinterpreterapi import CodeInterpreterSession\\n```\\n\\n다음 오류가 발생:\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeinterpreterapi\\\\__init__.py\", line 4, in <module>\\n    from codeinterpreterapi.schema import File\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeinterpreterapi\\\\schema.py\", line 4, in <module>\\n    from codeboxapi.schema import CodeBoxStatus\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\__init__.py\", line 8, in <module>\\n    from codeboxapi.box.codebox import CodeBox\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\__init__.py\", line 9, in <module>\\n    from .codebox import CodeBox\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\codebox.py\", line 44, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\config.py\", line 9, in <module>\\n    from pydantic_settings import BaseSettings\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic_settings\\\\__init__.py\", line 1, in <module>\\n    from .main import BaseSettings, SettingsConfigDict\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic_settings\\\\main.py\", line 7, in <module>\\n    from pydantic._internal._config import config_keys\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_config.py\", line 19, in <module>\\n    from ..config import ConfigDict, ExtraValues, JsonDict, JsonEncoder, JsonSchemaExtraCallable   \\nImportError: cannot import name \\'ExtraValues\\' from \\'pydantic.config\\' (C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic\\\\config.cp311-win_amd64.pyd)\\n```\\n\\n## 해결\\n\\n터미널에서 파이썬 셸을 새로 열어 다음을 실행해 본다.\\n\\n```\\n>>> import pydantic.config\\n>>> dir(pydantic.config)\\n```\\n\\n다음과 같이 결과에 `\\'ExtraValues\\'`가 포함돼 있다면,\\n\\n```\\n[\\'AliasGenerator\\', \\'Any\\', \\'Callable\\', \\'ConfigDict\\', \\'Dict\\', \\'ExtraValues\\', \\'JsonDict\\', \\'JsonEncoder\\', \\'JsonSchemaExtraCallable\\', \\'JsonValue\\', \\'List\\', \\'Literal\\', \\'PydanticUserError\\', \\'TYPE_CHECKING\\', \\'Type\\', \\'TypeAlias\\', \\'TypeVar\\', \\'TypedDict\\', \\'Union\\', \\'_TypeT\\', \\'__all__\\', \\'__annotations__\\', \\'__builtins__\\', \\'__cached__\\', \\'__doc__\\', \\'__file__\\', \\'__getattr__\\', \\'__loader__\\', \\'__name__\\', \\'__package__\\', \\'__spec__\\', \\'_annotations\\', \\'getattr_migration\\', \\'with_config\\']\\n```\\n\\n임포트를 실행하면 잘 될 것이다.\\n\\n```\\n>>> from pydantic.config import ExtraValues\\n```\\n\\n이런 경우에는 노트북의 커널을 재시작하면 해결될 가능성이 높다.'),\n Document(metadata={'id': 256113, 'source': 'https://wikidocs.net/256113', 'title': 'ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with: `pip install jupyter_kernel_gateway` to use the LocalBox.'}, page_content='## 증상\\n\\n```\\nfrom codeinterpreterapi import CodeInterpreterSession\\n\\nasync with CodeInterpreterSession() as session:\\n    # generate a response based on user input\\n    response = await session.generate_response(\\n        \"Generate a plot of the evolution of Covid-19 from March to June 2020, taking data from web.\"\\n    )\\n\\n    # output the response\\n    print(\"AI: \", response.content)\\n    for file in response.files:\\n        file.show_image()\\n        \\n```\\n\\n```\\n---------------------------------------------------------------------------\\nNotImplementedError                       Traceback (most recent call last)\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\localbox.py:180, in LocalBox.astart(self)\\n    179 try:\\n--> 180     self.jupyter = await asyncio.create_subprocess_exec(\\n    181         python,\\n    182         \"-m\",\\n    183         \"jupyter\",\\n    184         \"kernelgateway\",\\n    185         \"--KernelGatewayApp.ip=\\'0.0.0.0\\'\",\\n    186         f\"--KernelGatewayApp.port={self.port}\",\\n    187         stdout=out,\\n    188         stderr=out,\\n    189         cwd=\".codebox\",\\n    190     )\\n    191     self._jupyter_pids.append(self.jupyter.pid)\\n\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\asyncio\\\\subprocess.py:223, in create_subprocess_exec(program, stdin, stdout, stderr, limit, *args, **kwds)\\n    221 protocol_factory = lambda: SubprocessStreamProtocol(limit=limit,\\n    222                                                     loop=loop)\\n--> 223 transport, protocol = await loop.subprocess_exec(\\n    224     protocol_factory,\\n    225     program, *args,\\n    226     stdin=stdin, stdout=stdout,\\n    227     stderr=stderr, **kwds)\\n...\\n    200     try:\\n\\nModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with:\\n`pip install jupyter_kernel_gateway`\\nto use the LocalBox.\\n```\\n\\n## 원인\\n\\n미상.\\n\\n## 해결\\n\\n확인 중.'),\n Document(metadata={'id': 232562, 'source': 'https://wikidocs.net/232562', 'title': '위키북스의 생성 AI 프로그래밍 도서'}, page_content='위키북스에서 출간했거나 출간 예정인 생성 AI 프로그래밍 관련 도서 목록.\\n\\n## ChatGPT API×Python(가제)\\n\\n- 출간년월: 출간 예정\\n- 책에서 기준으로 삼은 패키지 버전: openai==1.10.0 langchain==0.1.4 langchain-core==0.1.17 langchain-community==0.0.17\\n- 코드 저장소: <https://github.com/ychoi-kr/ChatGPT-API-Python>\\n\\n## 랭체인 완벽 입문\\n\\n- URL: <https://wikibook.co.kr/langchain/>\\n- 출간년월: 2024. 2.\\n- 책에서 기준으로 삼은 패키지 버전: openai==0.28 langchain==0.0.261\\n- 코드 저장소: <https://github.com/wikibook/langchain>\\n\\n## GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍 2쇄\\n\\n- URL: https://wikibook.co.kr/openai-llm/\\n- 출간년월: 2024. 1.\\n- 책에서 기준으로 삼은 패키지 버전: Python 3.10, llama-index==0.6.12 langchain==0.0.181 openai==0.28\\n- 코드 저장소: <https://github.com/wikibook/openai-llm>\\n\\n## GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍\\n\\n- URL: https://wikibook.co.kr/openai-llm/\\n- 출간년월: 2023. 9.\\n- 책에서 기준으로 삼은 패키지 버전: Python 3.10, llama-index==0.6.12 langchain==0.0.181 openai==0.28\\n- 코드 저장소: <https://github.com/wikibook/openai-llm>\\n\\n## 만들면서 배우는 나만의 인공지능 서비스\\n\\n- URL: https://wikibook.co.kr/pyai/\\n- 출간년월: 2023. 9.\\n- 책에서 기준으로 삼은 패키지 버전: openai==0.28.1\\n- 코드 저장소: <https://github.com/wikibook/pyai>')]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:21.582502Z",
     "start_time": "2025-02-28T08:31:21.575195Z"
    }
   },
   "id": "3e62fc43a0cd211c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1008, which is longer than the specified 600\n",
      "Created a chunk of size 622, which is longer than the specified 600\n",
      "Created a chunk of size 850, which is longer than the specified 600\n",
      "Created a chunk of size 744, which is longer than the specified 600\n",
      "Created a chunk of size 1247, which is longer than the specified 600\n",
      "Created a chunk of size 869, which is longer than the specified 600\n",
      "Created a chunk of size 681, which is longer than the specified 600\n",
      "Created a chunk of size 654, which is longer than the specified 600\n",
      "Created a chunk of size 1300, which is longer than the specified 600\n",
      "Created a chunk of size 1100, which is longer than the specified 600\n",
      "Created a chunk of size 1087, which is longer than the specified 600\n",
      "Created a chunk of size 947, which is longer than the specified 600\n",
      "Created a chunk of size 1854, which is longer than the specified 600\n",
      "Created a chunk of size 738, which is longer than the specified 600\n"
     ]
    }
   ],
   "source": [
    "# Create Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:33.973410Z",
     "start_time": "2025-02-28T08:31:33.733156Z"
    }
   },
   "id": "ae5bb868132ce38f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'id': 231844, 'source': 'https://wikidocs.net/231844', 'title': '1. OpenAI 관련 문제해결'}, page_content='OpenAI-Python 깃허브: <https://github.com/openai/openai-python>\\n\\n[파이썬 openai 패키지 릴리스 이력](https://pypi.org/project/openai/#history)\\n\\n마이그레이션 가이드:\\n\\n- OpenAI [v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)\\n- Azure [OpenAI Python API 라이브러리 1.x로 마이그레이션](https://learn.microsoft.com/ko-kr/azure/ai-services/openai/how-to/migration?tabs=python-new%2Cdalle-fix)'),\n Document(metadata={'id': 239781, 'source': 'https://wikidocs.net/239781', 'title': '1.1. OpenAI 관련 기본적인 문제 해결'}, page_content='.'),\n Document(metadata={'id': 231848, 'source': 'https://wikidocs.net/231848', 'title': \"ImportError: cannot import name 'OpenAI' from 'openai'\"}, page_content=\"## 문제\\n\\nopenai==0.28을 설치한 채로 다음을 실행하면,\\n\\n```python\\nfrom openai import OpenAI\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nImportError: cannot import name 'OpenAI' from 'openai'\\n```\\n\\n## 해결\\n\\n[최신 버전을 설치](229554#installing-latest-openai-package)해 해결한다.\\n\\n## 참고\\n\\n- <https://community.openai.com/t/cannot-import-name-openai-from-openai/486147>\"),\n Document(metadata={'id': 231849, 'source': 'https://wikidocs.net/231849', 'title': \"TypeError: 'Choice' object is not subscriptable\"}, page_content='## 문제\\n\\nopenai>=1.0.0을 설치한 채로 응답 객체를 구버전에서처럼 딕셔너리로 처리하려고 하면,\\n\\n```\\nprint(response.choices[0][\"message\"][\"content\"])\\n```\\n\\n다음과 같은 오류가 발생한다.\\n\\n```\\n>>> print(response.choices[0][\"message\"][\"content\"])\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: \\'Choice\\' object is not subscriptable\\n```\\n\\n## 설명\\n\\nopenai>=1.0.0에서 응답 객체는 딕셔너리 형태가 아닌 [Pydantic 모델](https://docs.pydantic.dev/latest/concepts/models/)로 반환된다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.'),\n Document(metadata={'id': 231849, 'source': 'https://wikidocs.net/231849', 'title': \"TypeError: 'Choice' object is not subscriptable\"}, page_content='### 옵션 2: 코드를 수정\\n\\n코드를 다음과 같이 수정한다.\\n\\n```\\nprint(response.choices[0].[[MARK]]message.content[[/MARK]])\\n```'),\n Document(metadata={'id': 267225, 'source': 'https://wikidocs.net/267225', 'title': \"TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given\"}, page_content='## 증상\\n\\n다음 코드를 실행하면,\\n\\n```\\nimport openai\\n\\nopenai.api_key = \\'your-api-key\\'\\n\\nresponse = openai.chat.completions.create(\\n    engine=\"text-davinci-003\",\\n    prompt=\"Hello.\",\\n    max_tokens=100\\n)\\n\\nprint(response.choices[0].text)\\n```\\n\\n다음 오류가 발생\\n```\\nTypeError: Missing required arguments; Expected either (\\'model\\' and \\'prompt\\') or (\\'model\\', \\'prompt\\' and \\'stream\\') arguments to be given\\n```\\n\\n## 설명\\n\\nChat Endpoint는 deprecate되었으며 Python openai 패키지 사용법도 바뀌었음. 또한 text-davinci-003 모델도 deprecate됨.\\n\\n## 해결\\n\\n다음 코드를 사용.\\n\\n```\\nfrom openai import OpenAI\\nclient = OpenAI()'),\n Document(metadata={'id': 267225, 'source': 'https://wikidocs.net/267225', 'title': \"TypeError: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given\"}, page_content='completion = client.chat.completions.create(\\n  model=\"gpt-4o-mini\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n    {\"role\": \"user\", \"content\": \"Hello!\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message)\\n```\\n\\n## 참고\\n\\n- <https://community.openai.com/t/typeerror-missing-required-arguments-expected-either-messages-and-model-or-messages-model-and-stream-arguments-to-be-given/601646>'),\n Document(metadata={'id': 231846, 'source': 'https://wikidocs.net/231846', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.ChatCompletion)'}, page_content='## 문제\\n\\n다음 코드는 openai==0.28에서 문제 없이 작동한다.\\n\\n```\\nimport os\\nimport openai\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nresponse = openai.ChatCompletion.create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n그런데 openai>=1.0.0으로 위의 코드를 실행하면 다음과 같은 오류가 난다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\lib\\\\_old_api.py\", line 39, in __call__\\n    raise APIRemovedInV1(symbol=self._symbol)\\nopenai.lib._old_api.APIRemovedInV1:'),\n Document(metadata={'id': 231846, 'source': 'https://wikidocs.net/231846', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.ChatCompletion)'}, page_content='You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface.\\n\\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\\n\\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\\n```\\n\\n## 설명\\n\\n`openai.ChatCompletion`은 openai>=1.0.0에서 지원되지 않는다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 한 가지를 선택한다.\\n\\n### 옵션 1: 구버전 설치'),\n Document(metadata={'id': 231846, 'source': 'https://wikidocs.net/231846', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.ChatCompletion)'}, page_content='다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 신버전의 패키지를 사용하고 코드 수정\\n\\nopenai>=1.0.0에서는 일단 다음과 같이 수정하면 오류나 경고가 뜨지 않고 잘 실행된다.\\n\\n```python\\nimport os\\nimport openai\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nresponse = openai.[[MARK]]chat.completions[[/MARK]].create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n[v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)에는 다음과 같이 하라고 안내되어 있다.'),\n Document(metadata={'id': 231846, 'source': 'https://wikidocs.net/231846', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.ChatCompletion)'}, page_content='```python\\nimport os\\n[[MARK]]from openai import OpenAI[[/MARK]]\\n\\n[[MARK]]client = OpenAI(\\n    api_key = os.environ[\"OPENAI_API_KEY\"]  # 생략 가능\\n)[[/MARK]]\\n\\nresponse = [[MARK]]client.chat.completions[[/MARK]].create(\\n    model=\"gpt-3.5-turbo\",\\n    messages=[\\n        {\"role\": \"user\", \"content\": \"hello\"},\\n    ],\\n)\\n```\\n\\n## 참고\\n\\n- [v1.0.0 Migration Guide](https://github.com/openai/openai-python/discussions/742)'),\n Document(metadata={'id': 229554, 'source': 'https://wikidocs.net/229554', 'title': '파이썬 OpenAI 패키지 버전 확인 및 재설치'}, page_content='## 설치된 버전 확인\\n\\nopenai 패키지를 이미 설치한 경우, 버전을 확인하려면 `pip list` 명령을 실행해 결과에서 openai의 버전을 확인한다.\\n\\n<a name=\"installing-openai-0.28\"></a>\\n\\n## 구버전(0.28)으로 고정\\n\\n2024년 1월 모델 종료와 관련해 구버전으로 고정하려면 아래 명령으로 (재)설치한다.\\n\\n```\\npip install -U openai==0.28\\n```\\n\\n<a name=\"installing-latest-openai-package\"></a>\\n\\n## 최신 버전 설치\\n\\n최신 버전으로 (재)설치하려면 아래 명령을 실행한다.\\n\\n```\\npip install -U openai\\n```'),\n Document(metadata={'id': 232051, 'source': 'https://wikidocs.net/232051', 'title': '1.2. OpenAI 임베딩 관련'}, page_content='.'),\n Document(metadata={'id': 231863, 'source': 'https://wikidocs.net/231863', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (distances_from_embeddings)\"}, page_content='## 문제\\n\\nopenai>=1.0.0에서 다음 코드를 실행하면,\\n\\n```\\nfrom openai.embeddings_utils import distances_from_embeddings\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nModuleNotFoundError: No module named \\'openai.embeddings_utils\\'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 embeddings_utils가 삭제됨\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 코드를 수정\\n\\n문제를 일으키는 임포트문을 제거하고, `distances_from_embeddings` 함수를 다음과 같이 코드에 삽입한다.'),\n Document(metadata={'id': 231863, 'source': 'https://wikidocs.net/231863', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (distances_from_embeddings)\"}, page_content='```\\ndef distances_from_embeddings(\\n    query_embedding: List[float],\\n    embeddings: List[List[float]],\\n    distance_metric=\"cosine\",\\n) -> List[List]:\\n    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\\n    distance_metrics = {\\n        \"cosine\": spatial.distance.cosine,\\n        \"L1\": spatial.distance.cityblock,\\n        \"L2\": spatial.distance.euclidean,\\n        \"Linf\": spatial.distance.chebyshev,\\n    }\\n    distances = [\\n        distance_metrics[distance_metric](query_embedding, embedding)\\n        for embedding in embeddings\\n    ]\\n    return distances\\n```\\n\\n## 참고'),\n Document(metadata={'id': 231863, 'source': 'https://wikidocs.net/231863', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (distances_from_embeddings)\"}, page_content='- <https://stackoverflow.com/a/77645783>\\n- <https://community.openai.com/t/embeddings-utils-distance-formulas-where-did-it-move/479868/7>'),\n Document(metadata={'id': 231864, 'source': 'https://wikidocs.net/231864', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (get_embedding)\"}, page_content='## 문제\\n\\nopenai>=1.0.0에서 다음 코드를 실행하면,\\n\\n```\\nfrom openai.embeddings_utils import get_embedding\\n```\\n\\n다음 오류가 발생한다.\\n\\n```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nModuleNotFoundError: No module named \\'openai.embeddings_utils\\'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 embeddings_utils가 삭제됨\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 코드를 수정\\n\\n문제를 일으키는 임포트문을 제거하고, `get_embedding` 함수를 다음과 같이 코드에 삽입한다.\\n\\n```\\nfrom openai import OpenAI\\n\\nclient = OpenAI()'),\n Document(metadata={'id': 231864, 'source': 'https://wikidocs.net/231864', 'title': \"ModuleNotFoundError: No module named 'openai.embeddings_utils' (get_embedding)\"}, page_content='def get_embedding(text, model=\"text-embedding-ada-002\"):\\n   text = text.replace(\"\\\\n\", \" \")\\n   return client.embeddings.create(input = [text], model=model).data[0].embedding\\n```\\n\\n## 참고\\n\\n- <https://stackoverflow.com/a/77645783>\\n- <https://community.openai.com/t/embeddings-utils-distance-formulas-where-did-it-move/479868/7>'),\n Document(metadata={'id': 232698, 'source': 'https://wikidocs.net/232698', 'title': 'ValidationError: 1 validation error for OpenAIEmbeddings'}, page_content='## 문제\\n\\n```\\nValidationError: 1 validation error for OpenAIEmbeddings\\n__root__\\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)\\n```\\n\\n## 설명\\n\\nopenai_api_key를 찾지 못함.\\n\\n## 해결\\n\\n`OPENAI_API_KEY` 환경변수를 등록하거나, 명명된 매개변수로 `openai_api_key`를 전달해서 호출'),\n Document(metadata={'id': 231865, 'source': 'https://wikidocs.net/231865', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.Embedding)'}, page_content=\"## 문제\\n\\nopenai>=1.0.0을 설치하고 다음 코드를 실행하면,\\n\\n```\\nq_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\\n```\\n\\n다음 오류가 발생한다.\"),\n Document(metadata={'id': 231865, 'source': 'https://wikidocs.net/231865', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.Embedding)'}, page_content='```\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\app.py\", line 21, in <module>\\n    answer = answer_question(user_input, conversation_history)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\search.py\", line 49, in answer_question\\n    context = create_context(question, df, max_len=200)  #←질문과 학습 데이터를 비교해 컨텍스트 생성\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\chatbot\\\\search.py\", line 14, in create_context\\n    q_embeddings = openai.Embedding.create(input=question, engine=\\'text-embedding-ada-002\\')[\\'data\\'][0][\\'embedding\\']\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\lib\\\\_old_api.py\", line 39, in __call__\\n    raise APIRemovedInV1(symbol=self._symbol)\\nopenai.lib._old_api.APIRemovedInV1:'),\n Document(metadata={'id': 231865, 'source': 'https://wikidocs.net/231865', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.Embedding)'}, page_content='You tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\\n\\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface.\\n\\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\\n\\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\\n```\\n\\n## 설명\\n\\n`openai.Embedding`은 openai>=1.0.0에서 지원되지 않는다.\\n\\n## 해결\\n\\n다음 두 가지 방법 중 한 가지를 선택한다.\\n\\n### 옵션 1: 구버전 설치'),\n Document(metadata={'id': 231865, 'source': 'https://wikidocs.net/231865', 'title': 'openai.lib._old_api.APIRemovedInV1 (openai.Embedding)'}, page_content=\"다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n코드를 다시 실행하면 잘 실행될 것이다.\\n\\n### 옵션 2: 신버전의 패키지를 사용하고 코드 수정\\n\\nopenai>=1.0.0을 그대로 사용하고 코드를 다음과 같이 수정한다.\\n\\n```python\\nq_embeddings = [[MARK]]client.embeddings[[/MARK]].create(input=[question], [[MARK]]model='text-embedding-3-small'[[/MARK]]).[[MARK]]data[0].embedding[[/MARK]]\\n```\"),\n Document(metadata={'id': 232048, 'source': 'https://wikidocs.net/232048', 'title': '1.3. OpenAI Whisper 관련'}, page_content='- [파이썬 openai-whisper 패키지 릴리스 이력](https://pypi.org/project/openai-whisper/#history)'),\n Document(metadata={'id': 232049, 'source': 'https://wikidocs.net/232049', 'title': \"AttributeError: 'Audio' object has no attribute 'transcribe'\"}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```python\\nimport openai\\nimport os\\n\\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = client.audio.transcribe(\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n다음 오류가 발생한다.'),\n Document(metadata={'id': 232049, 'source': 'https://wikidocs.net/232049', 'title': \"AttributeError: 'Audio' object has no attribute 'transcribe'\"}, page_content='```\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\yong\\\\OneDrive\\\\바탕 화면\\\\python_chatgpt\\\\whisper\\\\srt_old.py\", line 8, in <module>\\n    transcript = openai.audio.transcribe(\\n                 ^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\openai\\\\_utils\\\\_proxy.py\", line 23, in __getattr__\\n    return getattr(proxied, attr)\\n           ^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: \\'Audio\\' object has no attribute \\'transcribe\\'\\n```\\n\\n## 해결\\n\\n다음과 같이 코드를 수정하면 오류가 발생하지 않는다.\\n\\n```python\\nimport openai\\nimport os'),\n Document(metadata={'id': 232049, 'source': 'https://wikidocs.net/232049', 'title': \"AttributeError: 'Audio' object has no attribute 'transcribe'\"}, page_content='openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n[[MARK]]client = openai.OpenAI()[[/MARK]]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = [[MARK]]client.audio.transcriptions.create[[/MARK]](\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n또한 다음 코드가 더 신식이다.\\n\\n```python\\n[[MARK]]from openai import OpenAI\\nclient = OpenAI()[[/MARK]]\\n\\nfile = open(\"sample.wav\", \"rb\")\\n\\ntranscript = client.audio.transcriptions.create(\\n    model=\"whisper-1\",\\n    file=file,\\n    response_format=\"srt\"\\n)\\n```\\n\\n`OPENAI_API_KEY`를 환경변수에 저장하는 것이 디폴트이므로 생략한다.'),\n Document(metadata={'id': 232568, 'source': 'https://wikidocs.net/232568', 'title': \"AttributeError: 'str' object has no attribute 'text'\"}, page_content='## 문제\\n\\n`audio.transcriptions.create()`의 `response_format` 인자를 `\"srt\"` 등으로 지정할 경우, 결괏값의 `.text`에 접근하려고 하면 `AttributeError: \\'str\\' object has no attribute \\'text\\'` 오류 발생\\n\\n## 설명\\n\\n이 오류의 주된 원인은 `create` 함수 호출 결과가 문자열(str)을 반환하는데, 코드가 이 반환값에 `.text` 속성을 접근하려고 시도하기 때문이다. 이 함수가 직접적으로 텍스트를 반환한다면, `.text` 속성 접근 대신 반환된 문자열을 직접 사용해야 한다.\\n\\n## 해결\\n\\n`response_format=\"srt\"`를 지정할 경우 `.text` 속성 접근 대신 반환된 문자열을 직접 사용한다.\\n\\n예를 들어, `return transcript.text`를 `return transcript`로 수정한다.'),\n Document(metadata={'id': 239780, 'source': 'https://wikidocs.net/239780', 'title': '1.4. GPT-4o 관련'}, page_content='.'),\n Document(metadata={'id': 239779, 'source': 'https://wikidocs.net/239779', 'title': \"KeyError: 'Could not automatically map gpt-4o to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'\"}, page_content=\"## 증상\\n\\n```\\nKeyError: 'Could not automatically map gpt-4o to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'\\n```\\n\\n## 해결\\n\\n```\\npip install -U tiktoken\\n```\"),\n Document(metadata={'id': 232052, 'source': 'https://wikidocs.net/232052', 'title': '1.5. 그 밖의 OpenAI 관련 문제'}, page_content='.'),\n Document(metadata={'id': 231380, 'source': 'https://wikidocs.net/231380', 'title': \"ImportError: cannot import name 'BaseTransport' from 'httpx'\"}, page_content=\"## 문제\\n\\nopenai>=1.0.0과 googletrans 패키지를 함께 사용하는 경우 이 오류가 발생할 수 있다.\\n\\n```\\nImportError: cannot import name 'BaseTransport' from 'httpx'\\n```\\n\\n## 설명\\n\\nopenai 패키지에서 사용하는 httpx 버전과 googletrans 에서 사용하는 httpx 버전이 맞지 않아서 발생하는 문제다.\\n\\n## 해결\\n\\n다음 두 가지 옵션 중 하나를 선택한다.\\n\\n### 옵션 1: 구버전 설치\\n\\ngoogletrans 패키지를 꼭 써야 하거나, 2023년까지의 자료를 바탕으로 실습할 때는 이 방법을 택하는 것이 좋을 것이다.\\n\\n다음을 참조해 openai==0.28로 다운그레이드한다.  \\n<https://wikidocs.net/229554#installing-openai-0.28>\\n\\n\\n### 옵션 2: googletrans 패키지를 삭제하고 httpx 재설치\\n\\n굳이 googletrans 패키지를 사용할 필요가 없다면 삭제한다.\\n\\n```\\npip uninstall googletrans\\n```\\n\\nhttpx 패키지를 높은 버전으로 재설치한다.\"),\n Document(metadata={'id': 231380, 'source': 'https://wikidocs.net/231380', 'title': \"ImportError: cannot import name 'BaseTransport' from 'httpx'\"}, page_content='```\\npip install -U httpx\\n```\\n\\n## 참고\\n\\n- <https://www.inflearn.com/questions/1139993/ch07-실습에-필요한-패키지-설치-시-오류가-납니다>'),\n Document(metadata={'id': 231845, 'source': 'https://wikidocs.net/231845', 'title': '2. LangChain'}, page_content='LangChain 문서: <https://python.langchain.com/docs/get_started/introduction>\\n\\nLangChain 레거시(v0.0.354) 레퍼런스 매뉴얼:  \\n[langchain 0.0.354](https://api.python.langchain.com/en/v0.0.354/langchain_api_reference.html)\\n\\n최신 레퍼런스 매뉴얼 및 소스 코드:'),\n Document(metadata={'id': 231845, 'source': 'https://wikidocs.net/231845', 'title': '2. LangChain'}, page_content='| 패키지 | 레퍼런스 매뉴얼 | 소스 코드 |\\n| --- | --- | --- |\\n| langchain-core | [레퍼런스](https://api.python.langchain.com/en/latest/core_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/core/langchain_core) |\\n| langchain-community | [레퍼런스](https://api.python.langchain.com/en/latest/community_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community) |\\n| langchain | [레퍼런스](https://api.python.langchain.com/en/latest/langchain_api_reference.html) | [소스 코드](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain)'),\n Document(metadata={'id': 231845, 'source': 'https://wikidocs.net/231845', 'title': '2. LangChain'}, page_content='LangChain 프레임워크 개요:\\n\\n![](https://wikidocs.net/images/page/231845/LangChain-Framework-Overview.png)  \\n(이미지 출처: <https://python.langchain.com/docs/get_started/introduction>)\\n\\n패키지 릴리스 이력:\\n\\n- [파이썬 langchain 패키지 릴리스 이력](https://pypi.org/project/langchain/#history)\\n- [파이썬 langchain-community 패키지 릴리스 이력](https://pypi.org/project/langchain-community/#history)\\n- [파이썬 langchain-core 패키지 릴리스 이력](https://pypi.org/project/langchain-core/#history)'),\n Document(metadata={'id': 267523, 'source': 'https://wikidocs.net/267523', 'title': '2.1 LangChain'}, page_content='.'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='## 증상\\n\\n다음 패키지를 사용해,\\n\\n```\\nlangchain                                0.2.13\\nlangchain-community                      0.2.5\\nlangchain-core                           0.2.30\\nlangchain-openai                         0.1.21\\nlangchainhub                             0.1.14\\n```\\n\\n다음 코드 실행 시,\\n\\n```\\nfrom langchain.agents import create_sql_agent\\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.chat_models import ChatOpenAI\\n\\nllm = ChatOpenAI()'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='db = SQLDatabase.from_uri(\\'sqlite:///chinook.db\\')\\n\\ntoolkit = SQLDatabaseToolkit(db=db, llm=llm)\\nagent_executor = create_sql_agent(\\n    llm=llm,\\n    toolkit=toolkit,\\n    verbose=True,\\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\n)\\n\\n[[MARK]]print(agent_executor.agent.llm_chain.prompt.template)[[/MARK]]\\n```\\n\\n다음 오류가 발생:\\n\\n```\\nAttributeError: \\'RunnableAgent\\' object has no attribute \\'llm_chain\\'\\n```\\n\\n## 해결\\n\\n```python\\nfrom langchain.agents import create_sql_agent\\nfrom langchain.sql_database import SQLDatabase\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\"gpt-4o-mini\")'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='db = SQLDatabase.from_uri(\\'sqlite:///chinook.db\\')\\n\\nagent_executor = create_sql_agent(\\n    llm=llm,\\n    db=db,\\n    agent_type=\"tool-calling\",\\n    verbose=True,    \\n)\\n\\n[[MARK]]print(agent_executor.agent.runnable.steps[1].messages[0].content)[[/MARK]]\\n```\\n\\n결과:'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='```.plaintext\\nYou are an agent designed to interact with a SQL database.\\nGiven an input question, create a syntactically correct sqlite query to run, then look at the results of the query and return the answer.\\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 10 results.\\nYou can order the results by a relevant column to return the most interesting examples in the database.\\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\\nYou have access to tools for interacting with the database.\\nOnly use the below tools. Only use the information returned by the below tools to construct your final answer.\\nYou MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.'),\n Document(metadata={'id': 255340, 'source': 'https://wikidocs.net/255340', 'title': \"AttributeError: 'RunnableAgent' object has no attribute 'llm_chain'\"}, page_content='DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\nIf the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n```'),\n Document(metadata={'id': 256096, 'source': 'https://wikidocs.net/256096', 'title': \"ImportError: cannot import name 'PythonREPL' from 'langchain.python'\"}, page_content='## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain.python import PythonREPL\\n```\\n\\n다음 오류가 발생:\\n\\n```\\n---------------------------------------------------------------------------\\nImportError                               Traceback (most recent call last)\\nCell In[2], line 4\\n      1 from langchain_experimental.agents.agent_toolkits import create_python_agent\\n      2 from langchain_experimental.tools.python.tool import PythonREPLTool\\n----> 4 from langchain.python import PythonREPL\\n      5 from langchain.llms.openai import OpenAI\\n      6 from langchain.agents.agent_types import AgentType'),\n Document(metadata={'id': 256096, 'source': 'https://wikidocs.net/256096', 'title': \"ImportError: cannot import name 'PythonREPL' from 'langchain.python'\"}, page_content=\"ImportError: cannot import name 'PythonREPL' from 'langchain.python' (c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\python.py)\\n```\\n\\n## 해결\\n\\n```\\n! pip install langchain_experimental\\n```\\n\\n```\\nfrom langchain_experimental.utilities import PythonREPL\\n```\"),\n Document(metadata={'id': 254474, 'source': 'https://wikidocs.net/254474', 'title': 'LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.'}, page_content='## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain import PromptTemplate, OpenAI, LLMChain\\n\\ntemplate = \"\"\"문장: {sentence}\\n{language}로 번역:\"\"\"\\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\\n\\nllm = OpenAI(temperature=0)\\n\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n\\nllm_chain.predict(sentence=\"탁자 위에 고양이가 있어요\", language=\"영어\")\\n```\\n\\n다음 경고가 발생함.'),\n Document(metadata={'id': 254474, 'source': 'https://wikidocs.net/254474', 'title': 'LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.'}, page_content='```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\\n  warn_deprecated(\\n```\\n\\n## 해결\\n\\nLCEL을 사용.\\n\\n```\\nfrom langchain import PromptTemplate, OpenAI\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableSequence, RunnablePassthrough'),\n Document(metadata={'id': 254474, 'source': 'https://wikidocs.net/254474', 'title': 'LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.'}, page_content='template = \"\"\"문장: {sentence}\\n{language}로 번역:\"\"\"\\nprompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\\n\\nllm = OpenAI(temperature=0)\\n\\noutput_parser = StrOutputParser()\\n\\nchain = RunnableSequence(\\n    {\\n        \"sentence\": RunnablePassthrough(),\\n        \"language\": RunnablePassthrough()\\n    }\\n    | prompt\\n    | llm\\n    | output_parser\\n)\\n\\nresult = chain.invoke({\\n    \"sentence\": \"탁자 위에 고양이가 있어요\",\\n    \"language\": \"영어\"\\n})\\nprint(result)\\n```'),\n Document(metadata={'id': 232743, 'source': 'https://wikidocs.net/232743', 'title': 'LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_community.chat_models import ChatOpenAI\\n\\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\nLangChainDeprecationWarning이 발생.'),\n Document(metadata={'id': 232743, 'source': 'https://wikidocs.net/232743', 'title': 'LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\\n```\\n\\n## 해결\\n\\n`langchain-openai` 패키지를 설치하고,\\n\\n```\\npip install -U langchain-openai\\n```\\n\\n코드를 다음과 같이 수정.\\n\\n```\\nfrom langchain_openai import ChatOpenAI'),\n Document(metadata={'id': 232743, 'source': 'https://wikidocs.net/232743', 'title': 'LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```'),\n Document(metadata={'id': 231843, 'source': 'https://wikidocs.net/231843', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_community.llms import OpenAI\\nopenai = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\\n```\\n\\n다음과 같은 오류가 난다.'),\n Document(metadata={'id': 231843, 'source': 'https://wikidocs.net/231843', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\\n  warn_deprecated(\\n```\\n\\n## 설명'),\n Document(metadata={'id': 231843, 'source': 'https://wikidocs.net/231843', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0.'}, page_content='`langchain_community.llms.openai.OpenAI`는 langchain-community 0.0.10에서 deprecate되었으며 0.2.0에서 제거될 예정이다. 업데이트된 버전의 클래스가 langchain-openai 패키지에 있으며 이것을 사용해야 한다.\\n\\n## 해결 방법\\n\\n명령 프롬프트(또는 터미널)에서 다음 명령을 실행해 langchain-openai 패키지를 설치하고,\\n\\n```bash\\npip install -U langchain-openai\\n```\\n\\n임포트문을 다음과 같이 바꾼다.\\n\\n```python\\nfrom langchain_openai import OpenAI\\n```'),\n Document(metadata={'id': 233334, 'source': 'https://wikidocs.net/233334', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. 및 LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.'}, page_content='## 현상\\n\\n다음 패키지를 설치하고,\\n\\n```\\n!pip install langchain==0.1.14 openai==1.14.3\\n```\\n\\n다음 코드를 실행하면,\\n\\n```python\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI()\\nllm(\"hello\")\\n```\\n\\n`LangChainDeprecationWarning`이 두 개 뜬다.'),\n Document(metadata={'id': 233334, 'source': 'https://wikidocs.net/233334', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. 및 LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.'}, page_content='```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\\n  warn_deprecated(\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\\n  warn_deprecated(\\n\"\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\\\n\\\\nhello\\n```'),\n Document(metadata={'id': 233334, 'source': 'https://wikidocs.net/233334', 'title': 'LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. 및 LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.'}, page_content='## 해결\\n\\n`langchain-openai`를 추가로 설치하고,\\n\\n```\\n!pip install langchain-openai==0.1.1\\n```\\n\\n코드를 이렇게 바꾼다.\\n\\n```python\\nfrom [[MARK]]langchain_openai[[/MARK]] import OpenAI\\n\\nllm = OpenAI()\\nllm[[MARK]].invoke[[/MARK]](\"hello\")\\n```\\n\\n이제 경고 메시지가 나오지 않는다.\\n\\n```\\n\\'world\\\\nThe quick brown fox jumps over the lazy dog.\\\\n\\\\nHello World!\\'\\n```'),\n Document(metadata={'id': 236206, 'source': 'https://wikidocs.net/236206', 'title': 'LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.'}, page_content='### 증상\\n\\n```\\n!pip install langchain==0.1.14 openai==1.16.2 langchain-openai==0.1.1\\n```\\n\\n```\\nfrom langchain.agents import AgentType, initialize_agent, load_tools\\nfrom langchain.chat_models import ChatOpenAI\\n\\nchat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\ntools = load_tools([\"terminal\"])\\nagent_chain = initialize_agent(\\n    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\\n)\\n\\nresult = agent_chain.run(\"sample_data 디렉터리에 있는 파일 목록을 알려줘\")\\nprint(결과)\\n```'),\n Document(metadata={'id': 236206, 'source': 'https://wikidocs.net/236206', 'title': 'LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.'}, page_content='```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\\n```\\n\\n### 해결\\n\\n```\\n!pip install langchain-experimental==0.0.56 langchainhub==0.1.15\\n```\\n\\n```\\nfrom langchain import hub\\nfrom langchain.agents import AgentExecutor, create_react_agent, load_tools\\nfrom langchain_openai import ChatOpenAI'),\n Document(metadata={'id': 236206, 'source': 'https://wikidocs.net/236206', 'title': 'LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.'}, page_content='chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\ntools = load_tools([\"terminal\"], allow_dangerous_tools=True)\\n\\nprompt = hub.pull(\"hwchase17/react\")\\n\\nagent = create_react_agent(chat, tools, prompt)\\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\\n\\nresult = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\\nprint(result)\\n```\\n\\n### 참고'),\n Document(metadata={'id': 236206, 'source': 'https://wikidocs.net/236206', 'title': 'LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.'}, page_content='- Agent Types: <https://python.langchain.com/docs/modules/agents/agent_types/>\\n- OpenAI functions: <https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent/>\\n- ReAct:\\n    - <https://python.langchain.com/docs/modules/agents/agent_types/react/>\\n    - create_react_agent: <https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html>\\n- JSON Chat Agent: <https://python.langchain.com/docs/modules/agents/agent_types/json_agent/>\\n- Structured chat: <https://python.langchain.com/docs/modules/agents/agent_types/structured_chat/>'),\n Document(metadata={'id': 235780, 'source': 'https://wikidocs.net/235780', 'title': 'LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.'}, page_content='## 현상\\n\\n다음을 설치하고,\\n\\n```\\n!pip install langchain==0.1.14 openai==1.14.3 langchain-openai==0.1.1\\n```\\n\\n다음을 실행하면,\\n\\n```\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain_openai import OpenAI\\n\\ntemplate = \"\"\"Question: {question}\\\\n\\\\nAnswer: Let\\'s think step by step.\"\"\"\\nprompt = PromptTemplate.from_template(template)\\nllm = OpenAI()\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\nquestion = \"What are the three key pieces of advice for learning how to code?\"\\nllm_chain.run(question)\\n```\\n\\n`LangChainDeprecationWarning`이 발생한다.'),\n Document(metadata={'id': 235780, 'source': 'https://wikidocs.net/235780', 'title': 'LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.'}, page_content=\"```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\\n  warn_deprecated(\\n \\\\n\\\\n1. Start with the basics: Before diving into any specific programming language, it's important to understand the fundamental concepts of coding. This includes understanding algorithms, data structures, and basic syntax. You can start with online resources like Codeacademy, Coursera, or YouTube tutorials to learn about these concepts.\\\\n\\\\n2. Choose a language and stick to it: There are many programming languages out there, but it's important to choose one and stick to it for a while. This will help you build a strong foundation and understand the core principles of coding. Some popular languages for beginners include Python, Java, and JavaScript.\\\\n\\\\n3. Practice, practice, practice: The best way to learn coding is by practicing regularly. Start with simple projects and gradually move on to more complex ones. This will not only help you improve your coding skills but also give you a better understanding of how to solve problems using code. You can also join coding communities or atten\\n```\\n \\n## 해결\"),\n Document(metadata={'id': 235780, 'source': 'https://wikidocs.net/235780', 'title': 'LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.'}, page_content='`run` 대신 `invoke`를 사용한다.\\n\\n```\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain_openai import OpenAI\\n\\ntemplate = \"\"\"Question: {question}\\\\n\\\\nAnswer: Let\\'s think step by step.\"\"\"\\nprompt = PromptTemplate.from_template(template)\\nllm = OpenAI()\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\nquestion = \"What are the three key pieces of advice for learning how to code?\"\\nllm_chain[[MARK]].invoke[[/MARK]](question)\\n```\\n\\n그러면 경고가 뜨지 않는다.'),\n Document(metadata={'id': 235780, 'source': 'https://wikidocs.net/235780', 'title': 'LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.'}, page_content='```\\n{\\'question\\': \\'What are the three key pieces of advice for learning how to code?\\',\\n \\'text\\': \" Here are three key pieces of advice for learning how to code:\\\\n\\\\n1. Start with the basics: Before diving into complex coding languages and projects, it is important to have a strong foundation in the basics of coding. This includes understanding concepts such as variables, loops, conditions, and data types. You can start with simple languages like HTML and CSS, which are used for building websites, or with programming languages like Python or Java.\\\\n\\\\n2. Practice, practice, practice: Coding is a skill that requires practice and repetition. The more you code, the better you will become at it. Set aside time each day to practice coding exercises or work on personal projects. This will help you improve your skills and build your confidence.\\\\n\\\\n3. Don\\'t be afraid to ask for help: Coding can be challenging, and it is common to run into roadblocks or encounter problems while learning. Don\\'t be afraid to ask for help from more experienced programmers, whether it\\'s through online forums, coding communities, or reaching out to a mentor. Learning from others and getting feedback on your code can greatly accelerate your learning process. \"}\\n```'),\n Document(metadata={'id': 256720, 'source': 'https://wikidocs.net/256720', 'title': \"ModuleNotFoundError: No module named 'youtube_search'\"}, page_content='## 증상\\n\\n다음 코드를 실행하면\\n\\n```\\nfrom langchain.tools import YouTubeSearchTool\\ntool = YouTubeSearchTool()\\nresult = tool.run(\"Avatar: The Way of Water,1\")\\n```\\n\\n다음 오류가 발생'),\n Document(metadata={'id': 256720, 'source': 'https://wikidocs.net/256720', 'title': \"ModuleNotFoundError: No module named 'youtube_search'\"}, page_content='```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\ncore\\\\tools.py\", line 621, in run\\n    raise error_to_raise\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\tools.py\", line 590, in run\\n    response = context.run(self._run, *tool_args, **tool_kwargs)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_community\\\\tools\\\\youtube\\\\search.py\", line 54, in _run\\n    return self._search(person, num_results)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_community\\\\tools\\\\youtube\\\\search.py\", line 33, in _search\\n    from youtube_search import YoutubeSearch\\nModuleNotFoundError: No module named \\'youtube_search\\'\\n```'),\n Document(metadata={'id': 256720, 'source': 'https://wikidocs.net/256720', 'title': \"ModuleNotFoundError: No module named 'youtube_search'\"}, page_content='## 해결\\n\\n다음 명령으로 youtube-search 패키지를 설치 후 재시도.\\n\\n```.console\\npip install youtube-search\\n```'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='## 증상\\n\\n```\\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\\nfrom langchain_experimental.tools.python.tool import PythonREPLTool\\n\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain.llms.openai import OpenAI\\nfrom langchain.agents.agent_types import AgentType\\nfrom langchain.chat_models import ChatOpenAI\\n\\nmodel = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\\n\\nagent_executor = create_python_agent(\\n    llm=model,\\n    tool=PythonREPLTool(),\\n    verbose=True,\\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\\n)'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='agent_executor = create_python_agent(\\n    llm=model,\\n    tool=PythonREPLTool(),\\n    verbose=True,\\n    agent_type=AgentType.OPENAI_FUNCTIONS,\\n    agent_executor_kwargs={\"handle_parsing_errors\": True},\\n)\\n\\nquery = \"\"\"\\nIn a different basketball game, we have the following player stats:\\n- Player A: 38 points, 10 rebounds, 7 assists\\n- Player B: 28 points, 9 rebounds, 6 assists\\n- Player C: 19 points, 6 rebounds, 3 assists\\n- Player D: 12 points, 4 rebounds, 2 assists\\n- Player E: 7 points, 2 rebounds, 1 assist'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='Could you create a scatter plot graph in Seaborn talk mode for each player, where the y-axis represents the number of points, the x-axis represents the number of rebounds, and use \\'o\\' as the marker? Additionally, please label each point with the player\\'s name and set the title as \"Team Players.\"\\n\"\"\"\\n\\nagent_executor.run(query)\\n```'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='```\\nc:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\\n  warn_deprecated(\\n\\n\\n> Entering new AgentExecutor chain...'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='---------------------------------------------------------------------------\\nNotFoundError                             Traceback (most recent call last)\\nCell In[6], line 12\\n      1 query = \"\"\"\\n      2 In a different basketball game, we have the following player stats:\\n      3 - Player A: 38 points, 10 rebounds, 7 assists\\n   (...)\\n      9 Could you create a scatter plot graph in Seaborn talk mode for each player, where the y-axis represents the number of points, the x-axis represents the number of rebounds, and use \\'o\\' as the marker? Additionally, please label each point with the player\\'s name and set the title as \"Team Players.\"\\n     10 \"\"\"\\n---> 12 agent_executor.run(query)'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:170, in deprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper(*args, **kwargs)\\n    168     warned = True\\n    169     emit_warning()\\n--> 170 return wrapped(*args, **kwargs)'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:598, in Chain.run(self, callbacks, tags, metadata, *args, **kwargs)\\n    596     if len(args) != 1:\\n    597         raise ValueError(\"`run` supports only one positional argument.\")\\n--> 598     return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\\n    599         _output_key\\n    600     ]\\n    602 if kwargs and not args:\\n    603     return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\\n    604         _output_key\\n...\\n   (...)\\n   1048     retries_taken=options.get_max_retries(self.max_retries) - retries,\\n   1049 )'),\n Document(metadata={'id': 256097, 'source': 'https://wikidocs.net/256097', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'The model `gpt-3.5-turbo-0613` has been deprecated ...\"}, page_content='NotFoundError: Error code: 404 - {\\'error\\': {\\'message\\': \\'The model `gpt-3.5-turbo-0613` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': \\'model_not_found\\'}}\\n```\\n\\n## 원인\\n\\nOpenAI에서 종료한 모델을 사용하려고 해서 오류 발생\\n\\n## 해결\\n\\n모델을 교체. 예:\\n\\n```\\nmodel = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\\n```'),\n Document(metadata={'id': 235773, 'source': 'https://wikidocs.net/235773', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', ...\"}, page_content='## 현상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain_openai import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n\\nllm(\"hello\")\\n```\\n\\n다음 오류가 발생.\\n\\n```\\nNotFoundError: Error code: 404 - {\\'error\\': {\\'message\\': \\'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': \\'model\\', \\'code\\': None}}\\n```\\n\\n## 해결\\n\\n구형(legacy)인 Completions 엔드포인트를 사용하려면 다음과 같이 `gpt-3.5-turbo-instruct` 모델을 사용한다.\\n\\n```\\nfrom langchain_openai import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)'),\n Document(metadata={'id': 235773, 'source': 'https://wikidocs.net/235773', 'title': \"NotFoundError: Error code: 404 - {'error': {'message': 'This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?', ...\"}, page_content='llm(\"hello\")\\n```\\n\\nChat Completions 엔드포인트를 지원하는 모델(예: `gpt-3.5-turbo`)을 사용하려면 `OpenAI` 대신 `ChatOpenAI`를 사용한다.'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='## 증상\\n\\nlangchain-openai==0.1.22에서 다음 코드를 실행하면,\\n\\n```\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain.vectorstores import FAISS\\nfrom langchain.document_loaders import PyPDFLoader\\n\\nimport os\\n\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\n\\nos.environ[\"OPENAI_API_KEY\"]\\n\\ntext_splitter = RecursiveCharacterTextSplitter(\\n            chunk_size=1500,\\n            chunk_overlap=200\\n        )'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='raw_documents = PyPDFLoader(\\'italy_travel.pdf\\').load()\\ndocuments = text_splitter.split_documents(raw_documents)\\ndb = FAISS.from_documents(documents, OpenAIEmbeddings())\\n\\n\\nfrom langchain.tools.retriever import create_retriever_tool\\nfrom langchain.memory import ConversationBufferMemory\\nfrom langchain.agents.agent_toolkits import create_conversational_retrieval_agent\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\\n\\ntool = create_retriever_tool(\\n    db.as_retriever(), \\n    \"italy_travel\",\\n    \"이탈리아에 관한 문서를 검색해서 반환합니다.\"\\n)\\ntools = [tool]'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='memory = ConversationBufferMemory(\\n    memory_key=\\'chat_history\\',\\n    return_messages=True,\\n    llm=llm\\n)\\n\\nagent_executor = create_conversational_retrieval_agent(\\n    llm, \\n    tools, \\n    memory_key=\\'chat_history\\', \\n    verbose=True\\n)\\n\\nagent_executor.invoke({\"input\": \"판테온(Pantheon)에 관해 알려주세요\"})\\n```\\n\\n다음 오류가 발생.\\n\\n```\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\nCell In[6], line 1\\n----> 1 agent_executor.invoke({\"input\": \"판테온(Pantheon)에 관해 알려주세요\"})'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:164, in Chain.invoke(self, input, config, **kwargs)\\n    162 except BaseException as e:\\n    163     run_manager.on_chain_error(e)\\n--> 164     raise e\\n    165 run_manager.on_chain_end(outputs)\\n    167 if include_run_info:'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:159, in Chain.invoke(self, input, config, **kwargs)\\n    152     self._validate_inputs(inputs)\\n    153     outputs = (\\n    154         self._call(inputs, run_manager=run_manager)\\n    155         if new_arg_supported\\n    156         else self._call(inputs)\\n    157     )\\n--> 159     final_outputs: Dict[str, Any] = self.prep_outputs(\\n    160         inputs, outputs, return_only_outputs\\n    161     )\\n    162 except BaseException as e:\\n    163     run_manager.on_chain_error(e)'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py:458, in Chain.prep_outputs(self, inputs, outputs, return_only_outputs)\\n    456 self._validate_outputs(outputs)\\n    457 if self.memory is not None:\\n--> 458     self.memory.save_context(inputs, outputs)\\n    459 if return_only_outputs:\\n    460     return outputs'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\agents\\\\openai_functions_agent\\\\agent_token_buffer_memory.py:97, in AgentTokenBufferMemory.save_context(self, inputs, outputs)\\n     95 # Prune buffer if it exceeds max token limit\\n     96 buffer = self.chat_memory.messages\\n---> 97 curr_buffer_length = self.llm.get_num_tokens_from_messages(buffer)\\n     98 if curr_buffer_length > self.max_token_limit:\\n     99     while curr_buffer_length > self.max_token_limit:'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_openai\\\\chat_models\\\\base.py:960, in BaseChatOpenAI.get_num_tokens_from_messages(self, messages)\\n    956     continue\\n    957 else:\\n    958     # Cast str(value) in case the message value is not a string\\n    959     # This occurs with function messages\\n--> 960     num_tokens += len(encoding.encode(value))\\n    961 if key == \"name\":\\n    962     num_tokens += tokens_per_name'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tiktoken\\\\core.py:116, in Encoding.encode(self, text, allowed_special, disallowed_special)\\n    114     if not isinstance(disallowed_special, frozenset):\\n    115         disallowed_special = frozenset(disallowed_special)\\n--> 116     if match := _special_token_regex(disallowed_special).search(text):\\n    117         raise_disallowed_special_token(match.group())\\n    119 # https://github.com/PyO3/pyo3/pull/3632\\n\\nTypeError: expected string or buffer\\n```\\n\\n## 해결\\n\\nlangchain-openai==0.1.23 이상을 설치.'),\n Document(metadata={'id': 256939, 'source': 'https://wikidocs.net/256939', 'title': 'TypeError: expected string or buffer'}, page_content='```\\npip install langchain-openai -U\\n```\\n\\n## 참고\\n\\n- openai[patch]: fix get_num_tokens for function calls ([#25785](https://github.com/langchain-ai/langchain/pull/25785))\\n- [langchain-openai==0.1.23 릴리스](https://github.com/langchain-ai/langchain/releases/tag/langchain-openai%3D%3D0.1.23)'),\n Document(metadata={'id': 235770, 'source': 'https://wikidocs.net/235770', 'title': 'UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`'}, page_content='## 현상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain.llms import OpenAI\\n\\nllm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\n다음 경고가 발생.'),\n Document(metadata={'id': 235770, 'source': 'https://wikidocs.net/235770', 'title': 'UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`'}, page_content='```\\n/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:249: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\\n  warnings.warn(\\n/usr/local/lib/python3.10/dist-packages/langchain_community/llms/openai.py:1070: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\\n  warnings.warn(\\n```\\n\\n## 1차 조치\\n\\n다음 코드로 변경.'),\n Document(metadata={'id': 235770, 'source': 'https://wikidocs.net/235770', 'title': 'UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`'}, page_content='```\\nfrom langchain_community.chat_models import ChatOpenAI\\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\\n```\\n\\n이제 LangChainDeprecationWarning이 발생.'),\n Document(metadata={'id': 235770, 'source': 'https://wikidocs.net/235770', 'title': 'UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`'}, page_content='```\\n/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\\n```\\n\\n## 2차 조치\\n\\n<https://wikidocs.net/232743>를 참조.'),\n Document(metadata={'id': 256093, 'source': 'https://wikidocs.net/256093', 'title': \"ValueError: 'agent_toolkits' is not in the subpath of 'langchain_core' OR one path is relative and the other is absolute.\"}, page_content='## 증상\\n\\n다음 코드를 실행하면,\\n\\n```\\nfrom langchain.agents.agent_toolkits import create_python_agent\\n```\\n\\n다음 오류가 발생:'),\n Document(metadata={'id': 256093, 'source': 'https://wikidocs.net/256093', 'title': \"ValueError: 'agent_toolkits' is not in the subpath of 'langchain_core' OR one path is relative and the other is absolute.\"}, page_content='```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain\\\\agents\\\\agent_toolkits\\\\__init__.py\", line 121, in __getattr__\\n    relative_path = as_import_path(Path(__file__).parent, suffix=name)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\\\path.py\", line 30, in as_import_path\\n    path = get_relative_path(file, relative_to=relative_to)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\path.py\", line 18, in get_relative_path\\n    return str(file.relative_to(relative_to))\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\pathlib.py\", line 730, in relative_to\\n    raise ValueError(\"{!r} is not in the subpath of {!r}\"\\nValueError: \\'C:\\\\\\\\Users\\\\\\\\yong\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Python\\\\\\\\Python311\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\langchain\\\\\\\\agents\\\\\\\\agent_toolkits\\' is not in the subpath of \\'C:\\\\\\\\Users\\\\\\\\yong\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Python\\\\\\\\Python311\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\langchain_core\\' OR one path is relative and the other is absolute.\\n```'),\n Document(metadata={'id': 256093, 'source': 'https://wikidocs.net/256093', 'title': \"ValueError: 'agent_toolkits' is not in the subpath of 'langchain_core' OR one path is relative and the other is absolute.\"}, page_content='## 해결\\n\\n```\\n!pip install langchain_experimental\\n```\\n\\n```\\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\\n```\\n\\n## 참고\\n\\n- <https://stackoverflow.com/a/78021185>'),\n Document(metadata={'id': 232860, 'source': 'https://wikidocs.net/232860', 'title': 'VectorstoreIndexCreator 사용 시 LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0.'}, page_content='## 문제\\n\\n`VectorStoreIndexCreator` 사용 시 `langchain_community.embeddings.openai.OpenAIEmbeddings`의 사용 중단 경고가 발생한다.'),\n Document(metadata={'id': 232860, 'source': 'https://wikidocs.net/232860', 'title': 'VectorstoreIndexCreator 사용 시 LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0.'}, page_content='```\\nC:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\\n  warn_deprecated(\\n```\\n\\n## 설명'),\n Document(metadata={'id': 232860, 'source': 'https://wikidocs.net/232860', 'title': 'VectorstoreIndexCreator 사용 시 LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0.'}, page_content='[vectorstore.py의 4번째 줄](https://github.com/langchain-ai/langchain/blob/5efb5c099f6ced0b752306c4cb1c45370c2a6920/libs/langchain/langchain/indexes/vectorstore.py#L4)에서 `langchain_community.embeddings.openai.OpenAIEmbeddings`가 사용되는 것이 원인으로 보인다. \\n\\n## 해결\\n\\n경고 메시지가 안 나오게 하려면 다음과 같이 할 수 있다.\\n\\n1. `langchain-openai` 패키지를 설치.\\n\\n        pip install -U langchain-openai\\n   \\n2. 코드에서, 사용 중단된 `langchain_community.embeddings.openai.OpenAIEmbeddings` 대신 `langchain_openai` 패키지에서 `OpenAIEmbeddings`를 임포트한다.\\n\\n\\n        from langchain_openai import OpenAIEmbeddings'),\n Document(metadata={'id': 232860, 'source': 'https://wikidocs.net/232860', 'title': 'VectorstoreIndexCreator 사용 시 LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0.'}, page_content='3. `VectorStoreIndexCreator` 인스턴스 생성 시 업데이트된 `OpenAIEmbeddings` 클래스를 사용한다.\\n\\n        from langchain_openai import OpenAIEmbeddings\\n        from langchain.indexes.vectorstore import VectorstoreIndexCreator\\n        \\n        vectorstore_index_creator = VectorStoreIndexCreator(embedding=OpenAIEmbeddings())\\n   \\n\\n이렇게 하면 최신 `OpenAIEmbeddings` 클래스를 사용하여 LangChain의 기능을 계속 활용할 수 있고, 라이브러리의 향후 업데이트에도 대비할 수 있다.'),\n Document(metadata={'id': 239760, 'source': 'https://wikidocs.net/239760', 'title': '[terminal] is not a valid tool, try one of [terminal]'}, page_content='## 증상\\n\\nlangchain 0.1.19 미만에서 `tools = load_tools([\"terminal\"], allow_dangerous_tools=True)` 실행 시 terminal tool을 못 찾음.\\n\\n```\\n> Entering new AgentExecutor chain...\\nI should use the terminal to list the files in the sample_data directory.\\nAction: [terminal]\\nAction Input: ls sample_data[terminal] is not a valid tool, try one of [terminal].I should use the terminal to list the files in the sample_data directory.\\nAction: [terminal]\\n```\\n\\n## 해결\\n\\n```\\n!pip install langchain==0.1.19\\n```\\n\\n## 참고\\n\\n<https://github.com/langchain-ai/langchain/commit/44602bdc20ffa336326d64f593bf29f458088554>'),\n Document(metadata={'id': 239759, 'source': 'https://wikidocs.net/239759', 'title': 'ddg-search 사용 시 RatelimitException 발생'}, page_content='## 증상\\n\\nddg-search 사용 시 RatelimitException 발생\\n\\n```\\nduckduckgo_search.exceptions.RatelimitException: https://duckduckgo.com/ 202 Ratelimit\\n```\\n\\n## 해결\\n\\n```\\npip install -U duckduckgo_search\\n```\\n\\n## 참고\\n\\n<https://github.com/deedy5/duckduckgo_search/issues/213>'),\n Document(metadata={'id': 267506, 'source': 'https://wikidocs.net/267506', 'title': 'macOS에서 langchainhub 설치 시 npm error code EACCES 오류 발생'}, page_content='## 증상\\n\\n```\\n% npm i -g langchainhub\\nnpm error code EACCES\\nnpm error syscall open\\nnpm error path /Users/yong/.npm/_cacache/tmp/9cc563c5\\nnpm error errno EACCES\\nnpm error\\nnpm error Your cache folder contains root-owned files, due to a bug in\\nnpm error previous versions of npm which has since been addressed.\\nnpm error\\nnpm error To permanently fix this problem, please run:\\nnpm error   sudo chown -R 501:20 \"/Users/yong/.npm\"\\nnpm error A complete log of this run can be found in: /Users/yong/.npm/_logs/2024-11-27T09_04_47_244Z-debug-0.log\\n```\\n\\n## 해결\\n\\n루트 권한으로 설치.\\n\\n```\\nsudo npm i -g langchainhub\\n```'),\n Document(metadata={'id': 267524, 'source': 'https://wikidocs.net/267524', 'title': '2.2 LangSmith'}, page_content='.'),\n Document(metadata={'id': 267525, 'source': 'https://wikidocs.net/267525', 'title': 'LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API'}, page_content='## 증상\\n\\n구글 코랩  등에서 실습 시 LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API 경고 발생\\n\\n## 해결\\n\\n[LangSmith](https://www.langchain.com/langsmith) API 키를 받아서 환경 변수 설정.\\n\\n코드 예:\\n\\n```\\nimport getpass\\nimport os\\n\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\\nos.environ[\"LANGCHAIN_PROJECT\"] = \"My_project\"\\n```\\n\\n## 참고'),\n Document(metadata={'id': 267525, 'source': 'https://wikidocs.net/267525', 'title': 'LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API'}, page_content='- <https://github.com/langchain-ai/langchain/discussions/26755>\\n- [Create an account and API key](https://docs.smith.langchain.com/administration/how_to_guides/organization_management/create_account_api_key)'),\n Document(metadata={'id': 267503, 'source': 'https://wikidocs.net/267503', 'title': '3. Flowise'}, page_content='.'),\n Document(metadata={'id': 267508, 'source': 'https://wikidocs.net/267508', 'title': \"Flowise 실행 시 Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/flowise/logs'\"}, page_content=\"## 증상\\n\\nmacOS에서 Flowise 실행 시 다음 오류 발생:\\n\\n```\\n% npx flowise start\\n    Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/flowise/logs'\\n    Code: EACCES\\n```\\n\\n## 해결\\n\\n1. 현재 사용자와 그룹 확인\\n\\n    사용자의 기본 그룹을 확인한다.\\n\\n        id -gn\\n\\n    출력된 그룹명을 확인한다. 예를 들어, 그룹명이 `staff`로 출력된다면 이를 사용하면 된다.\\n\\n2. chown 명령 수정\\n\\n    위에서 확인한 그룹 이름을 사용하여 아래 명령을 실행한다.\\n\\n        sudo chown -R root:staff /usr/local/lib/node_modules/\\n\\n3. 권한 변경\\n\\n    사용자가 해당 디렉터리 및 하위 디렉터리에 쓰기 권한을 가지도록 설정한다.\\n\\n        sudo chmod -R 775 /usr/local/lib/node_modules/\\n\\n4. Flowise 실행\"),\n Document(metadata={'id': 267508, 'source': 'https://wikidocs.net/267508', 'title': \"Flowise 실행 시 Error: EACCES: permission denied, mkdir '/usr/local/lib/node_modules/flowise/logs'\"}, page_content='다시 `npx flowise start`를 실행한다.\\n    \\n5. 만약 동일한 문제가 발생하면 아래와 같이 권한을 추가로 설정한 뒤,\\n\\n        sudo chmod -R 777 /usr/local/lib/node_modules/flowise/logs\\n\\n    다시 실행한다.\\n\\n        npx flowise start\\n\\n### 추가 팁\\n\\n권한 문제를 완전히 피하려면 npm의 전역 설치 경로를 사용자 전용 디렉터리로 변경하는 것도 좋다.\\n\\n## 참고\\n\\n- <https://stackoverflow.com/questions/49679808/error-eacces-permission-denied-mkdir-usr-local-lib-node-modules-node-sass-b>'),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content='## 증상'),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content='```\\n(base) yong@MacBookPro ~ % npx flowise start\\n2024-11-27 19:57:27 [INFO]: Starting Flowise...\\n(node:77686) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.\\n(Use `node --trace-deprecation ...` to show where the warning was created)\\n2024-11-27 19:57:27 [INFO]: 📦 [server]: Data Source is initializing...\\nMigration \"AddFeedback1707213619308\" failed, error: SQLITE_READONLY: attempt to write a readonly database\\n2024-11-27 19:57:27 [ERROR]: ❌ [server]: Error during Data Source initialization: SQLITE_READONLY: attempt to write a readonly database\\nQueryFailedError: SQLITE_READONLY: attempt to write a readonly database\\n    at Statement.handler (/usr/local/lib/node_modules/flowise/node_modules/typeorm/driver/sqlite/SqliteQueryRunner.js:88:37)\\n    at Statement.replacement (/usr/local/lib/node_modules/flowise/node_modules/sqlite3/lib/trace.js:25:27)\\n    at Statement.replacement (/usr/local/lib/node_modules/flowise/node_modules/sqlite3/lib/trace.js:25:27)\\n2024-11-27 19:57:27 [INFO]: ⚡️ [server]: Flowise Server is listening at :3000\\n```'),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content='## 해결\\n\\n`SQLITE_READONLY: attempt to write a readonly database` 오류는 SQLite 데이터베이스 파일이 읽기 전용 권한으로 설정되어 있어 Flowise가 데이터베이스에 쓰기를 시도할 때 발생한다. 이를 해결하려면 데이터베이스 파일의 권한을 수정하거나 올바른 설정을 확인해야 한다.\\n\\n1. Flowise 데이터베이스 파일 경로 확인\\n\\n    Flowise는 기본적으로 SQLite 데이터베이스를 사용한다. 데이터베이스 파일이 있는 디렉터리를 찾아야 한다. Flowise는 `DATABASE_PATH` 환경 변수에 지정된 경로에서 데이터베이스 파일을 찾으며, 해당 환경 변수가 설정돼 있지 않으면 홈 디렉터리 아래의 `.flowise` 아래에 위치한다.\\n\\n    데이터베이스 파일의 위치를 확인하려면 아래 명령을 사용한다.\\n\\n        ls -l ~/.flowise\\n\\n    SQLite 데이터베이스 파일 이름은 `database.sqlite` 또는 유사한 이름일 것이다.\\n\\n2. 데이터베이스 파일 권한 수정\\n\\n    파일이 읽기 전용으로 설정되어 있으면 권한을 수정한다.'),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content='sudo chmod 664 ~/.flowise/database.sqlite\\n\\n    Flowise가 실행될 때 사용할 디렉터리에도 쓰기 권한이 있어야 하므로 디렉터리 권한도 수정한다.\\n\\n        sudo chmod -R 775 ~/.flowise\\n\\n3. 데이터베이스 소유자 변경\\n\\n    현재 사용자가 데이터베이스 파일에 접근할 수 있도록 소유자를 변경한다.\\n\\n        sudo chown $(whoami):staff ~/.flowise/database.sqlite\\n\\n    여기서 staff는 기본 그룹 이름이며, macOS에서는 일반적으로 사용자 그룹으로 설정된다. 만약 다른 그룹을 사용 중이라면 해당 그룹 이름으로 변경하라.\\n\\n위 단계를 순서대로 진행한 후 다시 Flowise를 실행해 본다.\\n\\n[[TIP]]\\n**Flowise를 다른 디렉터리에 재설치**\\n\\n전역 설치 경로(/usr/local/lib)에서 권한 문제가 계속 발생한다면, Flowise를 사용자 디렉터리 내에 설치하는 방법도 있다.'),\n Document(metadata={'id': 267509, 'source': 'https://wikidocs.net/267509', 'title': 'Flowise 실행 시 QueryFailedError: SQLITE_READONLY: attempt to write a readonly database 오류 발생'}, page_content=\"npm config set prefix '~/.npm-global'\\n    npm install -g flowise\\n    npx flowise start\\n    \\n[[/TIP]]\"),\n Document(metadata={'id': 267507, 'source': 'https://wikidocs.net/267507', 'title': 'Flowise 채팅 시 화면이 하얗게 되는 문제 해결'}, page_content='## 증상\\n\\nmacOS에 설치한 Flowise 1.X 버전에서 Chatflow를 작성하고 채팅을 시작하면 화면이 하얗게 됨.\\n\\n## 해결\\n\\nFlowise 최신 버전(2.1.X)로 재설치\\n\\n## 참고\\n\\n- <https://github.com/FlowiseAI/Flowise/issues/3478>\\n- <https://github.com/FlowiseAI/Flowise/issues/3557>'),\n Document(metadata={'id': 267504, 'source': 'https://wikidocs.net/267504', 'title': 'macOS에 Flowise 설치 시 npm error code EEXIST 및 EACCES: permission denied 오류 발생'}, page_content='## 증상\\n\\nmacOS에서 Flowise 설치 시 다음 오류 발생:'),\n Document(metadata={'id': 267504, 'source': 'https://wikidocs.net/267504', 'title': 'macOS에 Flowise 설치 시 npm error code EEXIST 및 EACCES: permission denied 오류 발생'}, page_content=\"```\\n(base) yong@MacBookPro ~ % node -v\\nv22.11.0\\n(base) yong@MacBookPro ~ % npm install -g flowise\\n...\\nnpm error code EEXIST\\nnpm error syscall rename\\nnpm error path /Users/yong/.npm/_cacache/tmp/36e62795\\nnpm error dest /Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b\\nnpm error errno EEXIST\\nnpm error Invalid response body while trying to fetch https://registry.npmjs.org/@oclif%2fcore: EACCES: permission denied, rename '/Users/yong/.npm/_cacache/tmp/36e62795' -> '/Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b'\\nnpm error File exists: /Users/yong/.npm/_cacache/content-v2/sha512/b1/67/bab8b23ccca98011e86a34b8e5954278c42dbfa1c648c273ab4e7959e700164107aab93962488bd17a13b7e88414ab83099d15b48b7631e415b6a00cb18b\\nnpm error Remove the existing file and try again, or run npm\\nnpm error with --force to overwrite files recklessly.\\n...\\n```\"),\n Document(metadata={'id': 267504, 'source': 'https://wikidocs.net/267504', 'title': 'macOS에 Flowise 설치 시 npm error code EEXIST 및 EACCES: permission denied 오류 발생'}, page_content='## 해결\\n\\n캐시 삭제 후 다시 설치 시도.\\n\\n```\\nsudo npm cache clean --force\\nsudo npm install -g flowise\\n```'),\n Document(metadata={'id': 267505, 'source': 'https://wikidocs.net/267505', 'title': \"macOS에서 Flowise 실행 시 ModuleLoadError: [MODULE_NOT_FOUND] require failed to load ... Cannot find module 'langchainhub'오류\"}, page_content='## 증상'),\n Document(metadata={'id': 267505, 'source': 'https://wikidocs.net/267505', 'title': \"macOS에서 Flowise 실행 시 ModuleLoadError: [MODULE_NOT_FOUND] require failed to load ... Cannot find module 'langchainhub'오류\"}, page_content=\"```\\n% sudo npx flowise start\\nPassword:\\n ›   ModuleLoadError: [MODULE_NOT_FOUND] require failed to load /usr/local/lib/node_modules/flowise/dist/commands/start.js: Cannot \\n ›   find module 'langchainhub'\\n ›   Require stack:\\n ›   - /usr/local/lib/node_modules/flowise/dist/index.js\\n ›   - /usr/local/lib/node_modules/flowise/dist/commands/start.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/module-loader.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/plugin.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/config.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/config/index.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/command.js\\n ›   - /usr/local/lib/node_modules/flowise/node_modules/@oclif/core/lib/index.js\\n ›   - /usr/local/lib/node_modules/flowise/bin/run\\n ›   Code: MODULE_NOT_FOUND\\n```\"),\n Document(metadata={'id': 267505, 'source': 'https://wikidocs.net/267505', 'title': \"macOS에서 Flowise 실행 시 ModuleLoadError: [MODULE_NOT_FOUND] require failed to load ... Cannot find module 'langchainhub'오류\"}, page_content='## 해결\\n\\n다음 명령으로 랭체인허브 설치 후 Flowise 실행.\\n\\n```\\nnpm i -g langchainhub\\n```\\n\\n(만약 위 명령 실행 시 `npm error code EACCES` 오류 발생하면 다음을 참고: <https://wikidocs.net/267506>)\\n\\n## 참고\\n\\n- <https://github.com/FlowiseAI/Flowise/issues/2390#issuecomment-2385029705>'),\n Document(metadata={'id': 256103, 'source': 'https://wikidocs.net/256103', 'title': '4. 기타'}, page_content='.'),\n Document(metadata={'id': 256709, 'source': 'https://wikidocs.net/256709', 'title': 'ERROR: No matching distribution found for azure-ai-vision'}, page_content='## 증상\\n\\n`pip install azure-ai-vision` 명령을 실행하면 다음 오류가 발생\\n\\n```\\nERROR: Ignored the following yanked versions: 0.8.0a1, 0.8.0b0.dev33537970, 0.8.1b1, 0.9.0b1, 0.10.0b1, 0.11.1b1, 0.13.0b1, 0.15.1b1\\nERROR: Could not find a version that satisfies the requirement azure-ai-vision (from versions: none)\\nERROR: No matching distribution found for azure-ai-vision\\n```\\n\\n## 해결\\n\\n<https://pypi.org/project/azure-ai-vision/#files>에서 whl 파일을 다운로드해서 설치\\n\\n```\\npip install azure_ai_vision-0.15.1b1-py3-none-win_amd64.whl\\n```\\n\\n## 참고'),\n Document(metadata={'id': 256709, 'source': 'https://wikidocs.net/256709', 'title': 'ERROR: No matching distribution found for azure-ai-vision'}, page_content='- <https://learn.microsoft.com/en-us/answers/questions/1511970/error-occurred-while-trying-to-install-ai-vision-l>'),\n Document(metadata={'id': 256104, 'source': 'https://wikidocs.net/256104', 'title': \"ImportError: cannot import name 'ExtraValues' from 'pydantic.config'\"}, page_content='## 증상\\n\\n노트북에서 codeinterpreterapi를 설치한 후,\\n\\n```\\n!pip install -q codeinterpreterapi\\n```\\n\\n다음 명령을 실행하면,\\n\\n```\\nfrom codeinterpreterapi import CodeInterpreterSession\\n```\\n\\n다음 오류가 발생:'),\n Document(metadata={'id': 256104, 'source': 'https://wikidocs.net/256104', 'title': \"ImportError: cannot import name 'ExtraValues' from 'pydantic.config'\"}, page_content='```\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeinterpreterapi\\\\__init__.py\", line 4, in <module>\\n    from codeinterpreterapi.schema import File\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeinterpreterapi\\\\schema.py\", line 4, in <module>\\n    from codeboxapi.schema import CodeBoxStatus\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\__init__.py\", line 8, in <module>\\n    from codeboxapi.box.codebox import CodeBox\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\__init__.py\", line 9, in <module>\\n    from .codebox import CodeBox\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\codebox.py\", line 44, in <module>\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\config.py\", line 9, in <module>\\n    from pydantic_settings import BaseSettings\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic_settings\\\\__init__.py\", line 1, in <module>\\n    from .main import BaseSettings, SettingsConfigDict\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic_settings\\\\main.py\", line 7, in <module>\\n    from pydantic._internal._config import config_keys\\n  File \"C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic\\\\_internal\\\\_config.py\", line 19, in <module>\\n    from ..config import ConfigDict, ExtraValues, JsonDict, JsonEncoder, JsonSchemaExtraCallable   \\nImportError: cannot import name \\'ExtraValues\\' from \\'pydantic.config\\' (C:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\pydantic\\\\config.cp311-win_amd64.pyd)\\n```'),\n Document(metadata={'id': 256104, 'source': 'https://wikidocs.net/256104', 'title': \"ImportError: cannot import name 'ExtraValues' from 'pydantic.config'\"}, page_content=\"## 해결\\n\\n터미널에서 파이썬 셸을 새로 열어 다음을 실행해 본다.\\n\\n```\\n>>> import pydantic.config\\n>>> dir(pydantic.config)\\n```\\n\\n다음과 같이 결과에 `'ExtraValues'`가 포함돼 있다면,\"),\n Document(metadata={'id': 256104, 'source': 'https://wikidocs.net/256104', 'title': \"ImportError: cannot import name 'ExtraValues' from 'pydantic.config'\"}, page_content=\"```\\n['AliasGenerator', 'Any', 'Callable', 'ConfigDict', 'Dict', 'ExtraValues', 'JsonDict', 'JsonEncoder', 'JsonSchemaExtraCallable', 'JsonValue', 'List', 'Literal', 'PydanticUserError', 'TYPE_CHECKING', 'Type', 'TypeAlias', 'TypeVar', 'TypedDict', 'Union', '_TypeT', '__all__', '__annotations__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__spec__', '_annotations', 'getattr_migration', 'with_config']\\n```\\n\\n임포트를 실행하면 잘 될 것이다.\\n\\n```\\n>>> from pydantic.config import ExtraValues\\n```\\n\\n이런 경우에는 노트북의 커널을 재시작하면 해결될 가능성이 높다.\"),\n Document(metadata={'id': 256113, 'source': 'https://wikidocs.net/256113', 'title': 'ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with: `pip install jupyter_kernel_gateway` to use the LocalBox.'}, page_content='## 증상\\n\\n```\\nfrom codeinterpreterapi import CodeInterpreterSession\\n\\nasync with CodeInterpreterSession() as session:\\n    # generate a response based on user input\\n    response = await session.generate_response(\\n        \"Generate a plot of the evolution of Covid-19 from March to June 2020, taking data from web.\"\\n    )\\n\\n    # output the response\\n    print(\"AI: \", response.content)\\n    for file in response.files:\\n        file.show_image()\\n        \\n```'),\n Document(metadata={'id': 256113, 'source': 'https://wikidocs.net/256113', 'title': 'ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with: `pip install jupyter_kernel_gateway` to use the LocalBox.'}, page_content='```\\n---------------------------------------------------------------------------\\nNotImplementedError                       Traceback (most recent call last)\\nFile c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\codeboxapi\\\\box\\\\localbox.py:180, in LocalBox.astart(self)\\n    179 try:\\n--> 180     self.jupyter = await asyncio.create_subprocess_exec(\\n    181         python,\\n    182         \"-m\",\\n    183         \"jupyter\",\\n    184         \"kernelgateway\",\\n    185         \"--KernelGatewayApp.ip=\\'0.0.0.0\\'\",\\n    186         f\"--KernelGatewayApp.port={self.port}\",\\n    187         stdout=out,\\n    188         stderr=out,\\n    189         cwd=\".codebox\",\\n    190     )\\n    191     self._jupyter_pids.append(self.jupyter.pid)'),\n Document(metadata={'id': 256113, 'source': 'https://wikidocs.net/256113', 'title': 'ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with: `pip install jupyter_kernel_gateway` to use the LocalBox.'}, page_content='File c:\\\\Users\\\\yong\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\asyncio\\\\subprocess.py:223, in create_subprocess_exec(program, stdin, stdout, stderr, limit, *args, **kwds)\\n    221 protocol_factory = lambda: SubprocessStreamProtocol(limit=limit,\\n    222                                                     loop=loop)\\n--> 223 transport, protocol = await loop.subprocess_exec(\\n    224     protocol_factory,\\n    225     program, *args,\\n    226     stdin=stdin, stdout=stdout,\\n    227     stderr=stderr, **kwds)\\n...\\n    200     try:'),\n Document(metadata={'id': 256113, 'source': 'https://wikidocs.net/256113', 'title': 'ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with: `pip install jupyter_kernel_gateway` to use the LocalBox.'}, page_content='ModuleNotFoundError: Jupyter Kernel Gateway not found, please install it with:\\n`pip install jupyter_kernel_gateway`\\nto use the LocalBox.\\n```\\n\\n## 원인\\n\\n미상.\\n\\n## 해결\\n\\n확인 중.'),\n Document(metadata={'id': 232562, 'source': 'https://wikidocs.net/232562', 'title': '위키북스의 생성 AI 프로그래밍 도서'}, page_content='위키북스에서 출간했거나 출간 예정인 생성 AI 프로그래밍 관련 도서 목록.\\n\\n## ChatGPT API×Python(가제)\\n\\n- 출간년월: 출간 예정\\n- 책에서 기준으로 삼은 패키지 버전: openai==1.10.0 langchain==0.1.4 langchain-core==0.1.17 langchain-community==0.0.17\\n- 코드 저장소: <https://github.com/ychoi-kr/ChatGPT-API-Python>\\n\\n## 랭체인 완벽 입문\\n\\n- URL: <https://wikibook.co.kr/langchain/>\\n- 출간년월: 2024. 2.\\n- 책에서 기준으로 삼은 패키지 버전: openai==0.28 langchain==0.0.261\\n- 코드 저장소: <https://github.com/wikibook/langchain>\\n\\n## GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍 2쇄'),\n Document(metadata={'id': 232562, 'source': 'https://wikidocs.net/232562', 'title': '위키북스의 생성 AI 프로그래밍 도서'}, page_content='- URL: https://wikibook.co.kr/openai-llm/\\n- 출간년월: 2024. 1.\\n- 책에서 기준으로 삼은 패키지 버전: Python 3.10, llama-index==0.6.12 langchain==0.0.181 openai==0.28\\n- 코드 저장소: <https://github.com/wikibook/openai-llm>\\n\\n## GPT-4, ChatGPT, 라마인덱스, 랭체인을 활용한 인공지능 프로그래밍\\n\\n- URL: https://wikibook.co.kr/openai-llm/\\n- 출간년월: 2023. 9.\\n- 책에서 기준으로 삼은 패키지 버전: Python 3.10, llama-index==0.6.12 langchain==0.0.181 openai==0.28\\n- 코드 저장소: <https://github.com/wikibook/openai-llm>\\n\\n## 만들면서 배우는 나만의 인공지능 서비스'),\n Document(metadata={'id': 232562, 'source': 'https://wikidocs.net/232562', 'title': '위키북스의 생성 AI 프로그래밍 도서'}, page_content='- URL: https://wikibook.co.kr/pyai/\\n- 출간년월: 2023. 9.\\n- 책에서 기준으로 삼은 패키지 버전: openai==0.28.1\\n- 코드 저장소: <https://github.com/wikibook/pyai>')]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:49:30.245119Z",
     "start_time": "2025-02-28T08:49:30.237034Z"
    }
   },
   "id": "dce9464b49f631da",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:42.400513Z",
     "start_time": "2025-02-28T08:31:42.381019Z"
    }
   },
   "id": "8ed3b601a9eccac7",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "search_index = FAISS.from_documents(docs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:31:56.547012Z",
     "start_time": "2025-02-28T08:31:50.680214Z"
    }
   },
   "id": "58ce04d912f1e20a",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieval QA with Sources"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c94bebc694958efa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "retrieval_qa_with_sources_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", retriever=search_index.as_retriever()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:33:35.240831Z",
     "start_time": "2025-02-28T08:33:35.228725Z"
    }
   },
   "id": "1f6cf7bdc0650b37",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def retrieval_qa_with_sources(question):\n",
    "    response = retrieval_qa_with_sources_chain.invoke(\n",
    "        {\"question\": question}, return_only_outputs=True\n",
    "    )\n",
    "    if response[\"sources\"]:\n",
    "        return response[\"answer\"] + \"출처: \" + response[\"sources\"]\n",
    "    else:\n",
    "        return response[\"answer\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:33:35.244236Z",
     "start_time": "2025-02-28T08:33:35.242168Z"
    }
   },
   "id": "e2b0bb7602d71d70",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " openai 패키지의 구버전(0.28)과 최신 버전의 설치 방법은 다음과 같다: \n",
      "- 구버전(0.28)으로 고정: `pip install -U openai==0.28` (https://wikidocs.net/229554#installing-openai-0.28)\n",
      "- 최신 버전 설치: `pip install -U openai` (https://wikidocs.net/229554#installing-latest-openai-package)\n",
      "- 코드 수정하여 신버전의 패키지 사용: openai>=1.0.0에서는 코드를 다음과 같이 수정하면 오류나 경고가 뜨지 않고 잘 실행된다: \n",
      "```python\n",
      "import os\n",
      "import openai\n",
      "\n",
      "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
      "\n",
      "response = openai.[[MARK]]chat.completions[[/MARK]].create(\n",
      "    model=\"gpt-3.5-turbo\",\n",
      "    messages=[\n",
      "        {\"role\": \"user\", \"content\": \"hello\"},\n",
      "    ],\n",
      ")\n",
      "```\n",
      "(https://wikidocs.net/231865\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_qa_with_sources(\"openai 패키지 구버전과 최신 버전 설치 방법\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:33:39.380972Z",
     "start_time": "2025-02-28T08:33:35.244908Z"
    }
   },
   "id": "29857c9c899a9ea3",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "출처: https://wikidocs.net/231843, https://wikidocs.net/235770, https://wikidocs.net/233334\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_qa_with_sources(\"langchain_community.llms.openai.OpenAI 경고가 떠요\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:33:59.912956Z",
     "start_time": "2025-02-28T08:33:57.248805Z"
    }
   },
   "id": "7133bb743f690791",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "QA with sources"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf16983dacaeaf04"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/_knlqzks04q67bz6n79k4z2r0000gn/T/ipykernel_22177/2716219094.py:18: LangChainDeprecationWarning: This function is deprecated. Refer to this guide on retrieval and question answering with sources: https://python.langchain.com/docs/how_to/qa_sources/\n",
      "See also the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "  qa_with_sources_chain = load_qa_with_sources_chain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\").\n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "ALWAYS return a \"SOURCES\" part in your answer.\n",
    "Respond in Korean.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER IN KOREAN:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
    "\n",
    "qa_with_sources_chain = load_qa_with_sources_chain(\n",
    "    OpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=PROMPT\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:34:35.310197Z",
     "start_time": "2025-02-28T08:34:35.289637Z"
    }
   },
   "id": "6087cc5e5182d7c6",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def qa_with_sources(question):\n",
    "    return qa_with_sources_chain.invoke(\n",
    "        {\n",
    "            \"input_documents\": search_index.similarity_search(question, k=3),\n",
    "            \"question\": question,\n",
    "        },\n",
    "        return_only_outputs=True,\n",
    "    )[\"output_text\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:34:51.741104Z",
     "start_time": "2025-02-28T08:34:51.738702Z"
    }
   },
   "id": "cbcf4bf0e5993ffa",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " openai 패키지를 설치하는 방법은 두 가지가 있습니다. 첫 번째 방법은 구버전인 0.28로 고정하는 것이고, 두 번째 방법은 최신 버전으로 설치하는 것입니다. 구버전으로 고정하려면 `pip install -U openai==0.28` 명령을 실행하면 됩니다. 최신 버전으로 설치하려면 `pip install -U openai` 명령을 실행하면 됩니다. 하지만 최신 버전에서는 코드를 수정해야 합니다. 따라서 옵션 2를 선택하면 됩니다. 이때 코드를 수정하는 방법은 두 가지가 있습니다. 첫 번째 방법은 다운그레이드하는 것이고, 두 번째 방법은 코드를 수정하는 것입니다. 다운그레이드하는 방법은 [https://wikidocs.net/229554#installing-openai-0.28](https://wikidocs.net\n"
     ]
    }
   ],
   "source": [
    "print(qa_with_sources('openai 패키지 구버전과 최신 버전 설치 방법'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:34:55.869533Z",
     "start_time": "2025-02-28T08:34:52.302091Z"
    }
   },
   "id": "e89433cc6b183587",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "langchain_community.llms.openai.OpenAI는 langchain-community 0.0.10에서 폐기되었으며 0.2.0에서 제거될 예정입니다. 대신 langchain-openai 패키지에 업데이트된 버전의 클래스가 있으며 사용해야 합니다. 사용하려면 `pip install -U langchain-openai`를 실행하고 `from langchain_openai import OpenAI`로 가져와야 합니다. 이로 인해 LangChainDeprecationWarning이 발생합니다. (출처: https://wikidocs.net/231843, https://wikidocs.net/235770)\n"
     ]
    }
   ],
   "source": [
    "print(qa_with_sources('langchain_community.llms.openai.OpenAI 경고가 떠요'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T08:35:02.828928Z",
     "start_time": "2025-02-28T08:34:59.441767Z"
    }
   },
   "id": "57856608494e60d6",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
