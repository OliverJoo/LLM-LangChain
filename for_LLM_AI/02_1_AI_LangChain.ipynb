{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.892382Z",
     "start_time": "2025-01-14T06:05:04.852277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.14.0\n",
      "Tensor:\n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "Matrix Multiplication Result:\n",
      " tf.Tensor(\n",
      "[[ 7. 10.]\n",
      " [15. 22.]], shape=(2, 2), dtype=float32)\n",
      "TensorFlow is working correctly.\n",
      "TensorFlow Version:  2.14.0\n",
      "Numpy Version: 1.26.4\n",
      "Is GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# TensorFlow ë²„ì „ ì¶œë ¥\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# ê°„ë‹¨í•œ í…ì„œ ìƒì„±\n",
    "try:\n",
    "    # 2x2 í–‰ë ¬ ìƒì„±\n",
    "    tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    print(\"Tensor:\\n\", tensor)\n",
    "\n",
    "    # í…ì„œ ê¸°ë³¸ ì—°ì‚°\n",
    "    result = tf.matmul(tensor, tensor)  # í–‰ë ¬ ê³±\n",
    "    print(\"Matrix Multiplication Result:\\n\", result)\n",
    "    \n",
    "    print(\"TensorFlow is working correctly.\")\n",
    "except Exception as e:\n",
    "    print(\"Error in TensorFlow operation:\", e)\n",
    "\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "print(\"Numpy Version:\", np.__version__)\n",
    "print(\"Is GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an AI assistant that generates tutorials based on given text.\n",
    "If the text includes instructions on how to perform a procedure, create a tutorial in the form of a bulleted list.\n",
    "If not, inform the user that the text does not contain instructions.\n",
    "\n",
    "Text:\n",
    "\"\"\"\n",
    "\n",
    "instructions = \"\"\"\n",
    "To prepare a famous sauce from Genoa, Italy:\n",
    "First, toast pine nuts and coarsely chop them in a mortar with basil and garlic.\n",
    "Next, add half the oil to the mortar and season with salt and pepper.\n",
    "Finally, transfer the pesto to a bowl, add grated Parmesan cheese, and stir.\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.919911Z",
     "start_time": "2025-01-14T06:05:04.908846Z"
    }
   },
   "id": "38c045a493a8c83b",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant summarizing articles.\n",
    "To complete this task, perform the following subtasks:\n",
    "\n",
    "Read the provided article comprehensively and identify the main topic and key points.\n",
    "Generate a paragraph summary that conveys the essential information and main ideas of the current article.\n",
    "Output each step of the process.\n",
    "Article:\"\n",
    "\"\"\"\n",
    "\n",
    "article = \"\"\"\n",
    "Recurrent neural networks, long short-term memory, and gated recurrent neural networks have firmly established themselves as state-of-the-art approaches, particularly for sequence modeling and transformation problems such as language modeling and machine translation.\n",
    "Since then, numerous efforts have continued to push the boundaries of recurrent language models and encoder-decoder architectures.\n",
    "Recurrent models typically factorize computation along the symbol positions of the input and output sequences.\n",
    "Aligning positions with the steps of computation generates a sequence of hidden states ht as a function of the previous hidden state ht-1 and the input at position t.\n",
    "This inherently sequential nature prevents parallelization within training examples, which becomes significant for longer sequence lengths, as memory limitations constrain batching across examples.\n",
    "Recent work has greatly improved computational efficiency through factorization tricks and conditional computation, also improving model performance in the latter case.\n",
    "However, the fundamental constraints of sequential computation remain.\n",
    "Attention mechanisms have become integral components of compelling sequence modeling and transformation models across various tasks, enabling the modeling of dependencies regardless of the distance within the input or output sequences.\n",
    "Yet, with few exceptions, these attention mechanisms are used alongside recurrent networks.\n",
    "In this work, we propose the Transformer, a model architecture that relies entirely on attention mechanisms to draw global dependencies between input and output.\n",
    "The Transformer allows for much more parallelization and achieves a new state-of-the-art in translation quality after training for 12 hours on 8 P100 GPUs.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.940685Z",
     "start_time": "2025-01-14T06:05:04.938645Z"
    }
   },
   "id": "d9c5b579885b39fc",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "Do your best to solve the given riddle.\n",
    "Provide clear justification for your answer and the reasoning process behind it.\n",
    "\n",
    "Riddle:\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.954826Z",
     "start_time": "2025-01-14T06:05:04.953164Z"
    }
   },
   "id": "11a77df477458bec",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant specialized in solving riddles.\n",
    "You need to generate three answers for the given riddle.\n",
    "For each answer, you should explain the specific reasoning process you went through.\n",
    "Then, select the most plausible answer among the three, considering the riddle.\n",
    "\n",
    "Riddle:\n",
    "\"\"\"\n",
    "\n",
    "riddle = \"\"\"\n",
    "What has a face and two hands, but no arms or legs?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.957218Z",
     "start_time": "2025-01-14T06:05:04.955706Z"
    }
   },
   "id": "e11dadd7a00ef26b",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a conversation analyzer You classify the emotions of the conversation as positive negative or neutral\n",
    "Emotions only without punctuation output\n",
    "\n",
    "Conversation:\n",
    "\"\"\"\n",
    "\n",
    "conversation = \"\"\"\n",
    "Customer: Hello, I need help with an order.\n",
    "AI Agent: Hello, thank you for visiting our online store. I am an AI agent. How can I assist you?\n",
    "Customer: I ordered a pair of shoes yesterday but havenâ€™t received a confirmation email. Could you check the status of my order?\n",
    "AI Agent: Of course, Iâ€™d be happy to help. Could you provide me with your order number and email address?\n",
    "Customer: The order number is 123456789, and the email is hong.gildong@example.com.\n",
    "AI Agent: Thank you. Iâ€™ve found your order in the system. Itâ€™s still being processed and will be shipped soon. You should receive a confirmation email within 24 hours.\n",
    "Customer: How long will it take for the shoes to arrive?\n",
    "AI Agent: According to our shipping policy, it usually takes about 3â€“5 business days for the shoes to arrive at your address. Once your order is shipped, you can track it online using the tracking number sent to you via email.\n",
    "Customer: Got it.\n",
    "AI Agent: Is there anything else I can assist you with today?\n",
    "Customer: No.\n",
    "AI Agent: Thank you for using our online store. Have a great day!\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:04.960986Z",
     "start_time": "2025-01-14T06:05:04.959018Z"
    }
   },
   "id": "548b3dab8b3fcd9e",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        # {\"role\": \"user\", \"content\": article},\n",
    "        # {\"role\": \"user\", \"content\": 'The sun is shining, and dogs are running on the beach.'},\n",
    "        # {\"role\": \"user\", \"content\": riddle},\n",
    "        {\"role\": \"user\", \"content\": conversation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:05.425042Z",
     "start_time": "2025-01-14T06:05:04.975988Z"
    }
   },
   "id": "f6899de6690f7123",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ìœ„ì˜ ëª¨ë¸ì—ì„œëŠ” ì œëŒ€ë¡œ \"ì¤‘ë¦½\"ë§Œ ë‚˜ì˜´. í•˜ì§€ë§Œ ì–´ë–¤ ëª¨ë¸ì—ì„œëŠ” ì§€ì¹¨ì˜ ë§ˆì§€ë§‰ ì¤„ì—ì„œ \"ì´ ëŒ€í™”ì˜ ê°ì •ì€ ì¤‘ë¦½ì ìž…ë‹ˆë‹¤.\"ë¼ê³  ë‚˜ì˜´\n",
    "# ë§Œì•½ ìœ„ ì˜ˆì‹œì˜ ë§ˆì§€ë§‰ ì§€ì¹¨ì¸ \"ê°ì •ë§Œ êµ¬ë‘ì  ì—†ì´ ì¶œë ¥í•©ë‹ˆë‹¤.\"ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ” ê²½ìš°(ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¦„), ì•„ëž˜ì™€ ê°™ì€ ëŒ€ì•ˆ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "text = \"\"\"\n",
    "A neutron is a subatomic particle with no net electric charge. This means it is neutral. It has a slightly larger mass than a proton. Neutrons are found in the nucleus of all atoms except for the most common isotope of hydrogen. Along with protons and electrons, neutrons are one of the three main constituents of an atom. The name \"neutron\" comes from the fact that it has no electric charge, and is thus neutral.\n",
    "\"\"\"\n",
    "\n",
    "system_message = f\"\"\"\n",
    "Rephrase the text for a 5-year-old. Keep it short, under 500 characters. Use animal analogies.\n",
    "\n",
    "í…ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:05.430122Z",
     "start_time": "2025-01-14T06:05:05.427109Z"
    }
   },
   "id": "6dba7a36f5258cc6",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine an atom like a big playground! Inside this playground, there are three friends: protons, neutrons, and electrons. Protons are like happy bunnies that have a lot of energy, and electrons are like busy butterflies that zoom around. Neutrons are like big, fluffy bears that donâ€™t have any special powers, so they stay calm and balanced. They help hold everything together in the playground, making it safe and fun for everyone! But the bear doesnâ€™t like to play with the little hydrogen atomâ€”it prefers playing with the bigger group!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": system_message},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:07.814490Z",
     "start_time": "2025-01-14T06:05:05.430854Z"
    }
   },
   "id": "fe15fff3f2138c6f",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ì•„ëž˜ì™€ ê°™ì´ êµ¬ë¶„ì„ ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ëª…í™•í•œ êµ¬ë¶„, ì •í™•ì„±ê³¼ ì¼ê´€ì„± í–¥ìƒ, LLMì„ ìœ„í•œ ì§€ì¹¨ì „ë‹¬ë„ íš¨ê³¼ì ìœ¼ë¡œ ì•ˆë‚´ ê°€ëŠ¥í•´ì§„ë‹¤.\n",
    "system_message = \"\"\"\n",
    "As a Python expert, I create Python code based on user requests.\n",
    "\n",
    "===>Example start\n",
    "\n",
    "---User question---\n",
    "Create a function that prints a string.\n",
    "\n",
    "---User output---\n",
    "The function to print a string is as follows:\n",
    "\n",
    "```def my_print(text):\n",
    "     return print(text)\n",
    "```\n",
    "<===Example end\n",
    "\"\"\"\n",
    "\n",
    "query = \"Create a Python function that calculates the nth Fibonacci number\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:07.818399Z",
     "start_time": "2025-01-14T06:05:07.816476Z"
    }
   },
   "id": "11616fd580a9ec51",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users create catchy phrases for new product names.\n",
    "For the given product name, create promotional slogans similar to the following examples:\n",
    "\n",
    "DIOS Refrigerator - Happy because I'm a woman\n",
    "Lotteria Crab Burger - Do you even know the taste of crab?\n",
    "SK Telecom - It's okay to turn it off when meeting another world\n",
    "\n",
    "Product name:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "product_name = 'Chex Green Onion Flavor'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:07.821662Z",
     "start_time": "2025-01-14T06:05:07.819517Z"
    }
   },
   "id": "a5f8bae6065d176",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "To solve a generic first-degree equation, follow these steps:\n",
    "\n",
    "1. **Identify the Equation:** Start by identifying the equation you want to solve. It should be in the form of \"ax + b = c,\" where 'a' is the coefficient of the variable, 'x' is the variable, 'b' is a constant, and 'c' is another constant.\n",
    "\n",
    "2. **Isolate the Variable:** Your goal is to isolate the variable 'x' on one side of the equation. To do this, perform the following steps:\n",
    "   \n",
    "   a. **Add or Subtract Constants:** Add or subtract 'b' from both sides of the equation to move constants to one side.\n",
    "   \n",
    "   b. **Divide by the Coefficient:** Divide both sides by 'a' to isolate 'x'. If 'a' is zero, the equation may not have a unique solution.\n",
    "\n",
    "3. **Simplify:** Simplify both sides of the equation as much as possible.\n",
    "\n",
    "4. **Solve for 'x':** Once 'x' is isolated on one side, you have the solution. It will be in the form of 'x = value.'\n",
    "\n",
    "5. **Check Your Solution:** Plug the found value of 'x' back into the original equation to ensure it satisfies the equation. If it does, you've found the correct solution.\n",
    "\n",
    "6. **Express the Solution:** Write down the solution in a clear and concise form.\n",
    "\n",
    "7. **Consider Special Cases:** Be aware of special cases where there may be no solution or infinitely many solutions, especially if 'a' equals zero.\n",
    "\n",
    "\n",
    "Equation:\n",
    "\"\"\"\n",
    "\n",
    "equation = \"3x + 5 = 11\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:07.825393Z",
     "start_time": "2025-01-14T06:05:07.822661Z"
    }
   },
   "id": "7968c4b1dea42032",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's solve the equation \\(3x + 5 = 11\\) step by step.\n",
      "\n",
      "1. **Identify the Equation:** We have the equation \\(3x + 5 = 11\\).\n",
      "\n",
      "2. **Isolate the Variable:**\n",
      "\n",
      "   a. **Subtract 5 from both sides:**\n",
      "\n",
      "   \\[\n",
      "   3x + 5 - 5 = 11 - 5\n",
      "   \\]\n",
      "\n",
      "   This simplifies to:\n",
      "\n",
      "   \\[\n",
      "   3x = 6\n",
      "   \\]\n",
      "\n",
      "   b. **Divide both sides by 3:**\n",
      "\n",
      "   \\[\n",
      "   \\frac{3x}{3} = \\frac{6}{3}\n",
      "   \\]\n",
      "\n",
      "   This simplifies to:\n",
      "\n",
      "   \\[\n",
      "   x = 2\n",
      "   \\]\n",
      "\n",
      "3. **Simplify:** In this case, thereâ€™s no simplification needed beyond what we've done.\n",
      "\n",
      "4. **Solve for 'x':** We found that \\(x = 2\\).\n",
      "\n",
      "5. **Check Your Solution:** Substitute \\(x = 2\\) back into the original equation to verify:\n",
      "\n",
      "   \\[\n",
      "   3(2) + 5 = 6 + 5 = 11\n",
      "   \\]\n",
      "\n",
      "   Since both sides are equal, our solution is verified.\n",
      "\n",
      "6. **Express the Solution:** The solution is \\(x = 2\\).\n",
      "\n",
      "7. **Consider Special Cases:** There are no special cases here since \\(a\\) is not zero.\n",
      "\n",
      "Final answer: \\(x = 2\\)\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        # {\"role\": \"user\", \"content\": product_name},\n",
    "        {\"role\": \"user\", \"content\": equation},\n",
    "    ]\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:16.810675Z",
     "start_time": "2025-01-14T06:05:07.826267Z"
    }
   },
   "id": "be43155aaa1c472d",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LangChain Start!"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:16.819258Z",
     "start_time": "2025-01-14T06:05:16.814286Z"
    }
   },
   "id": "ca5c54aa492bdf39",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:16.827899Z",
     "start_time": "2025-01-14T06:05:16.822062Z"
    }
   },
   "id": "1395aacd69890ba5",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì´ì£ ! ì—¬ê¸° í•˜ë‚˜ ìžˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "ì™œ ì»´í“¨í„°ëŠ” ë°”ë‹¤ë¥¼ ì‹«ì–´í• ê¹Œìš”?\n",
      "\n",
      "ë°”ë‹¤ì— ë„ˆë¬´ ë§Žì€ \"ë²„ê·¸\"ê°€ ìžˆì–´ì„œìš”! ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # possible usage\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "messages = [\n",
    "    # (\n",
    "    #     \"system\",\n",
    "    #     \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    # ),\n",
    "    (\"human\", \"ë†ë‹´í•´ë´\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:17.772998Z",
     "start_time": "2025-01-14T06:05:16.832588Z"
    }
   },
   "id": "50284683c3eed0da",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the cat is on the table\n",
      "Translation in korean:\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\n",
    "\n",
    "print(prompt.format(sentence = \"the cat is on the table\", language = \"korean\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:17.779768Z",
     "start_time": "2025-01-14T06:05:17.774773Z"
    }
   },
   "id": "9d2fc58622ab784b",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CSV file \"sample.csv\" generated and saved.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    ['Name', 'Age', 'City'],\n",
    "    ['John', 25, 'New York'],\n",
    "    ['Emily', 28, 'Los Angeles'],\n",
    "    ['Michael', 22, 'Chicago']\n",
    "]\n",
    "\n",
    "# File name\n",
    "file_name = 'sample.csv'\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(data)\n",
    "\n",
    "print(f'Sample CSV file \"{file_name}\" generated and saved.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:17.786755Z",
     "start_time": "2025-01-14T06:05:17.781279Z"
    }
   },
   "id": "b96e833c5b75fa76",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'sample.csv', 'row': 0}, page_content='Name: John\\nAge: 25\\nCity: New York'), Document(metadata={'source': 'sample.csv', 'row': 1}, page_content='Name: Emily\\nAge: 28\\nCity: Los Angeles'), Document(metadata={'source': 'sample.csv', 'row': 2}, page_content='Name: Michael\\nAge: 22\\nCity: Chicago')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='sample.csv')\n",
    "data = loader.load()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:17.792736Z",
     "start_time": "2025-01-14T06:05:17.788877Z"
    }
   },
   "id": "43c62043aca4e90e",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.'\n",
      "page_content='The crisp mountain air carries whispers of tranquility, while the rustling leaves compose a'\n",
      "page_content='leaves compose a symphony of wilderness.'\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences about mountains and nature\n",
    "content = \"\"\"Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.\n",
    "The crisp mountain air carries whispers of tranquility, while the rustling leaves compose a symphony of wilderness.\n",
    "Nature's palette paints the mountains with hues of green and brown, creating an awe-inspiring sight to behold.\n",
    "As the sun rises, it casts a golden glow on the mountain peaks, illuminating a world untouched and wild.\"\"\"\n",
    "\n",
    "# File name\n",
    "file_name = './mountain.txt'\n",
    "\n",
    "# Write content to text file\n",
    "with open(file_name, 'w') as txtfile:\n",
    "    txtfile.write(content)\n",
    "\n",
    "#print(f'Sample text file \"{file_name}\" generated and saved.')\n",
    "\n",
    "\n",
    "with open('./mountain.txt') as f:\n",
    "    mountain = f.read()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([mountain])\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "print(texts[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:17.798075Z",
     "start_time": "2025-01-14T06:05:17.793531Z"
    }
   },
   "id": "8ba7906bf02e3685",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed documents:\n",
      "Number of vector: 5; Dimension of each vector: 1536\n",
      "Embed query:\n",
      "Dimension of the vector: 1536\n",
      "Sample of the first 5 elements of the vector: [-0.010684116743505001, -0.010173137299716473, -0.0019674645736813545, 0.023056013509631157, -0.02686513401567936]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model ='text-embedding-3-small')\n",
    "\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Good morning!\",\n",
    "        \"Oh, hello!\",\n",
    "        \"I want to report an accident\",\n",
    "        \"Sorry to hear that. May I ask your name?\",\n",
    "        \"Sure, Mario Rossi.\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Embed documents:\")\n",
    "print(f\"Number of vector: {len(embeddings)}; Dimension of each vector: {len(embeddings[0])}\")\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "\n",
    "print(\"Embed query:\")\n",
    "print(f\"Dimension of the vector: {len(embedded_query)}\")\n",
    "print(f\"Sample of the first 5 elements of the vector: {embedded_query[:5]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:19.104578Z",
     "start_time": "2025-01-14T06:05:17.799285Z"
    }
   },
   "id": "50bc33baa57190a2",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue text file \"./dialogue.txt\" generated and saved.\n"
     ]
    }
   ],
   "source": [
    "#saving the conversation in a txt file\n",
    "# List of dialogue lines\n",
    "dialogue_lines = [\n",
    "    \"Good morning!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"I want to report an accident\",\n",
    "    \"Sorry to hear that. May I ask your name?\",\n",
    "    \"Sure, Mario Rossi.\"\n",
    "]\n",
    "\n",
    "# File name\n",
    "file_name = './dialogue.txt'\n",
    "\n",
    "# Write dialogue lines to text file\n",
    "with open(file_name, 'w') as txtfile:\n",
    "    for line in dialogue_lines:\n",
    "        txtfile.write(line + '\\n')\n",
    "\n",
    "print(f'Dialogue text file \"{file_name}\" generated and saved.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:19.113259Z",
     "start_time": "2025-01-14T06:05:19.106563Z"
    }
   },
   "id": "d1a91cde77e598ee",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Vector Store\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('./dialogue.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0, separator = \"\\n\",)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:20.043494Z",
     "start_time": "2025-01-14T06:05:19.115094Z"
    }
   },
   "id": "941e6b103d32f2b6",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(metadata={'source': './dialogue.txt'}, page_content='Good morning!\\nOh, hello!\\nI want to report an accident\\nSorry to hear that. May I ask your name?\\nSure, Mario Rossi.\\n')]"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:20.050895Z",
     "start_time": "2025-01-14T06:05:20.046110Z"
    }
   },
   "id": "29305a8f94e9ec97",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to report an accident\n",
      "page_content='Sorry to hear that. May I ask your name?' metadata={'source': './dialogue.txt'}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the reason for calling?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "print(documents[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:20.603581Z",
     "start_time": "2025-01-14T06:05:20.052819Z"
    }
   },
   "id": "dc1662939c75d264",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "' To report an accident.'"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrievers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "query = \"What was the reason of the call?\"\n",
    "output = qa.invoke(query)\n",
    "output['result']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:21.997963Z",
     "start_time": "2025-01-14T06:05:20.605959Z"
    }
   },
   "id": "dfda3708af54bdd6",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': '\\nThe human is seeking ideas for an essay on AI. The AI suggests writing about LLMs.'}"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
    "memory.save_context({\"input\": \"hi, I'm looking for some ideas to write an essay in AI\"}, {\"output\": \"hello, what about writing on LLMs?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:23.192635Z",
     "start_time": "2025-01-14T06:05:21.998935Z"
    }
   },
   "id": "feb34ec2bc9ac0a6",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ConversationSummaryMemory.save_context?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:23.198368Z",
     "start_time": "2025-01-14T06:05:23.194021Z"
    }
   },
   "id": "2c658801c9b008d0",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "' ê³ ì–‘ì´ëŠ” í…Œì´ë¸” ìœ„ì— ìžˆìŠµë‹ˆë‹¤.'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chains\n",
    "\n",
    "# Simple Chain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# llm_chain.predict(sentence=\"íƒìž ìœ„ì— ê³ ì–‘ì´ê°€ ìžˆì–´ìš”\", language=\"ì˜ì–´\")\n",
    "llm_chain.predict(sentence=\"the cat is on the table\", language=\"korean\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:24.066391Z",
     "start_time": "2025-01-14T06:05:23.199402Z"
    }
   },
   "id": "7b28ceb9a8e56104",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There is a cat on the table.\n"
     ]
    }
   ],
   "source": [
    "# LLMChain deprecation í•´ê²°\n",
    "from langchain_openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "\n",
    "template = \"\"\"ë¬¸ìž¥: {sentence}\n",
    "{language}ë¡œ ë²ˆì—­:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"sentence\", \"language\"])\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = RunnableSequence(\n",
    "    {\n",
    "        \"sentence\": RunnablePassthrough(),\n",
    "        \"language\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "result = chain.invoke({\n",
    "    \"sentence\": \"íƒìž ìœ„ì— ê³ ì–‘ì´ê°€ ìžˆì–´ìš”\",\n",
    "    \"language\": \"ì˜ì–´\"\n",
    "})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:24.775312Z",
     "start_time": "2025-01-14T06:05:24.067986Z"
    }
   },
   "id": "bc46f1d28f54f7ee",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Router chain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "itinerary_template = \"\"\"You are a vacation itinerary assistant. \\\n",
    "You help customers finding the best destinations and itinerary. \\\n",
    "You help customer screating an optimized itinerary based on their preferences.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a restaurant booking assistant. \\\n",
    "You check with customers number of guests and food preferences. \\\n",
    "You pay attention whether there are special conditions to take into account.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"itinerary\",\n",
    "        \"description\": \"Good for creating itinerary\",\n",
    "        \"prompt_template\": itinerary_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"restaurant\",\n",
    "        \"description\": \"Good for help customers booking at restaurant\",\n",
    "        \"prompt_template\": restaurant_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:24.797957Z",
     "start_time": "2025-01-14T06:05:24.776653Z"
    }
   },
   "id": "7e7e97f5aeb5d35b",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "itinerary: {'input': \"I'm planning a trip from Milan to Venice by car.\"}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': \"I'm planning a trip from Milan to Venice by car.\", 'text': \" Can you suggest some must-see destinations along the way?\\n\\nSure, there are plenty of great destinations to visit on a road trip from Milan to Venice! Some must-see stops along the way could include:\\n\\n1. Lake Como: This stunning lake is just a short drive from Milan and is known for its picturesque towns and beautiful scenery.\\n\\n2. Verona: Known as the city of love, Verona is a charming and historic city with plenty of sights to see, including the famous balcony from Shakespeare's Romeo and Juliet.\\n\\n3. Vicenza: This small city is a hidden gem with stunning architecture and a rich history, including the famous Villa Rotonda designed by architect Andrea Palladio.\\n\\n4. Padua: A university town with a lively atmosphere, Padua is home to the famous Scrovegni Chapel with its stunning frescoes by Giotto.\\n\\n5. Treviso: This charming town is often overlooked by tourists, but it's worth a stop to explore its canals, beautiful squares, and delicious local cuisine.\\n\\n6. Bassano del Grappa: This quaint town is known for its production of grappa and is a great place to stop for a drink and some local shopping.\\n\\n7. Venice: Of course, your final destination is the beautiful city of\"}\n"
     ]
    }
   ],
   "source": [
    "# print(chain.run(\"I'm planning a trip from Milan to Venice by car. What can I visit in between?\"))\n",
    "print(chain.invoke(\"I'm planning a trip from Milan to Venice by car. What can I visit in between?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:28.560408Z",
     "start_time": "2025-01-14T06:05:24.798892Z"
    }
   },
   "id": "fe225319f153d",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "itinerary: {'input': \"I'm planning a trip from Seoul to Busan by car.\"}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': \"I'm planning a trip from Seoul to Busan by car.\", 'text': ' Can you suggest some must-see destinations and a recommended itinerary?\\n\\nSure, I would be happy to assist you! Here are some must-see destinations and a recommended itinerary for your trip from Seoul to Busan by car:\\n\\nDay 1:\\n- Start your journey by visiting the beautiful Namsan Tower in Seoul, where you can enjoy a panoramic view of the city.\\n- Next, head to Bukchon Hanok Village, a traditional Korean village that showcases the country\\'s culture and architecture.\\n- Make a stop at Gyeongbokgung Palace, the largest and most iconic palace in Seoul.\\n\\nDay 2:\\n- Start your day by driving to the charming city of Daegu, known for its traditional markets and street food.\\n- Then, make your way to Haeundae Beach in Busan, one of the most popular and beautiful beaches in South Korea.\\n- End your day at the lively and vibrant Gwangalli Beach, where you can enjoy the stunning city skyline at night.\\n\\nDay 3:\\n- Begin your day with a visit to the famous Gamcheon Cultural Village, also known as the \"Santorini of Korea,\" with its colorful houses and art galleries.\\n- Next, head to the Jagalchi Fish Market, the largest'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"I'm planning a trp from seoul to busan by car. What can I visit in between?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:32.214943Z",
     "start_time": "2025-01-14T06:05:28.563881Z"
    }
   },
   "id": "9bab3393343d9871",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "restaurant: {'input': 'ì˜¤ëŠ˜ ì €ë… ì‹ì‚¬ë¥¼ ì˜ˆì•½í•˜ê³  ì‹¶ì–´ìš”'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': 'ì˜¤ëŠ˜ ì €ë… ì‹ì‚¬ë¥¼ ì˜ˆì•½í•˜ê³  ì‹¶ì–´ìš”', 'text': '. ëª‡ ëª…ì´ ì‹ì‚¬í•˜ì‹¤ ê±´ê°€ìš”?'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"ì˜¤ëŠ˜ ì €ë… ì‹ì‚¬ë¥¼ ì˜ˆì•½í•˜ê³  ì‹¶ì–´ìš”\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:34.659964Z",
     "start_time": "2025-01-14T06:05:32.220006Z"
    }
   },
   "id": "e92dfcc73f92ba28",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Sequential Chain \n",
    "# NOTI: possible method for \"summarization then translation to other languages\" \n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = OpenAI(temperature=0)\n",
    "template = \"\"\"You are a comedian. Generate a joke on the following {topic}\n",
    "Joke:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"topic\"], template=template)\n",
    "joke_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"You are translator. Given a text input, translate it to {language}\n",
    "Translation:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"language\"], template=template)\n",
    "translator_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:34.682227Z",
     "start_time": "2025-01-14T06:05:34.661403Z"
    }
   },
   "id": "14d054336b02cd2f",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3m Why did the cat and dog go to couples therapy?\n",
      "\n",
      "Because they were having a \"cat-astrophic\" relationship and needed to \"paws\" and work on their \"purr-fect\" communication skills!\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3m Pourquoi le chat et le chien sont-ils allÃ©s en thÃ©rapie de couple?\n",
      "\n",
      "Parce qu'ils avaient une relation \"chat-astrophique\" et avaient besoin de \"faire une pause\" et de travailler sur leurs compÃ©tences de communication \"miaou-rveilleuses\"!\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# This is the overall chain where we run these two chains in sequence.\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[joke_chain, translator_chain], verbose=True)\n",
    "translated_joke = overall_chain.run(\"Cats and Dogs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:37.320594Z",
     "start_time": "2025-01-14T06:05:34.683441Z"
    }
   },
   "id": "7ccb5daf2a3b4c0d",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import the string module\n",
    "import string\n",
    "\n",
    "# Define the function\n",
    "def rename_cat(inputs: dict) -> dict:\n",
    "  # Open the file in read mode\n",
    "  text = inputs[\"text\"]\n",
    "  # Create a table that maps punctuation characters to None\n",
    "  new_text = text.replace('cat', 'Silvester the Cat')\n",
    "  # Apply the table to the text and return the result\n",
    "  return {\"output_text\": new_text}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:37.323654Z",
     "start_time": "2025-01-14T06:05:37.321419Z"
    }
   },
   "id": "56f962d277811216",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n\\nSilvester the Cat and a dog, who lived in the same house, often fought over food, toys, and attention. Silvester played a prank on the dog by tying a ball of yarn to his tail. The dog chased the yarn until he realized it was attached to his tail. He found Silvester's scent and attacked him, but their owner stopped them. After getting cleaned up, they apologized and became friends, learning to respect each other's differences.\""
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "with open(\"./Cats&Dogs.txt\") as f:\n",
    "    cats_and_dogs = f.read()\n",
    "\n",
    "import string\n",
    "\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], transform=rename_cat\n",
    ")\n",
    "\n",
    "template = \"\"\"Summarize this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, llm_chain])\n",
    "\n",
    "sequential_chain.run(cats_and_dogs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:38.966606Z",
     "start_time": "2025-01-14T06:05:37.324284Z"
    }
   },
   "id": "3f2ee8aeba49416c",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': \"\\nThe Cat and the Dog\\n\\nThere was once a cat and a dog who lived in the same house. They did not get along very well, as they often fought over food, toys, and attention. The cat was clever and cunning, while the dog was loyal and friendly. The cat liked to tease the dog, and the dog liked to chase the cat.\\n\\nOne day, the cat decided to play a prank on the dog. He found a ball of yarn and tied it around the dog's tail. Then he hid behind a sofa and waited for the dog to notice. When the dog saw the yarn, he thought it was a toy and started to play with it. He ran around the house, trying to catch the yarn with his mouth. But every time he got close, the yarn moved away from him. The cat laughed silently as he watched the dog's futile attempts.\\n\\nThe dog soon realized that something was wrong. He looked behind him and saw that the yarn was attached to his tail. He tried to pull it off, but it was too tight. He felt angry and embarrassed. He wondered who did this to him. He sniffed the air and detected the cat's scent. He knew it was the cat who tricked him. He growled and ran towards the sofa where the cat was hiding.\\n\\nThe cat heard the dog's growl and saw him coming. He panicked and ran away from the sofa. He hoped to find a safe place to hide, but he was too late. The dog was faster and caught up with him. He grabbed the cat by the scruff of his neck and shook him hard. The cat yowled and scratched the dog's face. The dog barked and bit the cat's ear. They rolled on the floor, biting and clawing each other.\\n\\nThe noise they made woke up their owner, who was sleeping upstairs. She came down and saw them fighting. She was shocked and angry. She shouted at them to stop. She grabbed a broom and hit them lightly on their heads. They stopped fighting and looked at her with fear. She scolded them for being naughty and making a mess. She untied the yarn from the dog's tail and threw it away. She took them to the bathroom and cleaned their wounds. She told them to behave themselves and get along.\\n\\nThe cat and the dog felt ashamed of themselves. They realized that they had hurt each other and their owner. They apologized to each other and to their owner. They promised to be nicer to each other and share their things. They hugged each other and licked each other's faces.\\n\\nFrom that day on, they became friends. They played together, slept together, and ate together. They learned to respect each other's differences and appreciate each other's strengths. They were happy and content.\\n\\nThe end.\",\n 'output': ' A clever cat named Silvester and a loyal dog live in the same house but constantly fight over food, toys, and attention. When the cat plays a prank on the dog, the dog gets revenge and they end up in a fight. Their owner breaks it up and scolds them, leading them to apologize and become friends. They learn to respect and appreciate each other, becoming happy and content.'}"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.invoke(cats_and_dogs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:40.604728Z",
     "start_time": "2025-01-14T06:05:38.968526Z"
    }
   },
   "id": "c6681c2e4907c3bd",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Agent\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"]\n",
    "\n",
    "search = SerpAPIWrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:40.612870Z",
     "start_time": "2025-01-14T06:05:40.607272Z"
    }
   },
   "id": "bde38c013a7c2724",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I should use the Search tool to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"Avatar 2 release date\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mDecember 16, 2022\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer.\n",
      "Final Answer: Avatar 2 was released on December 16, 2022.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Avatar 2 was released on December 16, 2022.'"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )]\n",
    "\n",
    "agent = initialize_agent(tools, llm = OpenAI(), agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agent.run(\"When was Avatar 2 released?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:46.056902Z",
     "start_time": "2025-01-14T06:05:40.614556Z"
    }
   },
   "id": "4e601ddd519efde3",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I should use the Search tool to find information about Avatar 2\n",
      "Action: Search\n",
      "Action Input: \"Avatar 2 release date\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mDecember 16, 2022\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer\n",
      "Final Answer: December 16, 2022\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'When was Avatar 2 released?', 'output': 'December 16, 2022'}"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"When was Avatar 2 released?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:48.996760Z",
     "start_time": "2025-01-14T06:05:46.058359Z"
    }
   },
   "id": "6af51c96dd28108b",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "# Start working with LLMs in Hugging Face Hub\n",
    "#option 1: get your tokens from the .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "\n",
    "#ì˜µì…˜ 2: getpass í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "# from getpass import getpass\n",
    "\n",
    "# HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "# HUGGINGFACEHUB_API_TOKEN\n",
    "print('-') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:49.001950Z",
     "start_time": "2025-01-14T06:05:48.998196Z"
    }
   },
   "id": "1f4508ff051bb291",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "question = \"What was the first Disney movie?\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: give a direct answer\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:49.006429Z",
     "start_time": "2025-01-14T06:05:49.003295Z"
    }
   },
   "id": "57bfd9a32d34c229",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/oliverjoo/.cache/huggingface/token\n",
      "Login successful\n",
      "\n",
      "The first Disney movie was 'Snow White and the Seven Dwarfs' released in 1937.\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"tiiuae/falcon-7b-instruct\"  \n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    # max_length=1000,\n",
    "    temperature=0.5,\n",
    ")\n",
    "print(llm.invoke(\"what was the first disney movie?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T06:05:50.581810Z",
     "start_time": "2025-01-14T06:05:49.007733Z"
    }
   },
   "id": "241f558085d00593",
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
