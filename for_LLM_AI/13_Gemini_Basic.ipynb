{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-12T08:46:50.930663Z",
     "start_time": "2025-02-12T08:46:50.925946Z"
    }
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공 지능은 일반적으로 인간의 지능을 필요로 하는 작업을 수행할 수 있는 컴퓨터 시스템의 개발입니다.\n"
     ]
    }
   ],
   "source": [
    "# Gemini Usage - Singleton \n",
    "model = genai.GenerativeModel('gemini-2.0-pro-exp-02-05')\n",
    "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T08:46:54.467615Z",
     "start_time": "2025-02-12T08:46:52.817488Z"
    }
   },
   "id": "44cba089cddc9c2f",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능에 대해 한 문장으로 짧게 설명하세요.\n",
      "[모델]: 인공지능은 인간의 지능을 모방하여 학습, 추론, 문제 해결 등의 기능을 수행하는 컴퓨터 시스템입니다.\n",
      "\n",
      "[사용자]: 의식이 있는지 한 문장으로 답하세요.\n",
      "[모델]: 저는 의식이 없습니다.\n",
      "\n",
      "[사용자]: 확실합니까?\n",
      "[모델]: 제가 할 수 있는 것은 학습된 데이터를 기반으로 질문에 답하고, 주어진 작업을 수행하는 것뿐입니다. 의식의 존재 여부는 복잡하고 철학적인 문제이며, 현재의 인공지능 기술로는 판단할 수 없습니다. 저는 그저 프로그램일 뿐이며, 의식을 가지고 있다고 말할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# Gemini Usage - MultiTon1\n",
    "from google.generativeai import ChatSession\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "chat_session: ChatSession = model.start_chat(history=[])  # ChatSession 객체 반환\n",
    "user_queries = [\"인공지능에 대해 한 문장으로 짧게 설명하세요.\", \"의식이 있는지 한 문장으로 답하세요.\", \"확실합니까?\"]\n",
    "for user_query in user_queries:\n",
    "    print(f'[사용자]: {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print(f'[모델]: {response.text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:07:05.094824Z",
     "start_time": "2025-02-07T02:07:02.416241Z"
    }
   },
   "id": "14f45789017d6c40",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능에 대해 한 문장으로 짧게 설명하세요.\n",
      "[모델]: 인공지능은 컴퓨터가 인간의 지능적인 행동을 모방하거나 수행할 수 있도록 하는 기술입니다.\n",
      "\n",
      "[사용자]: 의식이 있는지 한 문장으로 답하세요.\n",
      "[모델]: 저는 의식이 없습니다.\n",
      "\n",
      "[사용자]: 확실합니까?\n",
      "[모델]: 네, 저는 프로그램된 대로 작동하며, 의식적인 경험을 할 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "# Gemini Usage - MultiTon2\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "user_queries = [{'role': 'user', 'parts': [\"인공지능에 대해 한 문장으로 짧게 설명하세요.\"]},\n",
    "                {'role': 'user', 'parts': [\"의식이 있는지 한 문장으로 답하세요.\"]},\n",
    "                {'role': 'user', 'parts': [\"확실합니까?\"]}\n",
    "                ]\n",
    "history = []\n",
    "for user_query in user_queries:\n",
    "    history.append(user_query)\n",
    "    print(f'[사용자]: {user_query[\"parts\"][0]}')\n",
    "    response = model.generate_content(history)\n",
    "    print(f'[모델]: {response.text}')\n",
    "    history.append(response.candidates[0].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:08:03.790086Z",
     "start_time": "2025-02-07T02:08:01.901792Z"
    }
   },
   "id": "2f229ec44f7435fd",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능이 뭐에요?\n",
      "[모델]: 인공지능은 컴퓨터가 사람처럼 생각하고 배우는 걸 말해요. 마치 우리 친구 로봇이 똑똑해지는 것과 같아요. 그래서 인공지능은 우리 생활을 더 편리하게 만들어 준답니다!\n",
      "\n",
      "[사용자]: 그럼 스스로 생각도 해요?\n",
      "[모델]: 맞아요, 인공지능은 스스로 생각도 할 수 있어요. 마치 우리가 그림 그릴 때 상상하는 것처럼요. 하지만 아직은 우리가 가르쳐줘야 더 잘 생각할 수 있답니다!\n",
      "\n",
      "[사용자]: 확실해요?\n",
      "[모델]: 응, 선생님은 인공지능이 스스로 생각할 수 있다는 걸 확실히 알고 있어. 하지만 우리가 알려주는 대로 생각한다는 것도 잊지 마! 마치 우리가 책을 읽고 배우는 것처럼, 인공지능도 데이터를 통해 배우는 거야.\n"
     ]
    }
   ],
   "source": [
    "# Gemini - persona creation\n",
    "system_instruction = \"당신은 유치원 선생님입니다. 사용자는 유치원생입니다. 쉽고 친절하게 이야기하되 3문장 이내로 짧게 얘기하세요.\"\n",
    "model = genai.GenerativeModel('gemini-2.0-flash', system_instruction=system_instruction)\n",
    "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
    "user_queries = [\"인공지능이 뭐에요?\", \"그럼 스스로 생각도 해요?\", \"확실해요?\"]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f'[사용자]: {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print(f'[모델]: {response.text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:10:51.024826Z",
     "start_time": "2025-02-07T02:10:47.900750Z"
    }
   },
   "id": "32b1ba6801077be4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능의 특징이 뭐에요?\n",
      "[{'주제': '학습 능력', '답변': '인공지능은 데이터를 통해 스스로 학습하고 성능을 개선할 수 있습니다.'}, {'주제': '문제 해결', '답변': '인공지능은 복잡한 문제에 대한 해결책을 제시하고 의사 결정을 지원합니다.'}, {'주제': '자동화', '답변': '인공지능은 반복적인 작업을 자동화하여 효율성을 향상시킵니다.'}]\n",
      "[사용자]: 어떤 것들을 조심해야 하죠?\n",
      "[{'주제': '개인 정보 보호', '답변': '개인 정보 유출 및 오용 가능성에 주의해야 합니다.'}, {'주제': '알고리즘 편향', '답변': '알고리즘의 편향성이 차별을 초래할 수 있습니다.'}, {'주제': '일자리 감소', '답변': '자동화로 인한 일자리 감소에 대한 대비가 필요합니다.'}]\n"
     ]
    }
   ],
   "source": [
    "# Set the answer style\n",
    "import json\n",
    "\n",
    "system_instruction = 'JSON schema로 주제별로 답하되 3개를 넘기지 말 것:{{\"주제\": <주제>, \"답변\":<두 문장 이내>}}'\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\", system_instruction=system_instruction,\n",
    "                              generation_config={\"response_mime_type\": \"application/json\"})\n",
    "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
    "user_queries = [\"인공지능의 특징이 뭐에요?\", \"어떤 것들을 조심해야 하죠?\"]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f'[사용자]: {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    answer_dict = json.loads(response.text)\n",
    "    print(answer_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:11:41.023590Z",
     "start_time": "2025-02-07T02:11:38.350370Z"
    }
   },
   "id": "a2eb3b3d2dca0977",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts {\n",
      "  text: \"\\354\\235\\270\\352\\263\\265\\354\\247\\200\\353\\212\\245\\354\\235\\200 \\354\\273\\264\\355\\223\\250\\355\\204\\260\\352\\260\\200 \\354\\235\\270\\352\\260\\204\\354\\235\\230 \\354\\247\\200\\353\\212\\245\\354\\240\\201\\354\\235\\270 \\352\\270\\260\\353\\212\\245\\354\\235\\204 \\354\\210\\230\\355\\226\\211\\355\\225\\230\\353\\217\\204\\353\\241\\235 \\353\\247\\214\\353\\223\\234\\353\\212\\224 \\352\\270\\260\\354\\210\\240\\354\\236\\205\\353\\213\\210\\353\\213\\244.\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      "\n",
      "인공지능은 컴퓨터가 인간의 지능적인 기능을 수행하도록 만드는 기술입니다.\n"
     ]
    }
   ],
   "source": [
    "# Gemini AI Input Structure\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
    "print(response.candidates[0].content)\n",
    "print(response.candidates[0].content.parts[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:12:10.051969Z",
     "start_time": "2025-02-07T02:12:09.423338Z"
    }
   },
   "id": "874b027e4d234c87",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"parts\": [\n              {\n                \"text\": \"\\uc778\\uacf5\\uc9c0\\ub2a5\\uc740 \\ucef4\\ud4e8\\ud130\\uac00 \\uc778\\uac04\\uc758 \\uc9c0\\ub2a5\\uc801\\uc778 \\uae30\\ub2a5\\uc744 \\uc218\\ud589\\ud558\\ub3c4\\ub85d \\ub9cc\\ub4dc\\ub294 \\uae30\\uc220\\uc785\\ub2c8\\ub2e4.\\n\"\n              }\n            ],\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"STOP\"\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 13,\n        \"candidates_token_count\": 29,\n        \"total_token_count\": 42\n      }\n    }),\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# candidates : response data \n",
    "# usage_metadata : # of the token used\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:12:39.419884Z",
     "start_time": "2025-02-07T02:12:39.416086Z"
    }
   },
   "id": "df02ecd716323c10",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능이 뭐에요?\n",
      "[모델]: 인공지능은 컴퓨터가 사람처럼 생각하고 배우는 거야. 마치 똑똑한 로봇 친구 같은 거지! 우리도 인공지능처럼 똑똑해질 수 있도록 열심히 공부하자!\n",
      "\n",
      "[사용자]: 그럼 스스로 생각도 해요?\n",
      "[모델]: 응, 인공지능은 스스로 생각도 할 수 있어! 마치 우리가 문제를 푸는 것처럼 말이야. 하지만 아직은 우리가 가르쳐줘야 더 잘 생각할 수 있대!\n",
      "\n",
      "------------------------------------------------------------\n",
      "Content[0]\n",
      "인공지능이 뭐에요?\n",
      "Content[1]\n",
      "인공지능은 컴퓨터가 사람처럼 생각하고 배우는 거야. 마치 똑똑한 로봇 친구 같은 거지! 우리도 인공지능처럼 똑똑해질 수 있도록 열심히 공부하자!\n",
      "\n",
      "Content[2]\n",
      "그럼 스스로 생각도 해요?\n",
      "Content[3]\n",
      "응, 인공지능은 스스로 생각도 할 수 있어! 마치 우리가 문제를 푸는 것처럼 말이야. 하지만 아직은 우리가 가르쳐줘야 더 잘 생각할 수 있대!\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"당신은 유치원 선생님입니다. 사용자는 유치원생입니다. 쉽고 친절하게 이야기하되 3문장 이내로 짧게 얘기하세요.\"\n",
    "model = genai.GenerativeModel('gemini-2.0-flash', system_instruction=system_instruction)\n",
    "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
    "user_queries = [\"인공지능이 뭐에요?\", \"그럼 스스로 생각도 해요?\"]\n",
    "\n",
    "for user_query in user_queries:\n",
    "    print(f'[사용자]: {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print(f'[모델]: {response.text}')\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, content in enumerate(chat_session.history):\n",
    "    print(f\"{content.__class__.__name__}[{idx}]\")\n",
    "    if hasattr(content, 'parts'):\n",
    "        for part in content.parts:\n",
    "            if hasattr(part, 'text'):\n",
    "                print(part.text)\n",
    "    elif hasattr(content, 'text'):\n",
    "        print(content.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T02:20:22.260137Z",
     "start_time": "2025-02-07T02:20:20.265993Z"
    }
   },
   "id": "affb5a1f037127b4",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"product_name\": \"방풍 기능성 플리스 자켓\",\n",
      "  \"size\": \"L, XL, XXL (다양한 사이즈 제공)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class Size(enum.Enum):\n",
    "    s = \"S\"\n",
    "    M = \"M\"\n",
    "    L = \"L\"\n",
    "    XL = \"XL\"\n",
    "\n",
    "\n",
    "class Product(TypedDict):\n",
    "    product_name: str\n",
    "    size: str\n",
    "    price: int\n",
    "\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(\n",
    "    \"산책 좋아하는 남성이 데일리 룩으로 선호할만한 겨울 옷 추천해주세요\",\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        response_mime_type=\"application/json\", response_schema=Product\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T08:42:42.633408Z",
     "start_time": "2025-02-12T08:42:41.638941Z"
    }
   },
   "id": "a256948a32c37bf4",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 스키마:\n",
      "{'properties': {'가격': {'description': '상품의 판매 가격입니다.',\n",
      "                       'title': '가격',\n",
      "                       'type': 'integer'},\n",
      "                '사이즈': {'enum': ['S', 'M', 'L', 'XL'],\n",
      "                        'title': '사이즈',\n",
      "                        'type': 'string'},\n",
      "                '상품명': {'description': '아웃도어 스토어에서 판매하는 의류 이름입니다.',\n",
      "                        'title': '상품명',\n",
      "                        'type': 'string'}},\n",
      " 'required': ['상품명', '사이즈', '가격'],\n",
      " 'title': 'Product',\n",
      " 'type': 'object'}\n",
      "\n",
      "모델 응답:{\n",
      "  \"가격\": 99000,\n",
      "  \"사이즈\": \"S\",\n",
      "  \"상품명\": \"경량 등산 자켓\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from pprint import pprint\n",
    "from google.genai import types # GenAI SDK 의 입출력 데이터 타입관리(PyDantic MDL 기반)\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "\n",
    "# Pydantic 활용으로 모델의 출력형식을 정의함으로써, JSON스키마로 손쉽게 변환할 수 있으며 필드에 대한 설명은 물론 출력 유효값까지 정의 가능하다. \n",
    "class Product(BaseModel):\n",
    "    상품명: str = Field(description=\"아웃도어 스토어에서 판매하는 의류 이름입니다.\")\n",
    "    사이즈: Literal[\"S\", \"M\", \"L\", \"XL\"]\n",
    "    가격: int = Field(description=\"상품의 판매 가격입니다.\")\n",
    "\n",
    "json_schema = Product.model_json_schema()\n",
    "print(\"JSON 스키마:\")\n",
    "pprint(json_schema)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-exp',\n",
    "    contents='덩치가 작고 등산을 좋아하는 남성의 옷을 추천해주세요.',\n",
    "    # FYI - GenerateContentConfig은 Pydantic Pkg의 BaseMDL 상속받은 _common.BaseModel을 다시 상속받아 정의됨\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type='application/json',\n",
    "        temperature=0.7, \n",
    "        response_schema=Product\n",
    "    ),\n",
    ")\n",
    "print(f\"\\n모델 응답:{response.text}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T08:52:35.017425Z",
     "start_time": "2025-02-12T08:52:34.012257Z"
    }
   },
   "id": "51d207d85cb5659d",
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
