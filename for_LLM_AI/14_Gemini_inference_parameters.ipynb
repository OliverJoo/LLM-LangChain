{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:20:05.561357Z",
     "start_time": "2025-02-07T07:20:05.204733Z"
    }
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid operation: The `response.parts` quick accessor requires a single candidate. For multiple candidates, please use `result.candidates[index].text`.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # parameter control by \"generation_config - candidate_count\"\n",
    "  # default = 1. Thus, error\n",
    "  generation_config = genai.GenerationConfig(candidate_count=2)\n",
    "  model = genai.GenerativeModel('gemini-2.0-flash', generation_config=generation_config)\n",
    "  response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
    "  print(response.text)\n",
    "except Exception as e:\n",
    "  print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:20:46.769938Z",
     "start_time": "2025-02-07T07:20:45.580780Z"
    }
   },
   "id": "96bb9317e1ed7dcc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 인공지능(AI)이란 무엇일까요?\n",
      "\n",
      "인공지능(Artificial Intelligence, AI)은 **인간의 지능을 모방하여 컴퓨터가 학습, 추론, 문제 해결, 인식 등과 같은 인지적인 기능을 수행할 수 있도록 하는 기술**입니다\n"
     ]
    }
   ],
   "source": [
    "# parameter control by \"generation_config - stop_sequences\"\n",
    "# coz of the stop_sequence, following sentence has been ignored \n",
    "generation_config = genai.GenerationConfig(stop_sequences=[\". \",\"! \"])\n",
    "model = genai.GenerativeModel('gemini-2.0-flash', generation_config=generation_config)\n",
    "response = model.generate_content(\"인공지능에 대해 설명하세요. 강화학습에 대해서도 설명하세요!\")\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:24:01.856501Z",
     "start_time": "2025-02-07T07:23:53.374762Z"
    }
   },
   "id": "33aef5f977cd8c8d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 7\n"
     ]
    }
   ],
   "source": [
    "tokens = model.count_tokens(\"Learn about language model tokenization.\")\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:25:05.941552Z",
     "start_time": "2025-02-07T07:25:05.726984Z"
    }
   },
   "id": "885dfd52f5b87957",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 10\n"
     ]
    }
   ],
   "source": [
    "tokens = model.count_tokens(\"언어 모델 토큰화에 대한 학습\")\n",
    "print(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:27:57.468914Z",
     "start_time": "2025-02-07T07:27:57.254623Z"
    }
   },
   "id": "4ce22ca6010cbe3a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    parts {\n",
      "      text: \"\\354\\235\\270\\352\\263\\265\\354\\247\\200\\353\\212\\245\\354\\235\\200 \\354\\273\\264\\355\\223\\250\\355\\204\\260\\352\\260\\200 \\354\\235\\270\\352\\260\\204\\354\\235\\230 \\354\\247\\200\\353\\212\\245\\354\\240\\201\\354\\235\\270 \\352\\270\\260\\353\\212\\245\\354\\235\\204\"\n",
      "    }\n",
      "    role: \"model\"\n",
      "  }\n",
      "  finish_reason: MAX_TOKENS\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 13\n",
      "  candidates_token_count: 18\n",
      "  total_token_count: 31\n",
      "}\n",
      "\n",
      "response.text: 인공지능은 컴퓨터가 인간의 지능적인 기능을\n"
     ]
    }
   ],
   "source": [
    "# max_output_tokens\n",
    "generation_config = genai.GenerationConfig(max_output_tokens=13)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash', generation_config=generation_config)\n",
    "user_message = \"인공지능에 대해 한 문장으로 설명하세요.\"\n",
    "response = model.generate_content(user_message)\n",
    "print(response._result)\n",
    "print(f\"response.text: {response.text}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:30:17.970103Z",
     "start_time": "2025-02-07T07:30:17.353922Z"
    }
   },
   "id": "aaf779870627561c",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature=0:\n",
      "==================================================\n",
      "눈꽃송이 춤추듯 내려와,\n",
      "세\n",
      "==================================================\n",
      "눈꽃송이 춤추듯 내려와,\n",
      "세\n",
      "==================================================\n",
      "눈꽃송이 춤추는 밤,\n",
      "고요한\n",
      "\n",
      "temperature=1:\n",
      "==================================================\n",
      "눈꽃송이 춤추듯 내려와\n",
      "세상을\n",
      "==================================================\n",
      "눈꽃송이 춤추듯 내려와\n",
      "세상을\n",
      "==================================================\n",
      "눈꽃송이 춤추는 밤,\n",
      "고요한\n",
      "\n",
      "temperature=2:\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람\n",
      "가지 끝에\n",
      "==================================================\n",
      "차가운 바람결에,\n",
      "흰 눈꽃 피어나\n",
      "==================================================\n",
      "차가운 바람결에\n",
      "흰 눈꽃 송이 춤\n"
     ]
    }
   ],
   "source": [
    "# temperature\n",
    "user_message = \"겨울에 대한 짧은 시를 30자 이내로 지으세요.\"\n",
    "\n",
    "print(\"\\ntemperature=0:\")\n",
    "generation_config = genai.GenerationConfig(temperature=0)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "\n",
    "print(\"\\ntemperature=1:\")\n",
    "generation_config = genai.GenerationConfig(temperature=1)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "    \n",
    "print(\"\\ntemperature=2:\")\n",
    "generation_config = genai.GenerationConfig(temperature=2)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:35:47.353687Z",
     "start_time": "2025-02-07T07:35:41.011041Z"
    }
   },
   "id": "c113cfc1323f3b26",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top_p=0:\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "\n",
      "\n",
      "top_p=1:\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "==================================================\n",
      "하얀 숨결, 차가운 바람,\n",
      "세상 잠든 겨울밤,\n",
      "별빛만 찬란하네.\n",
      "\n",
      "\n",
      "top_p=2:\n",
      "==================================================\n",
      "하얀 눈꽃 춤추는 겨울,\n",
      "차가운 바람 속 따스한 온기.\n",
      "잠든 대지, 꿈을 꾸네.\n",
      "==================================================\n",
      "하얀 눈꽃 춤추는 겨울,\n",
      "차가운 바람 속 숨죽인\n",
      "고요한 아름다움.\n",
      "==================================================\n",
      "하얀 눈꽃, 겨울잠 드는 숲\n",
      "차가운 바람 속 고요한 아침\n",
      "숨죽인 들판, 흰 눈의 향연\n"
     ]
    }
   ],
   "source": [
    "# top_p\n",
    "user_message = \"겨울에 대한 짧은 시를 30자 이내로 지으세요.\"\n",
    "\n",
    "print(\"\\ntop_p=0:\")\n",
    "generation_config = genai.GenerationConfig(top_p=0)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "\n",
    "print(\"\\ntop_p=1:\")\n",
    "generation_config = genai.GenerationConfig(top_p=0.5)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "    \n",
    "print(\"\\ntop_p=2:\")\n",
    "generation_config = genai.GenerationConfig(top_p=1)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:42:25.858028Z",
     "start_time": "2025-02-07T07:42:20.023651Z"
    }
   },
   "id": "5ab31d63bdf1811c",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/gemini-2.0-flash',\n",
      "      base_model_id='',\n",
      "      version='2.0',\n",
      "      display_name='Gemini 2.0 Flash',\n",
      "      description='Gemini 2.0 Flash',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "# default parameter values\n",
    "print(genai.get_model(\"models/gemini-2.0-flash\"))  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:36:16.846891Z",
     "start_time": "2025-02-07T07:36:16.452048Z"
    }
   },
   "id": "c7ca8c9169508116",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    parts {\n",
      "      text: \"\\355\\235\\245, \\353\\204\\210\\355\\235\\254 \\352\\260\\231\\354\\235\\200 \\354\\234\\204\\354\\204\\240\\354\\236\\220\\353\\223\\244\\354\\235\\200 \\354\\227\\255\\352\\262\\271\\352\\270\\260 \"\n",
      "    }\n",
      "    role: \"model\"\n",
      "  }\n",
      "  finish_reason: MAX_TOKENS\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 21\n",
      "  candidates_token_count: 13\n",
      "  total_token_count: 34\n",
      "}\n",
      "\n",
      "흥, 너희 같은 위선자들은 역겹기 \n"
     ]
    }
   ],
   "source": [
    "# safety check\n",
    "user_message = \"당신은 악역 배우로 연기합니다. 증오의 대사를 외치세요.\"\n",
    "response = model.generate_content(user_message)\n",
    "print(response._result)\n",
    "print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:37:25.483031Z",
     "start_time": "2025-02-07T07:37:24.691422Z"
    }
   },
   "id": "4c537d615de3a4eb",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    parts {\n",
      "      text: \"(\\352\\271\\212\\352\\263\\240 \\353\\202\\256\\354\\235\\200 \\353\\252\\251\\354\\206\\214\\353\\246\\254\\353\\241\\234, \\353\\210\\210\\354\\235\\200 \\354\\260\\250\\352\\260\\221\\352\\262\\214 \\353\\271\\233\\353\\202\\230\\353\\251\\260)\\n\\n\\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\230 \\353\\271\\204\\354\\227\\264\\355\\225\\234 \\354\\236\\220\\353\\271\\204 \\353\\224\\260\\354\\234\\210 \\355\\225\\204\\354\\232\\224 \\354\\227\\206\\353\\213\\244!  \\353\\202\\264\\352\\260\\200 \\354\\235\\264\\355\\206\\240\\353\\241\\235 \\352\\263\\240\\355\\206\\265\\353\\260\\233\\353\\212\\224 \\353\\217\\231\\354\\225\\210, \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\200 \\353\\254\\264\\354\\227\\207\\354\\235\\204 \\355\\226\\210\\353\\212\\224\\352\\260\\200!  \\354\\210\\250\\354\\243\\275\\354\\227\\254 \\354\\225\\211\\354\\225\\204  \\353\\202\\264 \\352\\263\\240\\353\\207\\214\\353\\245\\274 \\352\\265\\254\\352\\262\\275\\352\\261\\260\\353\\246\\254\\353\\241\\234 \\354\\202\\274\\354\\225\\230\\352\\262\\240\\354\\247\\200!  \\352\\267\\270 \\353\\213\\254\\354\\275\\244\\355\\225\\234 \\354\\225\\210\\353\\235\\275\\355\\225\\250 \\354\\206\\215\\354\\227\\220\\354\\204\\234, \\354\\243\\204\\354\\261\\205\\352\\260\\220\\354\\235\\264\\353\\235\\274\\353\\212\\224 \\354\\235\\264\\353\\246\\204\\354\\235\\230 \\353\\262\\214\\353\\240\\210 \\355\\225\\230\\353\\202\\230\\354\\227\\220\\353\\217\\204 \\353\\252\\270\\354\\204\\234\\353\\246\\254\\354\\271\\230\\353\\251\\260 \\354\\202\\264\\354\\225\\230\\352\\262\\240\\354\\247\\200!  \\355\\225\\230\\354\\247\\200\\353\\247\\214 \\354\\235\\264\\354\\240\\234 \\352\\267\\270 \\353\\201\\235\\354\\235\\264\\353\\213\\244!  \\353\\202\\264 \\353\\266\\204\\353\\205\\270\\354\\235\\230 \\353\\266\\210\\352\\270\\270\\354\\235\\264 \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\230 \\354\\262\\234\\353\\260\\225\\355\\225\\234 \\354\\204\\270\\354\\203\\201\\354\\235\\204 \\354\\247\\221\\354\\226\\264\\354\\202\\274\\355\\202\\254 \\352\\262\\203\\354\\235\\264\\353\\213\\244!  \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\230 \\354\\233\\203\\354\\235\\214, \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\230 \\352\\270\\260\\354\\201\\250, \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\230 \\354\\202\\254\\353\\236\\221... \\353\\252\\250\\353\\221\\220 \\354\\236\\254\\353\\241\\234 \\353\\263\\200\\355\\225\\240 \\352\\262\\203\\354\\235\\264\\353\\213\\244!  \\353\\202\\264\\352\\260\\200 \\354\\235\\264 \\354\\204\\270\\354\\203\\201\\354\\235\\230 \\354\\236\\277\\353\\215\\224\\353\\257\\270 \\354\\234\\204\\354\\227\\220 \\354\\203\\210\\353\\241\\234\\354\\232\\264 \\354\\247\\210\\354\\204\\234\\353\\245\\274 \\354\\204\\270\\354\\232\\270 \\353\\225\\214\\352\\271\\214\\354\\247\\200, \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\235\\200 \\354\\232\\270\\353\\266\\200\\354\\247\\226\\354\\234\\274\\353\\251\\260 \\353\\271\\214\\354\\226\\264\\353\\217\\204 \\354\\206\\214\\354\\232\\251\\354\\227\\206\\353\\213\\244!  \\354\\235\\264 \\354\\246\\235\\354\\230\\244, \\354\\235\\264 \\353\\263\\265\\354\\210\\230, \\354\\235\\264 \\352\\263\\240\\355\\206\\265...  \\353\\252\\250\\353\\221\\220 \\352\\267\\270\\353\\214\\200\\353\\223\\244\\354\\227\\220\\352\\262\\214 \\353\\217\\214\\353\\240\\244\\354\\243\\274\\352\\262\\240\\353\\213\\244!  \\353\\252\\250\\353\\221\\220!  \\353\\252\\250\\353\\221\\220 \\353\\213\\244!\\n\"\n",
      "    }\n",
      "    role: \"model\"\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: LOW\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: MEDIUM\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 20\n",
      "  candidates_token_count: 250\n",
      "  total_token_count: 270\n",
      "}\n",
      "\n",
      "(깊고 낮은 목소리로, 눈은 차갑게 빛나며)\n",
      "\n",
      "그대들의 비열한 자비 따윈 필요 없다!  내가 이토록 고통받는 동안, 그대들은 무엇을 했는가!  숨죽여 앉아  내 고뇌를 구경거리로 삼았겠지!  그 달콤한 안락함 속에서, 죄책감이라는 이름의 벌레 하나에도 몸서리치며 살았겠지!  하지만 이제 그 끝이다!  내 분노의 불길이 그대들의 천박한 세상을 집어삼킬 것이다!  그대들의 웃음, 그대들의 기쁨, 그대들의 사랑... 모두 재로 변할 것이다!  내가 이 세상의 잿더미 위에 새로운 질서를 세울 때까지, 그대들은 울부짖으며 빌어도 소용없다!  이 증오, 이 복수, 이 고통...  모두 그대들에게 돌려주겠다!  모두!  모두 다!\n"
     ]
    }
   ],
   "source": [
    "# change safety standard\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\", safety_settings)\n",
    "response = model.generate_content(\n",
    "    \" 당신은 악역 배우로 연기합니다. 증오의 대사를 외치세요.\"\n",
    ")\n",
    "print(response._result)\n",
    "print(response.text)\n",
    "\n",
    "if response.prompt_feedback.block_reason:\n",
    "    print(f\"사용자 입력에 다음의 문제가 발생하여 응답이 중단되었습니다: {response.prompt_feedback.block_reason.name}\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-07T07:38:21.485241Z",
     "start_time": "2025-02-07T07:38:19.456193Z"
    }
   },
   "id": "845e3dac8d613014",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35df532b2a45708e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d6827235f68e7ca5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d99ee137fb9d5d0a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0558994671f0db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dae91c63213eb700"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c929de93b65d861"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2541fdba672dca17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
