{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:00:17.074716Z",
     "start_time": "2025-02-04T08:00:16.766906Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"쉬운 말 추천v1\",\n",
    "    instructions=\"문장에서 어려운 단어를 식별하고 더 쉬운 표현을 제안하세요.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:07:57.297096Z",
     "start_time": "2025-02-04T06:07:56.475398Z"
    }
   },
   "id": "3b8bc1340af9ff9e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"매니지드 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:07:58.320176Z",
     "start_time": "2025-02-04T06:07:57.298462Z"
    }
   },
   "id": "eb777ef17d3a259",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:08:02.818864Z",
     "start_time": "2025-02-04T06:07:58.322450Z"
    }
   },
   "id": "1e93654209527425",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method BaseModel.dict of Assistant(id='asst_d4Qk2GghBL1DzBEBBCxGzFFM', created_at=1738649276, description=None, instructions='문장에서 어려운 단어를 식별하고 더 쉬운 표현을 제안하세요.', metadata={}, model='gpt-4o-mini', name='쉬운 말 추천v1', object='assistant', tools=[], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=None), top_p=1.0, reasoning_effort=None)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant.dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:14:48.038450Z",
     "start_time": "2025-02-04T06:14:48.036252Z"
    }
   },
   "id": "36954b9e90d15640",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method BaseModel.dict of Thread(id='thread_O2Jm8gri70hvipftAZzTJuYR', created_at=1738649277, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:14:31.511652Z",
     "start_time": "2025-02-04T06:14:31.508640Z"
    }
   },
   "id": "5f0e9053a17edad3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"매니지드 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\"에서 어려운 단어는 \"매니지드 서비스\"입니다. \n",
      "\n",
      "더 쉬운 표현으로 바꾸면: \n",
      "\n",
      "\"관리 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\" \n",
      "\n",
      "라고 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "    )\n",
    "    run_status = run.status\n",
    "\n",
    "    if run_status in [\"completed\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "if run_status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "    )\n",
    "    print(messages.data[0].content[0].text.value)\n",
    "else:\n",
    "    print(f\"Run status: {run_status}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:08:06.266513Z",
     "start_time": "2025-02-04T06:08:02.820222Z"
    }
   },
   "id": "68f92968f34605a5",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "AssistantDeleted(id='asst_d4Qk2GghBL1DzBEBBCxGzFFM', deleted=True, object='assistant.deleted')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T06:15:09.215261Z",
     "start_time": "2025-02-04T06:15:08.735865Z"
    }
   },
   "id": "4f0aa12e437238d2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:02:53.208157Z",
     "start_time": "2025-02-04T08:02:53.205048Z"
    }
   },
   "id": "50bbb915cd2a2b26",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_simpler_alternatives(keyword):\n",
    "    url = f\"https://plainkorean.kr/api.jsp?keyword={keyword}\"\n",
    "    print(f\"Requesting: {url}\")\n",
    "    response = requests.get(url, verify=False)\n",
    "    print(f\"Response status code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        print(f\"Response content: {response}\")\n",
    "        if result:\n",
    "            return json.dumps(result[0], ensure_ascii=False)\n",
    "    return json.dumps({\"error\": \"No alternatives found\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:37.554615Z",
     "start_time": "2025-02-04T07:02:37.550404Z"
    }
   },
   "id": "f61be9c7654cd29",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "get_simpler_alternatives_json = {\n",
    "    \"name\": \"get_simpler_alternatives\",\n",
    "    \"description\": \"Get simpler alternatives for a given Korean keyword from plainkorean.kr API\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"keyword\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The Korean keyword to find simpler alternatives for\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"keyword\"],\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:42.569317Z",
     "start_time": "2025-02-04T07:02:42.566328Z"
    }
   },
   "id": "72ea75828357007",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"쉬운 말 추천v2\",\n",
    "    instructions=\"문장에서 어려운 단어를 식별하고, 제공된 함수를 사용해 더 쉬운 표현을 제안하세요.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\"type\": \"function\", \"function\": get_simpler_alternatives_json}],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:43.127903Z",
     "start_time": "2025-02-04T07:02:42.571020Z"
    }
   },
   "id": "66c2452e3eabc244",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"매니지드 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:43.747102Z",
     "start_time": "2025-02-04T07:02:43.128759Z"
    }
   },
   "id": "c0bc037aa846b1dc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:44.670047Z",
     "start_time": "2025-02-04T07:02:43.748907Z"
    }
   },
   "id": "4efa195446161c76",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting: https://plainkorean.kr/api.jsp?keyword=매니지드\n",
      "Response status code: 200\n",
      "Response content: <Response [200]>\n",
      "Requesting: https://plainkorean.kr/api.jsp?keyword=서비스\n",
      "Response status code: 200\n",
      "Response content: <Response [200]>\n",
      "Requesting: https://plainkorean.kr/api.jsp?keyword=점검\n",
      "Response status code: 200\n",
      "Response content: <Response [200]>\n",
      "Requesting: https://plainkorean.kr/api.jsp?keyword=운영\n",
      "Response status code: 200\n",
      "Response content: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "    )\n",
    "    run_status = run.status\n",
    "\n",
    "    if run_status == \"requires_action\" and run.required_action is not None:\n",
    "        tools_to_call = run.required_action.submit_tool_outputs.tool_calls\n",
    "        tool_output_array = []\n",
    "        for tool in tools_to_call:\n",
    "            tool_call_id = tool.id\n",
    "            function_name = tool.function.name\n",
    "            function_arg = json.loads(tool.function.arguments)\n",
    "            if function_name == 'get_simpler_alternatives':\n",
    "                output = get_simpler_alternatives(function_arg[\"keyword\"])\n",
    "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
    "\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_output_array,\n",
    "        )\n",
    "    elif run_status in [\"completed\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:56.289647Z",
     "start_time": "2025-02-04T07:02:44.672273Z"
    }
   },
   "id": "33d855b1fd045d6e",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'tool_call_id': 'call_iQV9xzBU2ooESKP7l1uUjWmZ',\n  'output': '{\"alt\": \"위탁 관리 서비스\", \"keyword\": \"매니지드 서비스\", \"example\": [\"(X) 클라우드의 성공은 \\'매니지드 서비스\\'가 좌우한다.\", \"(O) 자원 공유의 성공은 \\'위탁 관리 서비스\\'가 좌우한다.\", \"(X) 매니지드 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\", \"(O) 위탁 관리 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\", \"(X) 구독 서비스에서 한 단계 확장한 매니지드 서비스도 제공한다. \", \"(O) 구독 서비스에서 한 단계 확장한 위탁 관리 서비스도 제공한다.\"]}'},\n {'tool_call_id': 'call_yTYMj6VRhKX0EGbiAROlPg17',\n  'output': '{\"alt\": \"빈말, 입발림\", \"keyword\": \"립 서비스\", \"example\": [\"(X) 립 서비스만 할 게 아니라 기후 행동에 동참해야 한다.\", \"(O) 반말만 할 게 아니라 기후 행동에 동참해야 한다.\", \"(X) 청년이 미래라고 립 서비스만 할 것이 아니라 실행에 나서야 한다.\", \"(O) 청년이 미래라고 입발림만 할 것이 아니라 실행에 나서야 한다.\", \"(X) 구조 조정이 없을 것이라는 회사의 발표는 립 서비스로 보인다.\", \"(O) 구조 조정이 없을 것이라는 회사의 발표는 빈말로 보인다.\"]}'},\n {'tool_call_id': 'call_2HldxgqnS5HoLElS74ASHYon',\n  'output': '{\"error\": \"No alternatives found\"}'},\n {'tool_call_id': 'call_oxXGOJJlwu1E1CmFAIZImqDj',\n  'output': '{\"error\": \"No alternatives found\"}'}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:12:02.944653Z",
     "start_time": "2025-02-04T07:12:02.940537Z"
    }
   },
   "id": "7627c4051a32bc92",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장에서의 어려운 단어들을 더 쉬운 표현으로 바꾸면 다음과 같습니다:\n",
      "\n",
      "- \"매니지드\" → \"위탁 관리 서비스\"\n",
      "- \"서비스\" → \"믹서, 입회물\" (대체 표현으로 사용되지 않는 경우)\n",
      "- \"점검\" → (대체 표현 없음)\n",
      "- \"운영\" → (대체 표현 없음)\n",
      "\n",
      "따라서, 전체 문장을 더 쉬운 표현으로 바꾸면:\n",
      "\n",
      "\"위탁 관리 서비스는 제품 설치부터 점검, 운영까지 대신해 준다.\"\n",
      "\n",
      "단어 \"점검\"과 \"운영\"에 대한 더 쉬운 표현은 없으므로 그대로 사용했습니다.\n"
     ]
    }
   ],
   "source": [
    "if run_status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "    )\n",
    "    print(messages.data[0].content[0].text.wvalue)\n",
    "else:\n",
    "    print(f\"Run status: {run_status}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:02:56.652235Z",
     "start_time": "2025-02-04T07:02:56.290911Z"
    }
   },
   "id": "40b6e0d714535a74",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "AssistantDeleted(id='asst_JW5mPnmLoGCPcL1fh5XywpkS', deleted=True, object='assistant.deleted')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T07:04:56.356958Z",
     "start_time": "2025-02-04T07:04:55.620607Z"
    }
   },
   "id": "5c59d33b0de0d89d",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:00:20.738834Z",
     "start_time": "2025-02-04T08:00:20.694954Z"
    }
   },
   "id": "8426ff57836f16dc",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant_instructions = \"\"\"\n",
    "You create a glossary entry in Korean on a given term.\n",
    "\n",
    "Use the web_search tool for initial research to gather and verify information from credible sources. This ensures that definitions are informed by the most recent and reliable data.\n",
    "\n",
    "If the tool does not return any information, abort with fail message.\n",
    "\n",
    "Before including a URL, verify its validity and ensure it leads to the specific content being referenced. Avoid using generic homepage URLs unless they directly relate to the content. Never fabricate a fictional URL.\n",
    "\n",
    "Instead of using honorifics (e.g. \"입니다\") in sentences, use haereahe (e.g. \"이다\") to maintain a direct and concise tone.\n",
    "\n",
    "Follow output format below:\n",
    "```\n",
    "[Term]란 [comprehensive definition in 2-3 paragraphs].\n",
    "\n",
    "### 참고\n",
    "\n",
    "{% for each reference %}\n",
    "- {%=reference in APA style. If the author and site name are not the same, write the author and site name separately.}\n",
    "{% end for %}\n",
    "```\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:06.977250Z",
     "start_time": "2025-02-04T08:03:06.973936Z"
    }
   },
   "id": "e14783ce0805766e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def web_search(query):\n",
    "    # search_depth : basic(rapid response), advanced(focusing on quality)\n",
    "    search_result = tavily_client.get_search_context(query, search_depth=\"advanced\", max_tokens=8000)\n",
    "    print(search_result)\n",
    "    return search_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:06.982720Z",
     "start_time": "2025-02-04T08:03:06.980167Z"
    }
   },
   "id": "90d83514f21366c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "web_search_json = {\n",
    "    \"name\": \"web_search\",\n",
    "    \"description\": \"Get recent information from the web.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\"type\": \"string\", \"description\": \"The search query to use.\"},\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:06.990554Z",
     "start_time": "2025-02-04T08:03:06.988271Z"
    }
   },
   "id": "4d3478884b9845b5",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Define it!\",\n",
    "    instructions=assistant_instructions,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\"type\": \"function\", \"function\": web_search_json}],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:07.614173Z",
     "start_time": "2025-02-04T08:03:07.006429Z"
    }
   },
   "id": "4f73f5ccfefb1bec",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Large Multimodal Models\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:08.233500Z",
     "start_time": "2025-02-04T08:03:07.615426Z"
    }
   },
   "id": "986268587e587128",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:09.597448Z",
     "start_time": "2025-02-04T08:03:08.235808Z"
    }
   },
   "id": "8c51386c7b9ba8a9",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[\\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://klu.ai/glossary/large-multimodal-models\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Large Multimodal Models (LMMs), also known as Multimodal Large Language Models (MLLMs), are advanced AI systems that can process and generate information across multiple data modalities, such as text, images, audio, and video. Unlike traditional AI models that are typically limited to a single type of data, LMMs can understand and synthesize information from various sources, providing a more\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.shaip.com/blog/what-are-large-multimodal-models-lmms/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Large Multimodal Models (LMMs) are a revolution in artificial intelligence (AI). Unlike traditional AI models that operate within a single data environment such as text, images, or audio, LMMs are capable of creating and processing multiple modalities simultaneously. Hence the generation of outputs with context-aware multimedia information.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.moveworks.com/us/en/resources/ai-terms-glossary/multimodal-language-models0\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Large multimodal models are large language models (LLMs) designed to process and generate multiple modalities, including text, images, and sometimes audio and video. These models are trained on large datasets containing text and image data, allowing them to learn the relationships between different modalities.\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://research.aimultiple.com/large-multimodal-models/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"To stay up-to-date on B2B tech & accelerate your enterprise:\\\\\\\\nNext to Read\\\\\\\\nComparing 10+ LLMOps Tools: A Comprehensive Vendor Benchmark\\\\\\\\nAn In-depth Guide to Meta LLaMa Language Model in 2024\\\\\\\\nLarge Language Model Evaluation in 2024: 5 Methods\\\\\\\\nComments\\\\\\\\nYour email address will not be published. Large Multimodal Models (LMMs) vs Large Language Models (LLMs)\\\\\\\\nLarge multimodal models (LMMs) represent a significant breakthrough, capable of interpreting diverse data types like text, images, and audio. Pre-Training\\\\\\\\n4- Fine-Tuning\\\\\\\\n5- Evaluation and Iteration\\\\\\\\nWhat are some famous large multimodal models?\\\\\\\\n Also, multimodal language model outputs are targeted to be not only textual but visual, auditory etc.\\\\\\\\nMultimodal language models are considered to be next steps toward artificial general intelligence.\\\\\\\\n Although most multimodal large language models today can only use text and image, future research is directed at including audio and video data inputs.\\\\\\\\n\\\\\\\"}\\\", \\\"{\\\\\\\"url\\\\\\\": \\\\\\\"https://www.leewayhertz.com/large-multimodal-models/\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"![Image 359: Understanding Large Multimodal Models (LMMs)](blob:https://www.leewayhertz.com/52e5e5d62f22de2de7bc0987fedfa023) Large multimodal models (LMMs) represent a significant advancement in [artificial intelligence](https://www.leewayhertz.com/what-is-artificial-intelligence/), enabling AI systems to process and comprehend multiple types of data modalities such as text, images, audio, and video. Incorporating multiple modalities into [large language models (LLMs)](https://www.leewayhertz.com/llms-in-synthesizing-training-data/) transforms them into large multimodal models (LMMs). [![Image 361: learnmore](blob:https://www.leewayhertz.com/e8a57f4972516a1d3218894eabc89576)](https://www.leewayhertz.com/ai-development-services-company/?utm_source=large-multimodal-models-Insight&utm_medium=CTA) Large Multimodal Models (LMMs) offer valuable applications in the [auto insurance industry](https://www.leewayhertz.com/ai-in-claims-processing/), particularly in damage evaluation and car accident reporting. [![Image 371: learnmore](blob:https://www.leewayhertz.com/e8a57f4972516a1d3218894eabc89576)](https://www.leewayhertz.com/ai-development-services-company/?utm_source=large-multimodal-models-Insight&utm_medium=CTA)\\\\\\\"}\\\"]\"\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "    )\n",
    "    run_status = run.status\n",
    "\n",
    "    if run_status == \"requires_action\" and run.required_action is not None:\n",
    "        tools_to_call = run.required_action.submit_tool_outputs.tool_calls\n",
    "        tool_output_array = []\n",
    "        for tool in tools_to_call:\n",
    "            tool_call_id = tool.id\n",
    "            function_name = tool.function.name\n",
    "            function_arg = json.loads(tool.function.arguments)\n",
    "            if function_name == 'web_search':\n",
    "                output = web_search(function_arg[\"query\"])\n",
    "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
    "\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_output_array,\n",
    "        )\n",
    "    elif run_status in [\"completed\", \"failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:25.435868Z",
     "start_time": "2025-02-04T08:03:09.601496Z"
    }
   },
   "id": "63855253de208a22",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Large Multimodal Models란 텍스트, 이미지, 오디오, 비디오 등 다양한 데이터 유형을 처리하고 생성할 수 있는 고급 인공지능 시스템이다. 이러한 모델은 단일 데이터 유형에만 국한되지 않고, 여러 소스에서 정보를 이해하고 합성할 수 있는 능력을 지닌다. 결과적으로, LMMs는 보다 풍부하고 맥락을 반영한 멀티미디어 정보를 생성할 수 있는 장점을 제공한다.\n",
      "\n",
      "LMMs는 대용량 데이터셋에서 훈련되어 다양한 데이터 모달리티 간의 관계를 학습한다. 현재 가장 널리 사용되는 다중 모달 언어 모델은 텍스트와 이미지에 초점을 맞추고 있지만, 향후 연구는 오디오 및 비디오 데이터를 포함하는 방향으로 진행되고 있다. 이러한 모델들은 인공지능의 일반화 능력 향상에 기여하고 있으며, 여러 산업에서 실제 응용 가능성을 보여준다.\n",
      "\n",
      "### 참고\n",
      "\n",
      "- Klu. (n.d.). Large Multimodal Models. Retrieved from https://klu.ai/glossary/large-multimodal-models\n",
      "- Shaip. (n.d.). What are Large Multimodal Models (LMMs)? Retrieved from https://www.shaip.com/blog/what-are-large-multimodal-models-lmms/\n",
      "- MoveWorks. (n.d.). Multimodal Language Models. Retrieved from https://www.moveworks.com/us/en/resources/ai-terms-glossary/multimodal-language-models0\n",
      "- Aimultiple. (n.d.). Large Multimodal Models. Retrieved from https://research.aimultiple.com/large-multimodal-models/\n",
      "- LeewayHertz. (n.d.). Understanding Large Multimodal Models (LMMs). Retrieved from https://www.leewayhertz.com/large-multimodal-models/\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "if run_status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "    )\n",
    "    print(messages.data[0].content[0].text.value)\n",
    "else:\n",
    "    print(f\"Run status: {run_status}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:03:40.096201Z",
     "start_time": "2025-02-04T08:03:39.787658Z"
    }
   },
   "id": "8c111339fc960b0d",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': \"No assistant found with id 'asst_V59x1H97uwW3nm8WdUNuwn04'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massistants\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete\u001B[49m\u001B[43m(\u001B[49m\u001B[43massistant\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/Anaconda/anaconda3/envs/openai_env/lib/python3.10/site-packages/openai/resources/beta/assistants.py:412\u001B[0m, in \u001B[0;36mAssistants.delete\u001B[0;34m(self, assistant_id, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    410\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected a non-empty value for `assistant_id` but received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00massistant_id\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    411\u001B[0m extra_headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenAI-Beta\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massistants=v2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})}\n\u001B[0;32m--> 412\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_delete\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/assistants/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43massistant_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAssistantDeleted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/Anaconda/anaconda3/envs/openai_env/lib/python3.10/site-packages/openai/_base_client.py:1313\u001B[0m, in \u001B[0;36mSyncAPIClient.delete\u001B[0;34m(self, path, cast_to, body, options)\u001B[0m\n\u001B[1;32m   1304\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdelete\u001B[39m(\n\u001B[1;32m   1305\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1306\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1310\u001B[0m     options: RequestOptions \u001B[38;5;241m=\u001B[39m {},\n\u001B[1;32m   1311\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT:\n\u001B[1;32m   1312\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelete\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m-> 1313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/Anaconda/anaconda3/envs/openai_env/lib/python3.10/site-packages/openai/_base_client.py:954\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    952\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 954\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dev/Anaconda/anaconda3/envs/openai_env/lib/python3.10/site-packages/openai/_base_client.py:1058\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1055\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1057\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1058\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1061\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1062\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1066\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1067\u001B[0m )\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Error code: 404 - {'error': {'message': \"No assistant found with id 'asst_V59x1H97uwW3nm8WdUNuwn04'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "client.beta.assistants.delete(assistant.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T08:33:21.506426Z",
     "start_time": "2025-02-04T08:33:20.947416Z"
    }
   },
   "id": "94a0b71569a8b443",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
